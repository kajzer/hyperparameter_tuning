{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic hyperparameter tuning for machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating machine learning algorithm introduces us with concept of hyperparameters. Tuning hyperparameters is time consuming and can radically influence performance of the algorithm. Choosing right hyperparameter for your model is crucial task that can make model viable solution to a problem and enable it to generalize on different data. Same model with different set of data may require entirely different hyperparameters that will need to be tuned to a problem since we don’t know them beforehand. Given the above hyperparameter optimization is the problem of optimizing a loss function over a configuration space. \n",
    "\n",
    "## What are hyperparameters?\n",
    "\n",
    "Hyperparameters are not model parameters and the can’t be learned from the data in contrast to model parameters. Model parameters are properties of model that will be adjusted during loss function optimization (weights or bias) while hyperparameters are properties of a model that determine who we conduct training process (learning rate, maximum depth of decision tree). \n",
    "\n",
    "## Methodology od hyperparameter tuning\n",
    "\n",
    "There are several approaches for hyperparameter tuning. One of them is manual tuning which in effect takes away time from other steps of machine learning pipeline like feature engineering. This approach is very inefficient and oftentimes is substituted with grid and random search. Those two are automatic but require long run times since they evaluate areas of parameter grid that don’t give good results. Since manual search is taking up human time and grid and random search is time and computationally inefficient new methods have been proposed. \n",
    "\n",
    "#### Grid Search      \n",
    "\n",
    "Grid search is most basic form of hyperparameter optimization, also called parameter sweep. It trains algorithm for all combinations of a manually specified hyperparameter space at the same time measuring performance with some metric (usually used with K-Fold cross validation). One of the drawbacks to performing grid search are fixed parameters in search space which combinations can omit minimum for specific performance metric.\n",
    "\n",
    "#### Random Search\n",
    "\n",
    "Random search randomly samples search space and evaluates sets from a specified probability space. Limits exhaustive enumeration of all combinations of random search. It can outperform grid search performance by assuming that in most data sets only a few of the hyperparameters matter.\n",
    "\n",
    "#### Bayesian Optimisation\n",
    "\n",
    "Bayesian approach finds extrema of objective function in informed way by keeping track of  previous results. Grid and random search perform every experiment in isolation and every next evaluation is not able to use information from previous runs to improve. Bayesian optimization thanks to record of previous evaluation is able to create a probabilistic model mapping hyperparameters to a probability of a score on the objective function. This model is called surrogate function or response surface. Picking next sample data for evaluation is done by acquisition function. Popular acquisition functions are:\n",
    "\n",
    "Maximum Probability of Improvement \n",
    "- Expected Improvement\n",
    "- Upper Confidence Bound\n",
    "- Expected loss criterion\n",
    "\n",
    "\n",
    "Bayesian optimization belongs to a class of sequential model-based optimization (SMBO) algorithms that allow for one to use the results of our previous iteration to improve our sampling method of the next experiment. Types of SMBO’s differ as well by the choice of surrogate model. Popular surrogate models are:\n",
    "\n",
    "- Gaussian Processes \n",
    "- Random Forest Regressions \n",
    "- Tree Parzen Estimators \n",
    "\n",
    "### Lets create few evaluations of hyperparameter optimization modules and compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "############ IMPORTS ################\n",
    "\n",
    "############ basic imports ##########\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "############ model imports ##########\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "############ metrics ################\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "############ model select sklearn ##\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "############ basic training data ####\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "############ settings #########\n",
    "random_state=123\n",
    "n_iter=50\n",
    "num_folds=2\n",
    "verbose=0\n",
    "\n",
    "############ silient mode ###########\n",
    "import warnings                         \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "########### SEARCH MODULES ##########\n",
    "\n",
    "########### sklearn search methods ##\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "########### hpsklearn search methods #\n",
    "from hpsklearn import HyperoptEstimator, xgboost_regression\n",
    "\n",
    "########### hyperopt search methods###\n",
    "from hyperopt import fmin, tpe, hp, anneal, Trials\n",
    "\n",
    "########### skopt search methods #####\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize, gbrt_minimize #gp minimize same as Bayes search\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "########### Handling errors while importing BayesSearch #####\n",
    "class BayesSearchCV(BayesSearchCV):\n",
    "    def _run_search(self, x): raise BaseException('Use newer skopt')\n",
    "        \n",
    "########## GPyOpt search methods #####\n",
    "import GPy\n",
    "import GPyOpt\n",
    "\n",
    "########## evolutionary search methods #\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "\n",
    "########## btb search methods #########\n",
    "from btb import HyperParameter, ParamTypes\n",
    "from btb.tuning import GP, Uniform\n",
    "\n",
    "######### tpot imports ################\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "######### auto_ml imports #############\n",
    "from auto_ml import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### implemantation of context manager to get time and collect data from different modules ################\n",
    "class timer:\n",
    "    def __init__(self, name):\n",
    "        self.name          = name\n",
    "        self.cv_score      = None\n",
    "        self.test_score    = None\n",
    "        self.object        = None\n",
    "        self.plot_data     = None\n",
    "        self.best_params   = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self._t0 = time.time()\n",
    "        print(f'[{self.name}] -- Starting tuning')\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *params):\n",
    "        self.time = time.time() - self._t0\n",
    "        print(f'[{self.name}] -- Finished tuning')\n",
    "        if isinstance(self.plot_data, pd.DataFrame):\n",
    "            self.plot_data['score'] = self.plot_data['score'].astype('float')\n",
    "            self.plot_data['learning_rate'] = self.plot_data['learning_rate'].astype('float')\n",
    "            self.plot_data['max_depth'] = self.plot_data['max_depth'].astype('int')\n",
    "            self.plot_data['n_estimators'] = self.plot_data['n_estimators'].astype('int')\n",
    "        return None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'##################### [{self.name}] ##################### \\\n",
    "        \\n \\\n",
    "        \\n   evaluated in:          {self.time:.2f} s\\\n",
    "        \\n   best cros val MSE was: {self.cv_score:.2f}\\\n",
    "        \\n   best test MSE was:     {self.test_score:.2f}\\\n",
    "        \\n   best params:           {self.best_params} \\n\\n'\n",
    "    \n",
    "    def print_time(self):\n",
    "        print(f'[{self.name}] evaluated in {self.time:.2f} s')\n",
    "        \n",
    "    def print_summary(self):\n",
    "        print(self)\n",
    "        self.plot()\n",
    "        \n",
    "    def print_score(self):\n",
    "        print(f'[{self.name}] best test MSE was {self.test_score:.2f}')\n",
    "    \n",
    "    def plot(self):\n",
    "        if isinstance(self.plot_data, pd.DataFrame):\n",
    "\n",
    "            print('\\n-----------Ploting graphs for searched parameters-----------\\n')\n",
    "            plt.rcParams['font.size'] = 12\n",
    "            \n",
    "            fig, axs = plt.subplots(4, 1, figsize = (10, 12))\n",
    "            i = 0\n",
    "            for i, hyper in enumerate(['score', 'learning_rate', 'max_depth', 'n_estimators']):\n",
    "                sns.lineplot(data=self.plot_data[hyper], ax = axs[i])\n",
    "                axs[i].set(xlabel = 'Iteration', ylabel = '{}'.format(hyper), title = '{} over Search'.format(hyper))\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            fig, axs = plt.subplots(4, 1, figsize = (10, 12))\n",
    "            i = 0\n",
    "            for i, hyper in enumerate(['score', 'learning_rate', 'max_depth', 'n_estimators']):\n",
    "                sns.kdeplot(self.plot_data[hyper], label = hyper, linewidth = 2, ax = axs[i], shade = True)\n",
    "                axs[i].set(xlabel = 'Value', ylabel = '{}'.format(hyper), title = '{} distribution'.format(hyper))\n",
    "                    \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 4, figsize = (24, 6))\n",
    "            i = 0\n",
    "            for i, hyper in enumerate(['score', 'learning_rate', 'max_depth', 'n_estimators']):\n",
    "                sns.regplot(x='index', y=hyper, data = self.plot_data.reset_index(), ax = axs[i])\n",
    "                #sns.lineplot(data=grid_search.plot_data[hyper], ax = axs[i])\n",
    "                axs[i].set(\n",
    "                    xlabel = 'Iteration', \n",
    "                    ylabel = '{}'.format(hyper), \n",
    "                    title = '{} over Search'.format(hyper), \n",
    "                    ylim=(self.plot_data[hyper].min() * 0.9 ,self.plot_data[hyper].max() * 1.1)\n",
    "                )\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            print('No plot data')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "n = diabetes.data.shape[0]\n",
    "\n",
    "data = diabetes.data\n",
    "targets = diabetes.target\n",
    "\n",
    "# from sklearn.datasets import load_boston\n",
    "# boston = load_boston()\n",
    "# data = pd.DataFrame(boston.data)\n",
    "# data.columns = boston.feature_names\n",
    "# data['PRICE'] = boston.target\n",
    "# data, targets = data.iloc[:,:-1],data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, \n",
    "                                                    test_size=0.20, \n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=random_state\n",
    "                                                   )\n",
    "\n",
    "kf = KFold(n_splits=num_folds, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_array = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LightGBM model\n",
    "This model is trained as reference point without specifying any parameters. It is done in two steps. First we wrap context manager object in function and than call function. Context manager object purpose is to collect time and data about trained model, training steps and scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_basic_lgbm(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf):\n",
    "    with timer('Basic LGBM') as t:\n",
    "        \n",
    "        # instantiate LGBM\n",
    "        model = LGBMRegressor(random_state=random_state)\n",
    "        \n",
    "        # assign test score to ccontext object\n",
    "        t.cv_score = -cross_val_score(\n",
    "            model, \n",
    "            train_data, \n",
    "            train_targets, \n",
    "            cv=kf, \n",
    "            scoring=\"neg_mean_squared_error\", \n",
    "            n_jobs=1, \n",
    "            verbose=verbose\n",
    "        ).mean()\n",
    "        \n",
    "        # assign best model to context object\n",
    "        t.object = model.fit(train_data, train_targets)\n",
    "        # assign test score\n",
    "        t.test_score = mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.best_params = t.object.get_params()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Basic LGBM] -- Starting tuning\n",
      "[Basic LGBM] -- Finished tuning\n",
      "##################### [Basic LGBM] #####################         \n",
      "         \n",
      "   evaluated in:          0.11 s        \n",
      "   best cros val MSE was: 3831.85        \n",
      "   best test MSE was:     2959.59        \n",
      "   best params:           {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 1} \n",
      "\n",
      "\n",
      "No plot data\n"
     ]
    }
   ],
   "source": [
    "basic_lgbm = evaluate_basic_lgbm()\n",
    "print(basic_lgbm)\n",
    "basic_lgbm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "Evaluating standard sklearn GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gridsearch(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf):\n",
    "    with timer('GridSearch') as t:\n",
    "        \n",
    "        model = LGBMRegressor(random_state=random_state)\n",
    "        \n",
    "        param_grid={'learning_rate': np.logspace(-3, -1, 3),\n",
    "                    'max_depth':  np.linspace(2,20, 5,dtype = int),\n",
    "                    'n_estimators': np.linspace(800,1200, 5, dtype = int),\n",
    "                    'random_state': [random_state]}\n",
    "\n",
    "        gs=GridSearchCV(\n",
    "            model, \n",
    "            param_grid, \n",
    "            scoring='neg_mean_squared_error', \n",
    "            fit_params=None, \n",
    "            n_jobs=-1, \n",
    "            cv=kf, \n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        gs.fit(train_data, train_targets)\n",
    "        t.object = gs\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.cv_score = -t.object.best_score_\n",
    "        t.best_params = t.object.best_params_\n",
    "        \n",
    "        # get pandas frame of parameter data across iterations of search space\n",
    "        t.plot_data=pd.DataFrame(np.transpose([-t.object.cv_results_['mean_test_score'],\n",
    "                                         t.object.cv_results_['param_learning_rate'].data,\n",
    "                                         t.object.cv_results_['param_max_depth'].data,\n",
    "                                         t.object.cv_results_['param_n_estimators'].data]),\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])     \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_gridsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "Evaluating sklearn RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomsearch(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf):\n",
    "    with timer('RandomSearch') as t:\n",
    "        \n",
    "        model = LGBMRegressor(random_state=random_state, n_jobs=-1)\n",
    "\n",
    "        param_grid_rand={'learning_rate': np.logspace(-4, 0, 100),\n",
    "                         'max_depth':  randint(2,20),\n",
    "                         'n_estimators': randint(100,2000),\n",
    "                         'random_state': [random_state]}\n",
    "\n",
    "        rs=RandomizedSearchCV(\n",
    "            model, \n",
    "            param_grid_rand, \n",
    "            n_iter = n_iter, \n",
    "            scoring='neg_mean_squared_error', \n",
    "            fit_params=None, \n",
    "            n_jobs=-1, \n",
    "            cv=kf, \n",
    "            verbose=verbose, \n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        rs.fit(train_data, train_targets)\n",
    "        t.object = rs\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.cv_score = -t.object.best_score_\n",
    "        t.best_params = t.object.best_params_\n",
    "        \n",
    "        t.plot_data=pd.DataFrame(np.transpose([-t.object.cv_results_['mean_test_score'],\n",
    "                                         t.object.cv_results_['param_learning_rate'].data,\n",
    "                                         t.object.cv_results_['param_max_depth'].data,\n",
    "                                         t.object.cv_results_['param_n_estimators'].data]),\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_randomsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperopt objective function\n",
    "def objective_hyperopt(params, random_state=random_state, cv=kf, X=X_train, y=y_train):\n",
    "    \n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'learning_rate': params['learning_rate']}\n",
    "    \n",
    "    \n",
    "    model = LGBMRegressor(random_state=random_state, **params, n_jobs=-1)\n",
    "    \n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hyperopt_tpe(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf, objective=objective_hyperopt):\n",
    "    with timer('Hyperopt TPE') as t:\n",
    "\n",
    "        # defining search space\n",
    "        space={'n_estimators': hp.quniform('n_estimators', 100, 2000, 1),\n",
    "               'max_depth' : hp.quniform('max_depth', 2, 20, 1),\n",
    "               'learning_rate': hp.loguniform('learning_rate', -4, -1)\n",
    "              }\n",
    "\n",
    "        # trials will log information about every evaluation\n",
    "        trials = Trials()\n",
    "\n",
    "        best=fmin(fn=objective, # function to optimize\n",
    "                  space=space, \n",
    "                  algo=tpe.suggest, # optimization algorithm\n",
    "                  max_evals=n_iter, \n",
    "                  trials=trials,\n",
    "                  rstate=np.random.RandomState(random_state)\n",
    "                 )\n",
    "\n",
    "\n",
    "        model = LGBMRegressor(random_state=random_state, n_estimators=int(best['n_estimators']),\n",
    "                              max_depth=int(best['max_depth']),learning_rate=best['learning_rate'])\n",
    "        model.fit(train_data, train_targets)\n",
    "        t.object = model\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.cv_score = objective(best)\n",
    "        t.best_params = best\n",
    "        \n",
    "        tpe_results=np.array([[x['result']['loss'],\n",
    "                      x['misc']['vals']['learning_rate'][0],\n",
    "                      x['misc']['vals']['max_depth'][0],\n",
    "                      x['misc']['vals']['n_estimators'][0]] for x in trials.trials])\n",
    "\n",
    "        t.plot_data=pd.DataFrame(tpe_results,\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])\n",
    "        \n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_hyperopt_tpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hyperopt_anneal(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf, objective=objective_hyperopt):\n",
    "    with timer('Hyperopt Anneal') as t:\n",
    "        \n",
    "        space={'n_estimators': hp.quniform('n_estimators', 100, 2000, 1),\n",
    "               'max_depth' : hp.quniform('max_depth', 2, 20, 1),\n",
    "               'learning_rate': hp.loguniform('learning_rate', -4, -1)\n",
    "              }\n",
    "\n",
    "       \n",
    "        trials = Trials()\n",
    "\n",
    "        best=fmin(fn=objective_hyperopt, \n",
    "                  space=space, \n",
    "                  algo=anneal.suggest, \n",
    "                  max_evals=n_iter, \n",
    "                  trials=trials, \n",
    "                  rstate=np.random.RandomState(random_state) \n",
    "                 )\n",
    "\n",
    "        # computing the score on the test set\n",
    "        model = LGBMRegressor(random_state=random_state, n_estimators=int(best['n_estimators']),\n",
    "                              max_depth=int(best['max_depth']),learning_rate=best['learning_rate'], n_jobs=-1, verbose=1)\n",
    "        model.fit(train_data,train_targets)\n",
    "        t.object = model\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.cv_score = objective(best)\n",
    "        t.best_params = best\n",
    "        \n",
    "        tpe_results=np.array([[x['result']['loss'],\n",
    "                      x['misc']['vals']['learning_rate'][0],\n",
    "                      x['misc']['vals']['max_depth'][0],\n",
    "                      x['misc']['vals']['n_estimators'][0]] for x in trials.trials])\n",
    "\n",
    "        t.plot_data=pd.DataFrame(tpe_results,\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_hyperopt_anneal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## skopt with sklearn api\n",
    "def evaluate_skopt_bayes(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf, optimizer={'base_estimator':'RF', 'acq_func':'PI', 'acq_optimizer':'auto'}):\n",
    "    with timer('Scikit-Optimize API Bayes') as t:\n",
    "        \n",
    "        model = LGBMRegressor(random_state=random_state, n_jobs=-1)\n",
    "        \n",
    "        param_grid_bayes={'learning_rate': Real(1e-4, 1e-1, prior='log-uniform'),\n",
    "                         'max_depth':  Integer(2,20),\n",
    "                         'n_estimators': Integer(100,2000)\n",
    "                         }\n",
    "\n",
    "        bs=BayesSearchCV(model, param_grid_bayes, n_iter = n_iter, scoring='neg_mean_squared_error', fit_params=None, \n",
    "                        n_jobs=-1, cv=kf, random_state=random_state, optimizer_kwargs=optimizer)\n",
    "\n",
    "        bs.fit(train_data, train_targets)\n",
    "\n",
    "        t.object = bs\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.cv_score = -t.object.best_score_\n",
    "        t.best_params = t.object.best_params_\n",
    "        \n",
    "        t.plot_data=pd.DataFrame(np.transpose([-np.array(t.object.cv_results_['mean_test_score']),\n",
    "                                         t.object.cv_results_['param_learning_rate'],\n",
    "                                         t.object.cv_results_['param_max_depth'],\n",
    "                                         t.object.cv_results_['param_n_estimators']]),\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_skopt_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########skopt Scikit-Optimize with objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "space  = [Integer(2, 20, name='max_depth'),\n",
    "          Real(10**-4, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "          Integer(100, 2000, name='n_estimators')]\n",
    "\n",
    "\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective_skopt(random_state=random_state, cv=kf, X=X_train, y=y_train,**space):    \n",
    "\n",
    "    model = LGBMRegressor(random_state=random_state, n_jobs=-1)\n",
    "    model.set_params(**space)\n",
    "    \n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_skopt_bayes_dummy(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf):\n",
    "    with timer('Scikit-Optimize dummy minimize') as t:\n",
    "\n",
    "        res_gp = dummy_minimize(objective_skopt, space, n_calls=n_iter, random_state=random_state)\n",
    "\n",
    "        # computing the score on the test set\n",
    "        model = LGBMRegressor(random_state=random_state, n_estimators=int(res_gp.x[2]),\n",
    "                              max_depth=int(res_gp.x[0]),learning_rate=res_gp.x[1], n_jobs=-1, verbose=verbose)\n",
    "        model.fit(train_data,train_targets)\n",
    "        t.object = model\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.cv_score = res_gp.fun\n",
    "        t.best_params = {'learning_rate': res_gp.x[1], 'max_depth': int(res_gp.x[0]), 'n_estimators': int(res_gp.x[2])}\n",
    "        \n",
    "        t.plot_data=pd.DataFrame(np.transpose([np.array(res_gp.func_vals),\n",
    "            np.array(res_gp.x_iters)[:,1], #learning rate\n",
    "            np.array(res_gp.x_iters)[:,2], #n estimators\n",
    "            np.array(res_gp.x_iters)[:,0]]), #max depth\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_skopt_bayes_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_skopt_bayes_forest(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf):\n",
    "    with timer('Scikit-Optimize forest minimize') as t:\n",
    "\n",
    "        res_forest = forest_minimize(objective_skopt, space, n_calls=n_iter, random_state=random_state)\n",
    "\n",
    "        model = LGBMRegressor(random_state=random_state, n_estimators=int(res_forest.x[2]),\n",
    "                      max_depth=int(res_forest.x[0]),learning_rate=res_forest.x[1], n_jobs=-1, verbose=verbose)\n",
    "        model.fit(train_data,train_targets)\n",
    "        t.object = model\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.cv_score = res_forest.fun\n",
    "        t.best_params = {'learning_rate': res_forest.x[1], 'max_depth': int(res_forest.x[0]), 'n_estimators': int(res_forest.x[2])}\n",
    "        \n",
    "        t.plot_data=pd.DataFrame(np.transpose([np.array(res_forest.func_vals),\n",
    "            np.array(res_forest.x_iters)[:,1], #learning rate\n",
    "            np.array(res_forest.x_iters)[:,2], #n estimators\n",
    "            np.array(res_forest.x_iters)[:,0]]), #max depth\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_skopt_bayes_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_skopt_bayes_gbrt(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf):\n",
    "    with timer('Scikit-Optimize gbrt minimize') as t:\n",
    "\n",
    "        res_gbrt = gbrt_minimize(objective_skopt, space, n_calls=n_iter, random_state=random_state)\n",
    "\n",
    "        model = LGBMRegressor(random_state=random_state, n_estimators=int(res_gbrt.x[2]),\n",
    "                      max_depth=int(res_gbrt.x[0]),learning_rate=res_gbrt.x[1], n_jobs=-1, verbose=verbose)\n",
    "        model.fit(train_data,train_targets)\n",
    "        t.object = model\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.cv_score = res_gbrt.fun\n",
    "        t.best_params = {'learning_rate': res_gbrt.x[1], 'max_depth': int(res_gbrt.x[0]), 'n_estimators': int(res_gbrt.x[2])}\n",
    "        \n",
    "        t.plot_data=pd.DataFrame(np.transpose([np.array(res_gbrt.func_vals),\n",
    "            np.array(res_gbrt.x_iters)[:,1], #learning rate\n",
    "            np.array(res_gbrt.x_iters)[:,2], #n estimators\n",
    "            np.array(res_gbrt.x_iters)[:,0]]), #max depth\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_skopt_bayes_gbrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### GPyOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(random_state)\n",
    "\n",
    "domain =[{'name': 'max_depth',   'type': 'discrete', 'domain': np.linspace(2,20, dtype=int)},\n",
    "       {'name': 'learning_rate', 'type': 'continuous', 'domain': (0.0001, 1)},\n",
    "       {'name': 'n_estimators',  'type': 'discrete', 'domain': np.linspace(100,2000, dtype=int)}\n",
    "      ]\n",
    "\n",
    "\n",
    "def bayes_lgbm_gpy(x, mdl=None, cv=None):\n",
    "    x = np.atleast_2d(x)\n",
    "    fs = np.zeros((x.shape[0], 1))\n",
    "    for i, params in enumerate(x):\n",
    "        dict_params = dict(zip([el['name'] for el in domain], params))\n",
    "        dict_params['max_depth'] = int(dict_params['max_depth'])\n",
    "        dict_params['n_estimators'] = int(dict_params['n_estimators'])\n",
    "        #print(dict_params)\n",
    "        mdl.set_params(**dict_params)\n",
    "        fs[i] = -cross_val_score(mdl, X_train, y_train, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "    return fs\n",
    "\n",
    "\n",
    "def evaluate_gpyopt(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf):\n",
    "    with timer('GPyOpt') as t:\n",
    "        opt = GPyOpt.methods.BayesianOptimization(f = partial(bayes_lgbm_gpy, mdl=LGBMRegressor(random_state=random_state, n_jobs=-1), cv=kf),       \n",
    "                                                  domain = domain,         # box-constrains of the problem\n",
    "                                                  model_type= 'GP',\n",
    "                                                  acquisition_type='EI',\n",
    "                                                  num_cores=8,\n",
    "                                                  #acquisition_weight = 0.01\n",
    "                                                 )  \n",
    "        # https://gpyopt.readthedocs.io/en/latest/GPyOpt.methods.html?highlight=acquisition_type\n",
    "        opt.run_optimization(max_iter=n_iter)\n",
    "        \n",
    "        model = LGBMRegressor(random_state=random_state, n_estimators=int(opt.x_opt[2]),\n",
    "                      max_depth=int(opt.x_opt[0]), learning_rate=opt.x_opt[1], n_jobs=-1, verbose=1)\n",
    "        t.object = model\n",
    "        t.object.fit(train_data,train_targets)\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.cv_score = opt.fx_opt\n",
    "        t.best_params = {'learning_rate': opt.x_opt[1], 'max_depth': int(opt.x_opt[0]), 'n_estimators': int(opt.x_opt[2])}\n",
    "        \n",
    "        t.plot_data=pd.DataFrame(np.transpose([np.array(opt.Y)[:,0],\n",
    "            np.array(opt.X)[:,1], #learning rate\n",
    "            np.array(opt.X)[:,2], #n estimators\n",
    "            np.array(opt.X)[:,0]]), #max depth\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_gpyopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(random_state)\n",
    "\n",
    "param_grid={'learning_rate': np.logspace(-5, -1, 300),\n",
    "            'max_depth':  np.linspace(2, 20, 20-1, dtype = int),\n",
    "            'n_estimators': np.linspace(100 ,2000, 2000-100, dtype = int),\n",
    "            'random_state': [random_state]}\n",
    "\n",
    "# print(\"Size: \", len(param_grid[\"learning_rate\"])*len(param_grid[\"max_depth\"])*len(param_grid[\"n_estimators\"]))\n",
    "def evaluate_evolutionary(train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf):\n",
    "    with timer('Evolutionary Algorithm Search') as t:\n",
    "        model = LGBMRegressor(random_state=random_state, n_jobs=-1)\n",
    "        evol=EvolutionaryAlgorithmSearchCV(model, \n",
    "                                           param_grid, \n",
    "                                           scoring='neg_mean_squared_error', \n",
    "                                           fit_params=None, \n",
    "                                           n_jobs=1, \n",
    "                                           cv=kf, \n",
    "                                           verbose=verbose, \n",
    "                                           population_size=15,\n",
    "                                           gene_mutation_prob=0.60,\n",
    "                                           gene_crossover_prob=0.5,\n",
    "                                           tournament_size=3,\n",
    "                                           generations_number=10)\n",
    "\n",
    "\n",
    "        evol.fit(train_data, train_targets)\n",
    "        t.object = evol\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))\n",
    "        t.cv_score=-t.object.best_score_\n",
    "        t.best_params=t.object.best_params_\n",
    "        \n",
    "        t.plot_data=pd.DataFrame(np.transpose([-np.array(evol.cv_results_['mean_test_score']),\n",
    "                                         [item['learning_rate'] for item in evol.cv_results_['params']],\n",
    "                                         [item['max_depth'] for item in evol.cv_results_['params']],\n",
    "                                         [item['n_estimators'] for item in evol.cv_results_['params']]]),\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_evolutionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(random_state)\n",
    "tunables = [\n",
    "    ('n_estimators', HyperParameter(ParamTypes.INT, [100, 2000])),\n",
    "    ('max_depth', HyperParameter(ParamTypes.INT, [2, 20])),\n",
    "    ('learning_rate', HyperParameter(ParamTypes.FLOAT_EXP, [0.0001, 1]))\n",
    "]\n",
    "\n",
    "def evaluate_btb(tuner=GP(tunables), train_data=X_train, train_targets=y_train, test_data=X_test, test_targets=y_test, kf=kf):\n",
    "    with timer('BTB') as t:\n",
    "\n",
    "    #def tune_lgbm(tuner, random_state=random_state, cv=kf, X=train_data, y=train_targets):\n",
    "        for i in range(n_iter):\n",
    "            params = tuner.propose()\n",
    "\n",
    "            model = LGBMRegressor(random_state=random_state, \n",
    "                                  n_jobs=-1,\n",
    "                                  n_estimators=params['n_estimators'],\n",
    "                                  max_depth=params['max_depth'],\n",
    "                                  learning_rate=params['learning_rate']\n",
    "                                 )\n",
    "\n",
    "            score = cross_val_score(model, train_data, train_targets, cv=kf, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "            tuner.add(params, score)\n",
    "            \n",
    "            \n",
    "        model = LGBMRegressor(random_state=random_state, n_estimators=tuner._best_hyperparams['n_estimators'],\n",
    "                      max_depth=tuner._best_hyperparams['max_depth'],learning_rate=tuner._best_hyperparams['learning_rate'], n_jobs=-1, verbose=1)\n",
    "        model.fit(train_data,train_targets)\n",
    "        t.object = model\n",
    "        t.cv_score = -tuner._best_score\n",
    "        t.best_params = tuner._best_hyperparams\n",
    "        t.test_score=mean_squared_error(test_targets, t.object.predict(test_data))    \n",
    "        t.plot_data=pd.DataFrame(np.transpose([-np.array(tuner.y),\n",
    "                                         10**tuner.X[:,2],\n",
    "                                         tuner.X[:,1],\n",
    "                                         tuner.X[:,0]]),\n",
    "                           columns=['score', 'learning_rate', 'max_depth', 'n_estimators'])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_array.append(evaluate_btb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GridSearch] -- Starting tuning\n",
      "[GridSearch] -- Finished tuning\n",
      "##################### [GridSearch] #####################         \n",
      "         \n",
      "   evaluated in:          6.82 s        \n",
      "   best cros val MSE was: 3438.89        \n",
      "   best test MSE was:     2523.14        \n",
      "   best params:           {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 800, 'random_state': 123} \n",
      "\n",
      "\n",
      "[RandomSearch] -- Starting tuning\n",
      "[RandomSearch] -- Finished tuning\n",
      "##################### [RandomSearch] #####################         \n",
      "         \n",
      "   evaluated in:          4.69 s        \n",
      "   best cros val MSE was: 3413.94        \n",
      "   best test MSE was:     2750.58        \n",
      "   best params:           {'learning_rate': 0.002848035868435802, 'max_depth': 2, 'n_estimators': 1332, 'random_state': 123} \n",
      "\n",
      "\n",
      "[Hyperopt TPE] -- Starting tuning\n",
      "[Hyperopt TPE] -- Finished tuning\n",
      "##################### [Hyperopt TPE] #####################         \n",
      "         \n",
      "   evaluated in:          6.41 s        \n",
      "   best cros val MSE was: 3473.88        \n",
      "   best test MSE was:     2777.77        \n",
      "   best params:           {'learning_rate': 0.01861678436575023, 'max_depth': 13.0, 'n_estimators': 110.0} \n",
      "\n",
      "\n",
      "[Hyperopt Anneal] -- Starting tuning\n",
      "[Hyperopt Anneal] -- Finished tuning\n",
      "##################### [Hyperopt Anneal] #####################         \n",
      "         \n",
      "   evaluated in:          4.14 s        \n",
      "   best cros val MSE was: 3537.09        \n",
      "   best test MSE was:     2694.64        \n",
      "   best params:           {'learning_rate': 0.04124879310445036, 'max_depth': 9.0, 'n_estimators': 111.0} \n",
      "\n",
      "\n",
      "[Scikit-Optimize API Bayes] -- Starting tuning\n",
      "[Scikit-Optimize API Bayes] -- Finished tuning\n",
      "##################### [Scikit-Optimize API Bayes] #####################         \n",
      "         \n",
      "   evaluated in:          29.15 s        \n",
      "   best cros val MSE was: 3450.59        \n",
      "   best test MSE was:     2706.23        \n",
      "   best params:           {'learning_rate': 0.0028285803213750596, 'max_depth': 14, 'n_estimators': 887} \n",
      "\n",
      "\n",
      "[Scikit-Optimize dummy minimize] -- Starting tuning\n",
      "[Scikit-Optimize dummy minimize] -- Finished tuning\n",
      "##################### [Scikit-Optimize dummy minimize] #####################         \n",
      "         \n",
      "   evaluated in:          7.57 s        \n",
      "   best cros val MSE was: 3432.74        \n",
      "   best test MSE was:     2636.70        \n",
      "   best params:           {'learning_rate': 0.0026125144567845037, 'max_depth': 3, 'n_estimators': 1330} \n",
      "\n",
      "\n",
      "[Scikit-Optimize forest minimize] -- Starting tuning\n",
      "[Scikit-Optimize forest minimize] -- Finished tuning\n",
      "##################### [Scikit-Optimize forest minimize] #####################         \n",
      "         \n",
      "   evaluated in:          14.88 s        \n",
      "   best cros val MSE was: 3449.77        \n",
      "   best test MSE was:     2714.06        \n",
      "   best params:           {'learning_rate': 0.003328188196195174, 'max_depth': 5, 'n_estimators': 751} \n",
      "\n",
      "\n",
      "[Scikit-Optimize gbrt minimize] -- Starting tuning\n",
      "[Scikit-Optimize gbrt minimize] -- Finished tuning\n",
      "##################### [Scikit-Optimize gbrt minimize] #####################         \n",
      "         \n",
      "   evaluated in:          10.40 s        \n",
      "   best cros val MSE was: 3445.60        \n",
      "   best test MSE was:     2679.64        \n",
      "   best params:           {'learning_rate': 0.014400565628745865, 'max_depth': 17, 'n_estimators': 181} \n",
      "\n",
      "\n",
      "[GPyOpt] -- Starting tuning\n",
      "[GPyOpt] -- Finished tuning\n",
      "##################### [GPyOpt] #####################         \n",
      "         \n",
      "   evaluated in:          38.21 s        \n",
      "   best cros val MSE was: 4386.43        \n",
      "   best test MSE was:     3506.66        \n",
      "   best params:           {'learning_rate': 0.04557019780525949, 'max_depth': 14, 'n_estimators': 953} \n",
      "\n",
      "\n",
      "[Evolutionary Algorithm Search] -- Starting tuning\n",
      "[Evolutionary Algorithm Search] -- Finished tuning\n",
      "##################### [Evolutionary Algorithm Search] #####################         \n",
      "         \n",
      "   evaluated in:          25.03 s        \n",
      "   best cros val MSE was: 3451.23        \n",
      "   best test MSE was:     2708.23        \n",
      "   best params:           {'learning_rate': 0.0013399552696593384, 'max_depth': 11, 'n_estimators': 1882, 'random_state': 123} \n",
      "\n",
      "\n",
      "[BTB] -- Starting tuning\n",
      "[BTB] -- Finished tuning\n",
      "##################### [BTB] #####################         \n",
      "         \n",
      "   evaluated in:          4.32 s        \n",
      "   best cros val MSE was: 3439.90        \n",
      "   best test MSE was:     2674.26        \n",
      "   best params:           {'n_estimators': 526, 'max_depth': 4, 'learning_rate': 0.005750524892206498} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, f in enumerate(eval_array):\n",
    "    func = f()\n",
    "    print(func)\n",
    "    eval_array[i] = func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4YAAANhCAYAAAC7MqU3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3X1cz/f++PHHu6Q+SGY1yxhlU6lP\nffr4FLnqYpSrGjbMxSaGk7nY7DZj+5455osfvn0dh5y52mSYtTGt43C+MWE1FxWfOa4vtphlJhZF\nKfX+/aHep1SEkvK8325uer/fr4vn+1Pdbp6er/f7paiqihBCCCGEEEKIJ5dFTQcghBBCCCGEEKJm\nSWIohBBCCCGEEE84SQyFEEIIIYQQ4gkniaEQQgghhBBCPOEkMRRCCCGEEEKIJ5wkhkIIIYQQQgjx\nhJPEUAghhBBCCCGecNWeGCqKkqYoyr8VRTEripJSdO5/FEU5rijKIUVRNimK0qTofGtFUXKK2poV\nRVlaYpz2ReOcVhRlkaIoSnXHLoQQQgghhBBPgkdVMQxUVdWgqqqp6Hgb4KGqqidwEvigRNszRW0N\nqqpGlDj/CTAWeLHoT89HEbgQQgghhBBC1HX1amJSVVXjSxzuBV69W3tFURyBxqqq7ik6/hzoB2yt\nqI+9vb3aunXrhw9WCCGEEEIIIWqh1NTUDFVVHSrT9lEkhioQryiKCixTVXX5HddHATEljp0URTkI\nXAP+rKrq98BzwPkSbc4XnatQ69atSUlJeejghRBCCCGEEKI2UhTlbGXbPorEsLOqqumKojwDbFMU\n5biqqrsBFEX5L+AWsK6o7QXgeVVVLyuK0h6IVRTFHSjveUL1zhOKoozl9nJTnn/++Wq4FSGEEEII\nIYSoe6r9GUNVVdOL/v4d2AT4AiiKMgLoCwxTVVUtanNTVdXLRV+nAmeAttyuELYoMWwLIL2cuZar\nqmpSVdXk4FCpiqkQQgghhBBCPPGqNTFUFKWhoii2xV8DwcBhRVF6AlOBMFVVb5Ro76AoimXR187c\nfsnMT6qqXgCyFEXpWPQ20jeAb6szdiGEEEIIIYR4UlT3UtJmwKainSXqAV+oqvovRVFOA9bcXloK\nsLfoDaTdgJmKotwCCoAIVVWvFI01DogGdNx+6UyFL54RQgghhBB1T35+PufPnyc3N7emQxHisWJj\nY0OLFi2wsrJ64DGUolWcdY7JZFLl5TNCCCGEEHXHzz//jK2tLU8//TSypbUQt6mqyuXLl8nKysLJ\nyanUNUVRUktsGXhXj2ofQyGEEEIIIR5Kbm6uJIVC3EFRFJ5++umHrqRLYiiEEEIIIWoNSQqFKKsq\nfi8kMRRCCCGEEEKIJ5wkhkIIIYQQQlTSxYsXGTp0KM7OzrRv3x4/Pz82bdpUpl16ejqvvvpquWME\nBARQ/C6Mzz77DL1ej6enJx4eHnz7bfW+eL9169ZkZGRU6xyidnoUG9wLIYQQQghR66mqSr9+/Rgx\nYgRffPEFAGfPniUuLq5Uu1u3btG8eXM2bNhw1/HOnz/P7NmzOXDgAHZ2dmRnZ3Pp0qWHjvPWrVvU\nqyf/zBf3RyqGQgghhBBCVMKOHTuoX78+ERER2rlWrVoxceJEoqOjGThwIKGhoQQHB5OWloaHhwcA\nOTk5vPbaa3h6ejJ48GBycnIA+P3337G1taVRo0YANGrUSHur5JkzZ+jZsyft27ena9euHD9+HIB/\n/OMfdOjQAW9vb7p3787FixcBmDFjBmPHjiU4OJg33niDgoIC3nvvPa0auXjxYi3mxYsXYzQa0ev1\n2rhCyH8lCCGEEEKIWufjfxzhaPq1Kh2zXfPG/CXUvcLrR44cwWg0Vnh9z549HDp0iKZNm5KWlqad\n/+STT2jQoAGHDh3i0KFD2hheXl40a9YMJycnXnrpJQYMGEBoaCgAY8eOZenSpbz44ovs27ePt956\nix07dtClSxf27t2LoiisXLmS+fPn87//+78ApKamkpiYiE6n45NPPuHnn3/m4MGD1KtXjytXrmjx\n2Nvbc+DAAf7+978TGRnJypUrH+ZjE3WEJIZCCCGEEEI8gPHjx5OYmEj9+vUZP348PXr0oGnTpmXa\n7d69m0mTJgHg6emJp6cnAJaWlvzrX/8iOTmZ7777jsmTJ5Oamsp7773HDz/8wMCBA7Uxbt68Cdxe\nfjp48GAuXLhAXl5eqX3rwsLC0Ol0AGzfvp2IiAhtSWnJuAYMGABA+/bt+eabb6ryIxG1mCSGQggh\nhBCi1rlbZa+6uLu7s3HjRu14yZIlZGRkYDLd3j+8YcOGFfataDsBRVHw9fXF19eXHj16MHLkSN59\n912aNGmC2Wwu037ixIm8++67hIWFsXPnTmbMmKFdKzm/qqoVzmltbQ3cTkxv3bpV8Q2LJ4o8YyiE\nEEIIIUQlBAUFkZubyyeffKKdu3Hjxj37devWjXXr1gFw+PBhDh06BNx+c+mBAwe0dmazmVatWtG4\ncWOcnJz4+uuvgdtJ3o8//gjA1atXee655wBYvXp1hXMGBwezdOlSLfEruZRUiPJIYiiEEEIIIUQl\nKIpCbGwsu3btwsnJCV9fX0aMGMG8efPu2m/cuHFkZ2fj6enJ/Pnz8fX1BSA/P5/33nsPV1dXDAYD\nMTEx/O1vfwNg3bp1fPrpp3h5eeHu7q5tYzFjxgwGDhxI165dsbe3r3DO0aNH8/zzz+Pp6YmXl5f2\nFlUhKqKoqlrTMVQLk8mkFu8PI4QQQgghar9jx47h5uZW02EI8Vgq7/dDUZRUVVVNlekvFUMhhBBC\nCCGEeMJJYiiEEEIIIYQQTzhJDIUQQgghhBDiCSeJoRBCCCGEEEI84SQxFEIIIYQQQognnCSGQggh\nhBBCCPGEk8RQCCGEEEKISrK0tMRgMODh4UFoaCiZmZlVMm5aWhoeHh5VMtbevXvp0KEDBoMBNzc3\nZsyYUSXjViQ8PJwNGzZU6xyi+kliKIQQQgghRCXpdDrMZjOHDx+madOmLFmypKZDKmPEiBEsX75c\ni3PQoEEPPWZBQUEVRCYeZ5IYCiGEEEII8QD8/Pz49ddfAcjOzuall17CaDSi1+v59ttvgduVQDc3\nN8aMGYO7uzvBwcHk5OQAkJqaipeXF35+fqUSzNzcXEaOHIler8fb25uEhAQAoqOj6devH6GhoTg5\nOREVFcWCBQvw9vamY8eOXLlyBYDff/8dR0dH4HaFs127dgBcv36dUaNG4ePjg7e3d6kYu3btitFo\nxGg08sMPPwCwc+dOAgMDGTp0KHq9HoDPP/8cT09PvLy8eP3117WYd+/eTadOnXB2dpbqYS1Vr6YD\nEEIIIYQQ4r5tnQa//btqx3xWD73mVqppQUEB3333HW+++SYANjY2bNq0icaNG5ORkUHHjh0JCwsD\n4NSpU6xfv54VK1YwaNAgNm7cyPDhwxk5ciSLFy/G39+fKVOmaGMXJ4n//ve/OX78OMHBwZw8eRKA\nw4cPc/DgQXJzc3nhhReYN28eBw8eZPLkyXz++ee88847TJ48GRcXFwICAujZsycjRozAxsaG2bNn\nExQUxGeffUZmZia+vr50796dZ555hm3btmFjY8OpU6cYMmQIKSkpAOzfv5/Dhw/j5OTEkSNHmD17\nNklJSdjb22uJKMCFCxdITEzk+PHjhIWF8eqrrz7890M8UlIxFEIIIYQQopJycnIwGAw8/fTTXLly\nhR49egCgqioffvghnp6edO/enV9//ZWLFy8C4OTkhMFgAKB9+/akpaVx9epVMjMz8ff3ByhVfUtM\nTNSOXV1dadWqlZYYBgYGYmtri4ODA3Z2doSGhgKg1+tJS0sDYPr06aSkpBAcHMwXX3xBz549AYiP\nj2fu3LkYDAYCAgLIzc3l3Llz5OfnM2bMGPR6PQMHDuTo0aNaLL6+vjg5OQGwY8cOXn31Vezt7QFo\n2rSp1q5fv35YWFjQrl077b5F7SIVQyGEEEIIUftUsrJX1YqfMbx69Sp9+/ZlyZIlTJo0iXXr1nHp\n0iVSU1OxsrKidevW5ObmAmBtba31t7S0JCcnB1VVURSl3DlUVa1w/pJjWVhYaMcWFhbcunVLu9am\nTRvGjRvHmDFjcHBw4PLly6iqysaNG3FxcSk15owZM2jWrBk//vgjhYWF2NjYaNcaNmxYKq6KYi4Z\n193iF48vqRgKIYQQQghxn+zs7Fi0aBGRkZHk5+dz9epVnnnmGaysrEhISODs2bN37d+kSRPs7OxI\nTEwEYN26ddq1bt26accnT57k3LlzZZK5u/nnP/+pJWenTp3C0tKSJk2aEBISwuLFi7VrBw8eBODq\n1as4OjpiYWHBmjVrKnzRzEsvvcRXX33F5cuXAUotJRW1nySGQgghhBBCPABvb2+8vLz48ssvGTZs\nGCkpKZhMJtatW4erq+s9+69atYrx48fj5+eHTqfTzr/11lsUFBSg1+sZPHgw0dHRpSpy97JmzRpc\nXFwwGAy8/vrrrFu3DktLSz766CPy8/Px9PTEw8ODjz76SJtv9erVdOzYkZMnT5aqEpbk7u7Of/3X\nf+Hv74+XlxfvvvtupWMSjz+lrpZ6TSaTWvzQrBBCCCGEqP2OHTuGm5tbTYchxGOpvN8PRVFSVVU1\nVaa/VAyFEEIIIYQQ4gkniaEQQgghhBBCPOHkraSPUEHBDW7c+PmhxrCxaYmVVeMqikgIIYQQQggh\nJDF8pLKzj5OSOvChxrCza4+p/VdVFJEQQgghhBBCSGL4SDVo4IynfukD90+/8DWZmclVGJEQQggh\nhBBCSGL4SFlZNcHBoccD97+Rc5aMjO/Iz7+KlZVdFUYmhBBCCCGEeJLJy2dqEZ1NSwBycn+p4UiE\nEEIIIZ5MjRo1KnUcHR3NhAkTaiiais2ZM6fc8x06dMBgMPD888/j4OCAwWDAYDCQlpZG69at0ev1\neHl5ERwczG+//QagnS9uO2nSpEd5K+IRkYphLaLTtQAgN+c8jW09ajgaIYQQQghR3W7dukW9evf/\nT/Y5c+bw4Ycfljm/b98+4HZCm5KSQlRUVKnrCQkJ2Nvb8+GHHzJnzhwWLVpU6ryou6RiWIvodM8D\nkJNzroYjEUIIIYQQJWVlZeHk5ER+fj4A165do3Xr1uTn5xMQEMA777xDp06d8PDwYP/+/QBcv36d\nUaNG4ePjg7e3N99++y1wO2kbOHAgoaGhBAcHo6oqU6ZMwcPDA71eT0xMDAA7d+6kW7du9O/fn3bt\n2hEREUFhYSHTpk0jJycHg8HAsGHDHuh+unXrxunTp6vgkxG1hVQMa5F69WypV8+OnNzzNR2KEEII\nIUSNmrd/HsevHK/SMV2bujLVd+pd2xQnXMWuXLlCWFgYtra2BAQE8M9//pN+/frx5Zdf8sorr2Bl\nZQXcTgJ/+OEHdu/ezahRozh8+DCzZ88mKCiIzz77jMzMTHx9fenevTsAe/bs4dChQzRt2pSNGzdi\nNpv58ccfycjIwMfHh27dugGwf/9+jh49SqtWrejZsyfffPMNc+fOJSoqCrPZ/MCfxebNm9Hr9dpx\nYGAglpaWAIwYMYLJkyc/8Nji8SSJYS2j07UgN0eeMRRCCCGEqAk6na5UwlW8JBNg9OjRzJ8/n379\n+rFq1SpWrFihtRsyZAhwuxJ37do1MjMziY+PJy4ujsjISAByc3M5d+72yrAePXrQtGlTABITExky\nZAiWlpY0a9YMf39/kpOTady4Mb6+vjg7O2tzJCYm8uqrrz7w/RUngJ6ensyaNUs7L0tJ6z5JDGsZ\nnc3zZF+v2v8dE0IIIYSobe5V2asJnTt3Ji0tjV27dlFQUICHx3/eCaEoSqm2iqKgqiobN27ExcWl\n1LV9+/bRsGFD7VhV1QrnLG/chyEJ4JNLnjGsZWx0LcjJ+RVVLazpUIQQQgghxB3eeOMNhgwZwsiR\nI0udL34uMDExETs7O+zs7AgJCWHx4sVa4nfw4MFyx+zWrRsxMTEUFBRw6dIldu/eja+vL3B7KenP\nP/9MYWEhMTExdOnSBQArKyvteUchKkMSw1pGZ9MSVc3jZt7vNR2KEEIIIYS4w7Bhw/jjjz+0paPF\nnnrqKTp16kRERASffvopAB999BH5+fl4enri4eHBRx99VO6Y/fv3x9PTEy8vL4KCgpg/fz7PPvss\nAH5+fkybNg0PDw+cnJzo378/AGPHjsXT0/OBXz5zp8DAQG27ijfeeKNKxhSPF+VupenazGQyqcXr\nveuSy5d3Y/5xJO2NMTRpYqrpcIQQQgghHpljx47h5uZW02Hc1YYNG/j2229Zs2aNdi4gIIDIyEhM\npqr9t9vOnTuJjIxk8+bNVTquqJ3K+/1QFCVVVdVK/eDJM4a1jE5XtMl9zjlJDIUQQgghHiMTJ05k\n69atbNmypaZDEeK+SWJYy9jYNAcU2bJCCCGEEOIxs3jx4nLP79y5s1rmCwgIICAgoFrGFk8eecaw\nlrGwsMbauplsWSGEEEIIIYSoMpIY1kI6m5bkSGIohBBCCCGEqCKSGNZCNroW5ORKYiiEEEIIIYSo\nGpIY1kI6m5bcvHmRwsKbNR2KEEIIIYQQog6QxLAWuv1mUpXc3PSaDkUIIYQQ4onSqFGjUsfR0dFM\nmDChhqKp2Jw5c+56/eDBgyiKwv/93/89ooj+487PUDweJDGshWy0LStkOakQQgghRF1269atB+p3\nr8Rw/fr1dOnShfXr1z/Q+KLukcSwFtLZtACQLSuEEEIIIR4TWVlZODk5kZ+fD8C1a9do3bo1+fn5\nBAQE8M4779CpUyc8PDzYv38/ANevX2fUqFH4+Pjg7e3Nt99+C9yuQg4cOJDQ0FCCg4NRVZUpU6bg\n4eGBXq8nJiYGuL0NRrdu3ejfvz/t2rUjIiKCwsJCpk2bRk5ODgaDgWHDhpWJVVVVNmzYQHR0NPHx\n8eTm5gKQlpaGm5sbY8aMwd3dneDgYHJycoDbW2NMnToVX19f2rZty/fffw9AQUEBU6ZMwcfHB09P\nT5YtWwZAdnY2L730EkajEb1er92beHzJPoa1kLV1MxSlvmxZIYQQQogn1m9z5nDz2PEqHdPazZVn\nP/zwrm2KE65iV65cISwsDFtbWwICAvjnP/9Jv379+PLLL3nllVewsrICbieBP/zwA7t372bUqFEc\nPnyY2bNnExQUxGeffUZmZia+vr50794dgD179nDo0CGaNm3Kxo0bMZvN/Pjjj2RkZODj40O3bt0A\n2L9/P0ePHqVVq1b07NmTb775hrlz5xIVFYXZbC73HpKSknBycqJNmzYEBASwZcsWBgwYAMCpU6dY\nv349K1asYNCgQWzcuJHhw4cDt6uX+/fvZ8uWLXz88cds376dTz/9FDs7O5KTk7l58yadO3cmODiY\nli1bsmnTJho3bkxGRgYdO3YkLCwMRVEe7pskqo1UDGshRbFAp3tOlpIKIYQQQjxiOp0Os9ms/Zk5\nc6Z2bfTo0axatQqAVatWMXLkSO3akCFDAOjWrRvXrl0jMzOT+Ph45s6di8FgICAggNzcXM6dOwdA\njx49aNq0KQCJiYkMGTIES0tLmjVrhr+/P8nJyQD4+vri7OyMpaUlQ4YMITEx8Z73sH79el577TUA\nXnvttVLLSZ2cnLTEt3379qSlpWnXipPHkufj4+P5/PPPMRgMdOjQgcuXL3Pq1ClUVeXDDz/E09OT\n7t278+uvv3Lx4sXKf9DikZOKYS1lYyNbVgghhBDiyXWvyl5N6Ny5M2lpaezatYuCggI8PDy0a3dW\nyhRFQVVVNm7ciIuLS6lr+/bto2HDhtqxqqoVzlneuHdTUFDAxo0biYuLY/bs2aiqyuXLl8nKygLA\n2tpaa2tpaaktJS15zdLSUnv2UVVVFi9eTEhISKl5oqOjuXTpEqmpqVhZWdG6dWttyap4PEnFsJbS\n6VqSkyPPGAohhBBCPE7eeOMNhgwZUqpaCGjPBSYmJmJnZ4ednR0hISEsXrxYS/wOHjxY7pjdunUj\nJiaGgoICLl26xO7du/H19QVuLyX9+eefKSwsJCYmhi5dugBgZWWlPe9Y0vbt2/Hy8uKXX34hLS2N\ns2fP8sorrxAbG/tA9xsSEsInn3yizXXy5EmuX7/O1atXeeaZZ7CysiIhIYGzZ88+0Pji0ZHEsJbS\n2bTk1q1Mbt3KqulQhBBCCCFEkWHDhvHHH39oS0eLPfXUU3Tq1ImIiAg+/fRTAD766CPy8/Px9PTE\nw8ODjz76qNwx+/fvj6enJ15eXgQFBTF//nyeffZZAPz8/Jg2bRoeHh44OTnRv39/AMaOHYunp2eZ\nl8+sX79ea1PslVde4Ysvvnig+x09ejTt2rXDaDTi4eHBn/70J27dusWwYcNISUnBZDKxbt06XF1d\nH2h88egodytN12Ymk0lNSUmp6TCqzcXft3L48AR8ff6BrW27mg5HCCGEEKLaHTt2DDc3t5oO4642\nbNjAt99+y5o1a7RzAQEBREZGYjKZqnSunTt3EhkZyebNm6t0XFE7lff7oShKqqqqlfrBk2cMa6n/\nbFnxiySGQgghhBCPgYkTJ7J161a2bNlS06EIcd8kMayldLrnAdnkXgghhBDicbF48eJyz+/cubNa\n5gsICCAgIKBaxhZPHnnGsJaysrKjXj1bcuUFNEIIIYQQQoiHJIlhLWZj01K2rBBCCCGEEEI8NEkM\nazHZskIIIYQQQghRFSQxrMV0Ni3Izf3lrpueCiGEEEIIIcS9SGJYi9noWlJYeJO8vEs1HYoQQggh\nxBNh9uzZuLu74+npicFgYN++fRW2TUlJYdKkSQDMmDGDyMjIMm2mT5/O9u3bAVi4cCE3btyocLzE\nxER8fX1xdXXF1dWV5cuX3zNes9lc6i2pcXFxzJ079579SurduzeZmZn31ac8t27dwt7eng8++KDU\n+YCAAFxcXPDy8qJz586cOHFCO1/e9nPF7Q0GA25ubpX6HMS9yVtJa7GSW1ZYWz9Tw9EIIYQQQtRt\ne/bsYfPmzRw4cABra2syMjLIy8ursL3JZLrn3oUzZ87Uvl64cCHDhw+nQYMGZdr99ttvDB06lNjY\nWIxGIxkZGYSEhPDcc8/Rp0+fCsc3m82kpKTQu3dvAMLCwggLC7vXrZZSVdtvxMfH4+LiwldffcWc\nOXNQFEW7tm7dOkwmE8uXL2fKlCnExcXddazi9leuXKFNmzaEh4dTv379KonzSSUVw1pMtqwQQggh\nhHh0Lly4gL29PdbW1gDY29vTvHlzAJKTk+nUqRNeXl74+vqSlZXFzp076du3b5lxVqxYQa9evcjJ\nySE8PJwNGzawaNEi0tPTCQwMJDAwsEyfJUuWEB4ejtFo1OaeP3++Vv0LDw8nIiKCrl270rZtWzZv\n3kxeXh7Tp08nJiYGg8FATEwM0dHRTJgwQeszbtw4AgMDcXZ2ZteuXYwaNQo3NzfCw8O1uVu3bk1G\nRgZLly7FYDBgMBhwcnLS4oyPj8fPzw+j0cjAgQPJzs4u9/Nbv349b7/9Ns8//zx79+4tt023bt04\nffp0Zb4dAGRnZ9OwYUMsLS0BGDduHCaTCXd3d/7yl78A8N1339G/f3+tz7Zt2xgwYMBdY582bRrt\n2rXD09OT9957r9Lx1GZSMazFbIoqhrmSGAohhBDiCfP9VyfJ+KX8BORB2bdsRNdBbSu8HhwczMyZ\nM2nbti3du3dn8ODB+Pv7k5eXx+DBg4mJicHHx4dr166h0+nKHSMqKor4+HhiY2O1BBNg0qRJLFiw\ngISEBOzt7cv0O3LkCCNGjCh1zmQyceTIEe04LS2NXbt2cebMGQIDAzl9+jQzZ84kJSWFqKgoAKKj\no0uN8ccff7Bjxw7i4uIIDQ0lKSmJlStX4uPjg9lsxmAwaG0jIiKIiIggPz+foKAg3n33XTIyMpg1\naxbbt2+nYcOGzJs3jwULFjB9+vRS8+Tk5PDdd9+xbNkyMjMzWb9+PX5+fmXu8x//+Ad6vb6C78B/\nDBs2DGtra06dOsXChQu1xHD27Nk0bdqUgoICXnrpJQ4dOkRQUBDjx4/n0qVLODg4sGrVKkaOHFlh\n7BMmTGDTpk0cP34cRVGqZBltbSAVw1rM0tKa+vWfISdX3kwqhBBCCFHdGjVqRGpqKsuXL8fBwYHB\ngwcTHR3NiRMncHR0xMfHB4DGjRtTr17Z+suaNWvYunUrGzduLJUUVoaqqqWWXhYreW7QoEFYWFjw\n4osv4uzszPHjx+85bmhoKIqioNfradasGXq9HgsLC9zd3UlLSyu3z9tvv01QUBChoaHs3buXo0eP\n0rlzZwwGA6tXr+bs2bNl+mzevJnAwEAaNGjAK6+8wqZNmygoKNCuDxs2DIPBQFJSUrnPYt5p3bp1\nHDp0iHPnzhEZGanN+dVXX2E0GvH29ubIkSMcPXoURVF4/fXXWbt2LZmZmezZs4devXpVGHvjxo2x\nsbFh9OjRfPPNN+Uu7a2LpGJYy93eskIqhkIIIYR4stytsledLC0tCQgIICAgAL1ez+rVqzEajeUm\nbXfy8PDAbDZz/vx5nJyc7tp206ZNfPzxxwCsXLkSd3d3UlJSSj0fmJqaSrt27bTjO2OoTEzFCaqF\nhUWpZNXCwoJbt26VaR8dHc3Zs2e1CqSqqvTo0YP169ffdZ7169eTlJRE69atAbh8+TIJCQl0794d\n+M8zg/fLwcEBo9HIvn37KCwsJDIykuTkZJ566inCw8PJzc0FYOTIkYSGhmJjY8PAgQOpV6/eXWPf\nv38/3333HV9++SVRUVHs2LHjvmOrbaRiWMvpbFrKUlIhhBBCiEfgxIkTnDp1Sjs2m820atUKV1dX\n0tPTSU5OBiArK6vcpMrb25tly5YRFhZGenp6meu2trZkZWUB0L9/f8xmM2azGZPJxPjx44mOjsZs\nNgO3E6upU6fy/vvva/2//vprCgsLOXPmDD/99BMuLi6lxnxYqampREZGsnbtWiwsbqcRHTt2JCkp\nSXsu8MaNG5w8ebJUv2vXrpGYmMi5c+dIS0sjLS2NJUuW3DOZrIwbN25w8OBB2rRpw7Vr12jYsCF2\ndnZcvHiRrVu3au2aN29O8+bNmTVrlvb8ZEWxZ2dnc/XqVXr37s3ChQu1z7yuk4phLWeja0HuxTgK\nC/OxsLCq6XCEEEIIIeqs7OxuRtmDAAAgAElEQVRsJk6cSGZmJvXq1eOFF15g+fLl1K9fn5iYGCZO\nnEhOTg46nU7bguJOXbp0ITIykj59+rBt27ZS18aOHUuvXr1wdHQkISGh1DVHR0fWrl3LmDFjyMrK\nQlVV3nnnHUJDQ7U2Li4u+Pv7c/HiRZYuXYqNjQ2BgYHMnTsXg8FQZpuI+xUVFcWVK1e0l86YTCZW\nrlxJdHQ0Q4YM4ebNmwDMmjWLtm3/U9H95ptvCAoKKlWRfPnll3n//fe1Pvdr2LBh6HQ6bt68SXh4\nOO3btwduJ9/u7u44OzvTuXPnMn0uXbqkVVkdHBzKjd3W1paXX36Z3NxcVFXlr3/96wPFWNsodXVz\ndJPJpJa370ldk35hA8eOTcWv4w4aNGhV0+EIIYQQQlSbY8eO4ebmVtNhPJbCw8Pp27cvr776ak2H\n8tiaMGEC3t7evPnmmzUdSrUo7/dDUZRUVVUrtUZXlpLWcjqblsDtvQyFEEIIIYQQZbVv355Dhw4x\nfPjwmg7lsSVLSWs5ne52YijPGQohhBBCPLnu3IZClJaamlrTITz2pGJYy1lbN0NRrGTLCiGEEEII\nIcQDk8SwllMUS2xsmpOTc66mQxFCCCGEEELUUpIY1gG3t6yQiqEQQgghhBDiwUhiWAfY6FrIUlIh\nhBBCCCHEA5PEsA7Q6Z4nP/8Kt25l13QoQgghhBB12uzZs3F3d8fT0xODwcC+ffsqbJuSksKkSZMA\nmDFjBpGRkWXaTJ8+XdvzcOHChdy4caPC8RITE/H19cXV1RVXV1eWL19+z3jNZjNbtmzRjuPi4pg7\nd+49+5XUu3dvMjMz76vP3aSlpeHh4VFl4z1qnTp1umeb0aNHc/To0UqPWfJnpabIW0nrAJ1NCwBy\ncs9j28i1hqMRQgghhKib9uzZw+bNmzlw4ADW1tZkZGSQl5dXYXuTyYTJdPct5GbOnKl9vXDhQoYP\nH06DBg3KtPvtt98YOnQosbGxGI1GMjIyCAkJ4bnnnqNPnz4Vjm82m0lJSaF3794AhIWFERYWdq9b\nLaVkYinghx9+uGeblStX3teYlflZqW5SMawDZMsKIYQQQojqd+HCBezt7bG2tgbA3t6e5s2bA5Cc\nnEynTp3w8vLC19eXrKwsdu7cSd++fcuMs2LFCnr16kVOTg7h4eFs2LCBRYsWkZ6eTmBgIIGBgWX6\nLFmyhPDwcIxGozb3/PnztepfeHg4ERERdO3albZt27J582by8vKYPn06MTExGAwGYmJiiI6OZsKE\nCVqfcePGERgYiLOzM7t27WLUqFG4ubkRHh6uzd26dWsyMjJYunQpBoMBg8GAk5OTFmd8fDx+fn4Y\njUYGDhxIdnbZVWypqal4eXnh5+fHkiVLtPMl4wHo27cvO3fuBKBRo0ZMnTqV9u3b0717d/bv309A\nQADOzs7ExcVp/fv160doaChOTk5ERUWxYMECvL296dixI1euXOHMmTPa5wZw6tQp2rdvXybGgIAA\nJk+eTLdu3XBzcyM5OZkBAwbw4osv8uc//1lr16hRIwB27txJQEAAr776Kq6urgwbNgxVVbWxUlJS\nKn0fJX9WevfurX3OdnZ2rF69moKCAqZMmYKPjw+enp4sW7asTPwPSyqGdUBxYijPGQohhBDiSZEQ\nvZzfz/5UpWM+08qZwPCxFV4PDg5m5syZtG3blu7duzN48GD8/f3Jy8tj8ODBxMTE4OPjw7Vr19Dp\ndOWOERUVRXx8PLGxsVqCCTBp0iQWLFhAQkIC9vb2ZfodOXKEESNGlDpnMpk4cuSIdpyWlsauXbs4\nc+YMgYGBnD59mpkzZ5KSkkJUVBRQdr/DP/74gx07dhAXF0doaChJSUmsXLkSHx8fzGYzBoNBaxsR\nEUFERAT5+fkEBQXx7rvvkpGRwaxZs9i+fTsNGzZk3rx5LFiwgOnTp5eaZ+TIkSxevBh/f3+mTJlS\n4Wdc0vXr1wkICGDevHn079+fP//5z2zbto2jR48yYsQIrfJ5+PBhDh48SG5uLi+88ALz5s3j4MGD\nTJ48mc8//5x33nkHOzs77X5WrVpVKvEtqX79+uzevZu//e1vvPzyy6SmptK0aVPatGnD5MmTefrp\np0u1P3jwIEeOHKF58+Z07tyZpKQkunTp8kD3Uay4QpuamsrIkSPp168fn376KXZ2diQnJ3Pz5k06\nd+5McHAwTk5OlfosK0MqhnVAvXpNsLRsJFtWCCGEEEJUo0aNGpGamsry5ctxcHBg8ODBREdHc+LE\nCRwdHfHx8QGgcePG1KtXtv6yZs0atm7dysaNG0slhZWhqiqKopQ5X/LcoEGDsLCw4MUXX8TZ2Znj\nx4/fc9zQ0FAURUGv19OsWTP0ej0WFha4u7uTlpZWbp+3336boKAgQkND2bt3L0ePHqVz584YDAZW\nr17N2bNnS7W/evUqmZmZ+Pv7A/D6669X6p7r169Pz549AdDr9fj7+2NlZYVery8VW2BgILa2tjg4\nOGBnZ0doaKjWp7jd6NGjWbVqFQUFBcTExDB06NBy5yxO0vR6Pe7u7jg6OmJtbY2zszO//FJ2dZ6v\nry8tWrTAwsICg8FQ7mdW2fsoKSMjg9dff50vvvgCOzs74uPj+fzzzzEYDHTo0IHLly9z6tSpynyM\nlSYVwzpAURR0uhayZYUQQgghnhh3q+xVJ0tLSwICAggICECv17N69WqMRmO5SdudPDw8MJvNnD9/\n/p6Vnk2bNvHxxx8Dt59Xc3d3JyUlpVR1KTU1lXbt2mnHd8ZQmZiKE1QLC4tSyaqFhQW3bt0q0z46\nOpqzZ89qFUhVVenRowfr16+vcI6KklqAevXqUVhYqB3n5uZqX1tZWWn9SsZ3Z2x3xl1eu1deeYWP\nP/6YoKAg2rdvX6byd+dYlf08SraxtLQst01l76NYQUEBr732GtOnT9de0qOqKosXLyYkJKTcuKuC\nVAzrCBubFuTkyjOGQgghhBDV5cSJE6WqNGazmVatWuHq6kp6ejrJyckAZGVllfsPfm9vb5YtW0ZY\nWBjp6ellrtva2pKVlQVA//79MZvNmM1mTCYT48ePJzo6GrPZDMDly5eZOnUq77//vtb/66+/prCw\nkDNnzvDTTz/h4uJSasyHlZqaSmRkJGvXrsXC4nYa0bFjR5KSkjh9+jQAN27c4OTJk6X6NWnSBDs7\nOxITEwFYt26ddq1169aYzWYKCwv55Zdf2L9/f5XEeicbGxtCQkIYN24cI0eOrJY5qsq0adPw9PTk\ntdde086FhITwySefkJ+fD8DJkye5fv16lc4rFcM6Qqd7nitXku76PzJCCCGEEOLBZWdnM3HiRDIz\nM6lXrx4vvPACy5cvp379+sTExDBx4kRycnLQ6XTaFhR36tKlC5GRkfTp04dt27aVujZ27Fh69eqF\no6MjCQkJpa45Ojqydu1axowZQ1ZWFqqq8s4772jLJgFcXFzw9/fn4sWLLF26FBsbGwIDA5k7dy4G\ng4EPPvjgoe4/KiqKK1euaC+dMZlMrFy5kujoaIYMGcLNmzcBmDVrFm3bti3Vd9WqVYwaNYoGDRqU\nqnp17twZJycn9Ho9Hh4epV4SU9WGDRvGN998Q3BwcLXNURUiIyNxd3fXnu+cOXMmo0ePJi0tDaPR\niKqqODg4EBsbW6XzKsVvzqlrTCaTWvwmoCfBL7+s5uSpmXTpsg/r+mUfWBZCCCGEqO2OHTuGm5tb\nTYfxWAoPD6dv3768+uqrNR3KYysyMpKrV6/y3//93zUdSrUo7/dDUZRUVVUrtQ+GVAzriJJbVkhi\nKIQQQgghxH/079+fM2fOsGPHjpoO5bEliWEdYVO8ZUXOL9jZeddwNEIIIYQQ4lG6cxsKUdqmTZtq\nOoTHnrx8po7Q2bQAkBfQCCGEEEIIIe6bJIZ1hKWljvr17WXLCiGEEEIIIcR9k8SwDtHZtJSKoRBC\nCCGEEOK+SWJYh9joWpKTI4mhEEIIIYQQ4v5IYliH6GxacPPmBQoLy26oKoQQQgghHt7s2bNxd3fH\n09MTg8HAvn37KmybkpLCpEmTAJgxYwaRkZFl2kyfPl3b83DhwoXcuHGjwvESExPx9fXF1dUVV1dX\nli9ffs94zWYzW7Zs0Y7j4uKYO3fuPfuV1Lt3bzIzM++rz52OHz+OwWDA29ubM2fOPNRYFYmNjeXo\n0aMPNUZl7rXk96wy0tPTa8U2IvJW0jpEp2uJqhZw8+YFbfsKIYQQQghRNfbs2cPmzZs5cOAA1tbW\nZGRkkJeXV2F7k8mEyXT3LeRmzpypfb1w4UKGDx9OgwYNyrT77bffGDp0KLGxsRiNRjIyMggJCeG5\n556jT58+FY5vNptJSUmhd+/eAISFhREWFnavWy2lZGL5oGJjY3n55Zf5+OOPK9VeVVVUVcXCovJ1\nrNjYWPr27Uu7du0eNMxK3WvJ71llNG/enA0bNjxoSI+MVAzrkP9sWXGuhiMRQgghhKh7Lly4gL29\nPdbW1gDY29vTvHlzAJKTk+nUqRNeXl74+vqSlZXFzp076du3b5lxVqxYQa9evcjJySE8PJwNGzaw\naNEi0tPTCQwMJDAwsEyfJUuWEB4ejtFo1OaeP3++Vv0LDw8nIiKCrl270rZtWzZv3kxeXh7Tp08n\nJiYGg8FATEwM0dHRTJgwQeszbtw4AgMDcXZ2ZteuXYwaNQo3NzfCw8O1uVu3bk1GRgZLly7FYDBg\nMBhwcnLS4oyPj8fPzw+j0cjAgQPJzs4uFfuWLVtYuHAhK1eu1PosWLAADw8PPDw8WLhwIQBpaWm4\nubnx1ltvYTQa+eWXXyoce9q0abRr1w5PT0/ee+89fvjhB+Li4pgyZQoGg6FMVfJ+77U4ljFjxuDu\n7k5wcDA5OTnaWMWJXuvWrfnwww/x8/PDZDJx4MABQkJCaNOmDUuXLtXuy8PDA4DRo0drn6GDg4OW\nKP/P//wPPj4+eHp68pe//KW8H79qJxXDOkRnU5QY5sqbSYUQQghRt2X+4wx56derdMz6zRvSJLRN\nhdeDg4OZOXMmbdu2pXv37gwePBh/f3/y8vIYPHgwMTEx+Pj4cO3aNXQ6XbljREVFER8fT2xsrJZg\nAkyaNIkFCxaQkJCAvb19mX5HjhxhxIgRpc6ZTCaOHDmiHaelpbFr1y7OnDlDYGAgp0+fZubMmaSk\npBAVFQWU3e/wjz/+YMeOHcTFxREaGkpSUhIrV67Ex8cHs9mMwWDQ2kZERBAREUF+fj5BQUG8++67\nZGRkMGvWLLZv307Dhg2ZN28eCxYsYPr06Vq/3r17ExERQaNGjXjvvfdITU1l1apV7Nu3D1VV6dCh\nA/7+/jz11FOcOHGCVatW8fe//73CsSdMmMCmTZs4fvw4iqKQmZlJkyZNCAsLo2/fvhUu27yfewU4\ndeoU69evZ8WKFQwaNIiNGzcyfPjwMuO2bNmSPXv2MHnyZMLDw0lKSiI3Nxd3d3ciIiJKtV25ciUA\nZ8+eJSQkhPDwcOLj4zl16hT79+9HVVXCwsLYvXs33bp1K/c+qku1VwwVRUlTFOXfiqKYFUVJKTrX\nVFGUbYqinCr6+6mi84qiKIsURTmtKMohRVGMJcYZUdT+lKIoIyqa70lmbf0simJJrryARgghhBCi\nyjVq1IjU1FSWL1+Og4MDgwcPJjo6mhMnTuDo6IiPjw8AjRs3pl69svWXNWvWsHXrVjZu3FgqKawM\nVVVRFKXM+ZLnBg0ahIWFBS+++CLOzs4cP378nuOGhoaiKAp6vZ5mzZqh1+uxsLDA3d2dtLS0cvu8\n/fbbBAUFERoayt69ezl69CidO3fGYDCwevVqzp49e9c5ExMT6d+/Pw0bNqRRo0YMGDCA77//HoBW\nrVrRsWNHgArHbty4MTY2NowePZpvvvmm3KW3VXGvTk5OWrLYvn37Cj+P4qW5er2eDh06YGtri4OD\nAzY2NuU+r5ibm8vAgQOJioqiVatWxMfHEx8fj7e3N0ajkePHj3Pq1KlK3VNVelQVw0BVVTNKHE8D\nvlNVda6iKNOKjqcCvYAXi/50AD4BOiiK0hT4C2ACVCBVUZQ4VVX/eETx1woWFvWwsX5O3kwqhBBC\niDrvbpW96mRpaUlAQAABAQHo9XpWr16N0WgsN2m7k4eHB2azmfPnz+Pk5HTXtps2bdKWGa5cuRJ3\nd3dSUlJKPR+Ymppa6nm6O2OoTEzFCaqFhUWpZNXCwoJbt8q+0DA6OpqzZ89qFUhVVenRowfr16+/\n51zFVFWt8FrDhg1Ltato7P379/Pdd9/x5ZdfEhUVxY4dO+457/3ea8k2lpaW2lLShx03IiKCAQMG\n0L17d+0+P/jgA/70pz/d8x6qU009Y/gysLro69VAvxLnP1dv2ws0URTFEQgBtqmqeqUoGdwG9HzU\nQdcGNroWspRUCCGEEKIanDhxolQlx2w206pVK1xdXUlPTyc5ORmArKyschMCb29vli1bRlhYGOnp\n6WWu29rakpWVBUD//v0xm82YzWZMJhPjx48nOjoas9kMwOXLl5k6dSrvv/++1v/rr7+msLCQM2fO\n8NNPP+Hi4lJqzIeVmppKZGQka9eu1V4K07FjR5KSkjh9+jQAN27c4OTJk3cdp1u3bsTGxnLjxg2u\nX7/Opk2b6Nq1a5l2FY2dnZ3N1atX6d27NwsXLtQ+k6q81+qyZMkSsrKymDZtmnYuJCSEzz77THt+\n8tdff+X3339/5LE9ioqhCsQriqICy1RVXQ40U1X1AoCqqhcURXmmqO1zQMly1/micxWdF3fQ2bTg\nUsZ3NR2GEEIIIUSdk52dzcSJE8nMzKRevXq88MILLF++nPr16xMTE8PEiRPJyclBp9NVuJ1Bly5d\niIyMpE+fPmzbtq3UtbFjx9KrVy8cHR1JSEgodc3R0ZG1a9cyZswYsrKyUFWVd955h9DQUK2Ni4sL\n/v7+XLx4kaVLl2JjY0NgYCBz587FYDDwwQcfPNT9R0VFceXKFe0FMiaTiZUrVxIdHc2QIUO4efMm\nALNmzaJt27YVjmM0GgkPD8fX1xe4/UIWb2/vMks1HRwcyh3b1taWl19+mdzcXFRV5a9//SsAr732\nGmPGjGHRokVs2LCBNm1qpqp8N5GRkVhZWWlLVIuf2zx27Bh+fn7A7SXLa9eu5ZlnnrnbUFVOuVsp\nt0omUJTmqqqmFyV/24CJQJyqqk1KtPlDVdWnFEX5J/D/VFVNLDr/HfA+EARYq6o6q+j8R8ANVVX/\n9465xgJjAZ5//vn291rfXBelpX3CmZ8iCfD/N5aWlVtvLYQQQghRGxw7dgw3N7eaDuOxFB4eftcX\nr4i6r7zfD0VRUlVVvfueKUWqfSmpqqrpRX//DmwCfIGLRUtEKfq7uFZ6Hii5AV8LIP0u5++ca7mq\nqiZVVU0ODg5VfSu1go2uBYA8ZyiEEEIIIYSotGpNDBVFaagoim3x10AwcBiIA4rfLDoC+Lbo6zjg\njaK3k3YErhYtOf0/IFhRlKeK3mAaXHRO3EG2rBBCCCGEePJER0dLtVA8lOp+xrAZsKnojUj1gC9U\nVf2XoijJwFeKorwJnAMGFrXfAvQGTgM3gJEAqqpeURTlv4HkonYzVVW9Us2x10q6ooqhbFkhhBBC\nCCGEqKxqTQxVVf0J8Crn/GXgpXLOq8D4Csb6DPisqmOsa6ysnsbSsoEsJRVCCCGEEEJUWk1tVyGq\niaIo2NjIlhVCCCGEEEKIypPEsA7S6VrKUlIhhBBCCCFEpUliWAfpbFqSk/sL1b0ViRBCCCHEk2b2\n7Nm4u7vj6emJwWBg3759FbZNSUlh0qRJAMyYMYPIyMgybaZPn67tebhw4UJu3LhR4XiJiYn4+vri\n6uqKq6sry5cvv2e8ZrOZLVu2aMdxcXHMnTv3nv1K6t27N5mZmffVp7Kio6OZMGFCpdrOmTPnoeYq\n+f24m06dOt3XuEuXLuXzzz9/0LAeG49ig3vxiNnoWlBQcIP8/CvUr/90TYcjhBBCCFEn7Nmzh82b\nN3PgwAGsra3JyMggLy+vwvYmkwmT6e5byM2cOVP7euHChQwfPpwGDcruRf3bb78xdOhQYmNjMRqN\nZGRkEBISwnPPPUefPn0qHN9sNpOSkkLv3r0BCAsLIyws7F63WkrJxLImqKqKqqrMmTOHDz/88IHH\nqcz3A+CHH364r3EjIiIeNKTHilQM6yDZskIIIYQQoupduHABe3t7rK2tAbC3t6d58+YAJCcn06lT\nJ7y8vPD19SUrK4udO3fSt2/fMuOsWLGCXr16kZOTQ3h4OBs2bGDRokWkp6cTGBhIYGBgmT5Lliwh\nPDwco9GozT1//nyt+hceHk5ERARdu3albdu2bN68mby8PKZPn05MTAwGg4GYmJhSFbrw8HDGjRtH\nYGAgzs7O7Nq1i1GjRuHm5kZ4eLg2d+vWrcnIyGDp0qUYDAYMBgNOTk5anPHx8fj5+WE0Ghk4cCDZ\n2dll4k9OTsbT0xM/Pz+mTJmCh4eHdu2XX36hZ8+euLi48PHHHwOQlpaGm5sbb731FkajkTfffJOc\nnBwMBgPDhg0rM36jRo2YOnUq7du3p3v37uzfv5+AgACcnZ2Ji4sDKPX9mDFjBqNGjdLaLFq0qNRY\nxe39/f0ZNGgQbdu2Zdq0aaxbtw5fX1/0ej1nzpzRxoqMjCQ9PV37fAwGA5aWlpw9e5ZLly7xyiuv\n4OPjg4+PD0lJSWXifxxIxbAO0uluJ4a5Ob9g17jMS2GFEEIIIWq9rVu38ttvv1XpmM8++yy9evWq\n8HpwcDAzZ86kbdu2dO/encGDB+Pv709eXh6DBw8mJiYGHx8frl27hk6nK3eMqKgo4uPjiY2N1RJM\ngEmTJrFgwQISEhKwt7cv0+/IkSOMGDGi1DmTycSRI0e047S0NHbt2sWZM2cIDAzk9OnTzJw5k5SU\nFKKiooDbSzdL+uOPP9ixYwdxcXGEhoaSlJTEypUr8fHxwWw2YzAYtLYRERFERESQn59PUFAQ7777\nLhkZGcyaNYvt27fTsGFD5s2bx4IFC5g+fXqpeUaOHMny5cvp1KkT06ZNK3Vt//79HD58mAYNGuDj\n40OfPn2wt7fnxIkTrFq1ir///e8AfP3115jN5nI/1+vXrxMQEMC8efPo378/f/7zn9m2bRtHjx5l\nxIgR5VZJjx8/TkJCAllZWbi4uDBu3DisrKxKtfnxxx85duwYTZs2xdnZmdGjR7N//37+9re/sXjx\nYhYuXKi1bd68uRbfkiVL2LVrF61atWLo0KFMnjyZLl26cO7cOUJCQjh27Fi591GTJDGsg2xsbu9l\nKFtWCCGEEEJUnUaNGpGamsr3339PQkICgwcPZu7cubRv3x5HR0d8fHwAaNy4cbn916xZQ4sWLYiN\njS2TgNyLqqoU7Q1eSslzgwYNwsLCghdffBFnZ2eOHz9+z3FDQ0NRFAW9Xk+zZs3Q6/UAuLu7k5aW\nVioxLPb2228TFBREaGgomzdv5ujRo3Tu3BmAvLw8/Pz8SrXPzMwkKytLe3Zv6NChbN68Wbveo0cP\nnn769uNPAwYMIDExkX79+tGqVSs6dux4z3sAqF+/Pj179gRAr9djbW2NlZUVer2etLS0cvv06dMH\na2trrK2teeaZZ7h48SItWrQo1cbHxwdHR0cA2rRpQ3BwsDZHQkJCueMWJ9fff/89ANu3b+fo0aPa\n9WvXrpGVlYWtrW2l7u1RkcSwDqpXryFWVk3JyZXEUAghhBB1090qe9XJ0tKSgIAAAgIC0Ov1rF69\nGqPRWG7SdicPDw/MZjPnz5/Hycnprm03bdqkLatcuXIl7u7upKSklKp8paam0q5dO+34zhgqE1Nx\n1dLCwqJUBdPCwoJbt26VaR8dHc3Zs2e1CqSqqvTo0YP169dXOMe9XohYUdwNGza8Z/zFrKystH4l\n76Wi+wBK3a+lpWW57e78TO417oULF3jzzTeJi4vTlqQWFhayZ8+eCqvIjwt5xrCOur1lhTxjKIQQ\nQghRVU6cOMGpU6e0Y7PZTKtWrXB1dSU9PZ3k5GQAsrKyyk0avL29WbZsGWFhYaSnp5e5bmtrS1ZW\nFgD9+/fHbDZjNpsxmUyMHz+e6Ohobani5cuXmTp1Ku+//77W/+uvv6awsJAzZ87w008/4eLiUmrM\nh5WamkpkZCRr167FwuJ2GtGxY0eSkpI4ffo0ADdu3ODkyZOl+j311FPY2tqyd+9eAL788stS17dt\n28aVK1fIyckhNjZWqz7eycrKivz8/Cq5l+qQn5/PoEGDmDdvHm3bttXOBwcHa4k0UOFy2JomiWEd\npbNpKUtJhRBCCCGqUHZ2NiNGjKBdu3Z4enpy9OhRZsyYQf369YmJiWHixIl4eXnRo0cPcnNzyx2j\nS5cuREZG0qdPHzIyMkpdGzt2LL169Sr35TOOjo6sXbuWMWPG4OrqSqdOnRg1ahSh/5+9Ow+Pqrz7\nP/65Z7LNHMg6CfsOKrKFTXBBwIVqxR1EtKX41PLT1upTq63Wutdq1dbl0UfbWgQ3oNXHDW21reJS\ntQqIVAEVBAGDkI0tk3Xm/v0xSQxbSMJMzmTm/bquuSZzzpxzPknrdfn1Xr6nn974ncMPP1wTJ07U\nqaeeqocfflgZGRmaPHmyVq1a1bj5zKF44IEHVFZWpsmTJ6uwsFAXX3yx8vPzNW/ePM2cOVPDhw/X\n+PHj9zuF9U9/+pPmzJmjo48+WtZaZWVl7fE3+e53v6vCwkKde+65B9w5dM6cORo+fPh+N5+JB++8\n844++OAD3XjjjY0b0BQVFen+++/X0qVLNXz4cB155JF6+OGH3Y66XyZRe92NGTPGLl261O0Yrlm7\n7m5t3PhHTZ60SsZ43Y4DAABwyFavXq3Bgwe7HSMuzZ49W1OnTtW0adPcjrJfu3fvbpxaeccdd2jL\nli267777XE6VWPb3z4cxZpm19uA9OsQaw4Tly+gpa+tUVfW1fL4ebscBAABAEnvppZd0++23q66u\nTn369Nlnd1S4j8IwQQqgEbIAACAASURBVDW0rKis2khhCAAAkODivdCaMWOGZsyY4XYMNIM1hgnq\nm16GbEADAAAAoHkUhgkqPb2bJA8tKwAAAAAcFIVhgvJ4UpWR0Z0RQwAAAAAHRWGYwHwZPVVZudHt\nGAAAAADiHIVhAsvw9VJlFSOGAAAA0bJ161ZdcMEF6t+/v0aPHq2jjz5azz77rJYsWaKsrCyNHDlS\ngwcP1s0333zQez333HMaPny4jjjiCA0bNkzPPffcQa9ZsmSJ3nnnnWj8KsAeKAwTmC+jp2pqihUK\nVbodBQAAoMOz1uqss87S8ccfry+++ELLli3TwoULtXlz5D/ET5gwQR9++KGWLl2qJ554QsuWLTvg\nvT766CNdddVVev7557VmzRq98MILuuqqq7Ry5cpmM1AYIlYoDBOYz9dbkhg1BAAAiILXXntNaWlp\nuuSSSxqP9enTRz/+8Y/3+J7jOBo9erTWrVunCRMmaMWKFY3njj32WK1cuVJ33323fvGLX6hfv36S\npH79+unaa6/VXXfdJUmaNGmS/vu//1vHHHOMhg4dqvfff18bNmzQww8/rHvuuUeFhYV666232uG3\nRrKgj2EC8/l6Soq0rOjkDHI5DQAAQPR89tmt2rV7dVTv2bnTYB122PUHPP/JJ59o1KhRB71PaWmp\n3nvvPV1//fW6+OKLNW/ePN1777367LPPVF1dreHDh+uTTz7RVVddtcd1Y8aM0YMPPtj4uaKiQu+8\n847efPNN/dd//Zc+/vhjXXLJJerUqdM+1wKHihHDBJaR0dDknpYVAAAA0fajH/1II0aM0NixYyVJ\nb731lkaOHKkpU6bommuu0ZAhQzR9+nQtXrxYtbW1mjt3rmbPni0pMi3VGLPH/fY+NnPmTEnS8ccf\nr507d2r79u3t84shKTFimMDS0gLyeDJUWUlhCAAAEktzI3uxMmTIED3zzDONnx988EGVlJRozJgx\nkiJrDBcvXrzHNX6/XyeffLKef/55/fnPf9bSpUsb77V06VINHz688bvLly/XkUce2fh578Jx789A\nNDFimMCMMfL5eqmKwhAAAOCQnXDCCaqqqtJDDz3UeCwYDB70uosvvliXX365xo4dq9zcXEnSVVdd\npdtvv10bNmyQJG3YsEG//vWv9dOf/rTxukWLFkmS3n77bWVlZSkrK0udO3fWrl27ovhbARGMGCa4\njIyebD4DAAAQBcYYPffcc/rJT36iO++8U/n5+XIcR7/5zW+avW706NHKzMzURRdd1HissLBQv/nN\nb3T66aertrZWqampuvPOO1VYWNj4nZycHB1zzDHauXOn5s6dK0k6/fTTNW3aND3//PP6n//5H02Y\nMCE2vyySDoVhgvP5emn79g/2O48dAAAArdOtWzctXLhwv+cmTZq03+NFRUUKh8OaMmXKHsfPOecc\nnXPOOQd81rnnnqvbb799j2OHHXbYQVtaAG3BVNIE58vopVBot+rqWKwMAADQ3h577DGNGzdOt912\nmzwe/tUb8YsRwwTX0LKisnKTUlNzXE4DAACQXGbNmqVZs2a1+rolS5ZEPwzQDP6zRYL7pmUF6wwB\nAAAA7B+FYYJrOmIIAAAAAPtDYZjgUlI6KzU1h5YVAAAAAA6IwjAJ0LICAAAAQHMoDJOAz9eLqaQA\nAABR4PV6VVhY2Pi644472nSfvn37qqSkpNnvzJs3T0VFRY2fL774Yq1atapNz4uFK664Qj169FA4\nHG48Nm/ePF122WVRe8YxxxwjSdqwYYOeeuqpmDwnHA7r8ssv19ChQzVs2DCNHTtW69evj8q992fD\nhg0aOnRozO7fVuxKmgR8Gb1UXPx3WRuSMV634wAAAHRYPp9PK1asaJdnzZs3T0OHDlX37t0lSY88\n8khMn1dXV6eUlJaVB+FwWM8++6x69eqlN99884A9HNsqFArJ6/XqnXfekfRNYXjBBRdE9TmStGjR\nIhUVFWnlypXyeDzavHmzHMc55Pu25u8ZDxgxTAIZvp6ytlbV1VvdjgIAAJBw/vrXv+q8885r/Lxk\nyRKdfvrpkqQFCxZo2LBhGjp0qH7+85/vc+3eo0d33323brrpJj399NNaunSpLrzwQhUWFqqyslKT\nJk3S0qVLm71vp06ddN1112nEiBEaP368tm6N/Pvfiy++qHHjxmnkyJE66aSTGo/fdNNNmjNnjqZM\nmaJZs2ZpwoQJexS+xx57rFauXLlP7tdff11Dhw7VpZdeqgULFuz377Ju3TqNHz9eY8eO1Q033KBO\nnTpJkqy1uvrqqxtH6BYtWtT4d5s8ebIuuOACDRs2rPH3kaRrrrlGb731lgoLC3XPPfdIkoqKinTK\nKado0KBB+tnPfrbH3+DnP/+5Ro8erZNOOknvv/++Jk2apP79++uFF17YJ+eWLVvUrVu3xj6TPXv2\nVE5OpM3bq6++qqOPPlqjRo3S9OnTtXv3bknSLbfcorFjx2ro0KGaM2eOrLWSpEmTJukXv/iFJk6c\nqPvuu09bt27V2WefrREjRmjEiBGNhW4oFNIPfvADDRkyRFOmTFFlZeV+/4btylqbkK/Ro0dbRJSU\nvmX/8c/+tqzs325HAQAAaLNVq1Y1/vzLzzbZs5Z/FtXXLz/bdNAMHo/HjhgxovG1cOFCW1tba3v1\n6mV3795trbX2kksusY8//rj96quvbK9evey2bdtsbW2tnTx5sn322Wettdb26dPHFhcX2/Xr19sh\nQ4Y03v+uu+6yN954o7XW2okTJ9oPPvig8VzD5+buK8m+8MIL1lprr776anvrrbdaa60tKyuz4XDY\nWmvtH//4R3vllVdaa6298cYb7ahRo2wwGLTWWjtv3jx7xRVXWGut/fTTT+2B/p36+9//vn3sscfs\njh07bPfu3W1NTY211tpHH33U/uhHP7LWWnvaaafZp556ylpr7UMPPWQdx7HWWvv000/bk046ydbV\n1dmvv/7a9urVyxYVFdnXX3/d+v1++8UXXzQ+p+Ga119/3Z522mmNxx999FHbr18/u337dltZWWl7\n9+5tN27c2Pg3ePnll6211p511ln25JNPtjU1NXbFihV2xIgR+/wumzZtsn369LEjRoywV155pV2+\nfLm11tri4mI7YcKExv9d77jjDnvzzTdba60tLS1tvP473/lO49984sSJ9tJLL208d95559l77rnH\nWmttXV2d3b59u12/fr31er32ww8/tNZaO336dPv444/v9+/cGk3/+WggaaltYf3EiGES8GXUt6yo\n2uhyEgAAgI6tYSppw2vGjBlKSUnRKaecohdffFF1dXV66aWXdOaZZ+qDDz7QpEmTlJ+fr5SUFF14\n4YV68803DzlDc/dNS0vT1KlTJUmjR4/Whg0bJEmbN2/Wt771LQ0bNkx33XWXPvnkk8b7nXHGGfL5\nfJKk6dOna/HixaqtrdXcuXM1e/bsfZ5fU1Ojl19+WWeddZYyMzM1btw4vfrqq/t8791339X06dMl\naY8poG+//bZmzpwpr9erLl26aOLEifrggw8kSUcddZT69evXor/DiSeeqKysLGVkZOjII4/Ul19+\n2fg3OOWUUyRJw4YN08SJE5Wamqphw4Y1/j2a6tmzpz799FPdfvvt8ng8OvHEE/XPf/5T7733nlat\nWqVjjz1WhYWFmj9/fuMzXn/9dY0bN07Dhg3Ta6+9tsffc8aMGY0/v/baa7r00kslRdanZmVlSZL6\n9eunwsJCSXv+7+SmjjPpFW2WkdFdklFVJTuTAgCAxHDroJ5uR9jDjBkz9OCDDyo3N1djx45V586d\nG6cXNiclJWWPzVuqqqoOek1z901NTZUxRlKkEKmrq5Mk/fjHP9aVV16pM844Q0uWLNFNN93UeE3T\n9XR+v18nn3yynn/+ef35z39unLra1N/+9jft2LGjcbpnMBiU3+/XaaeddtDsB8vfmrV96enpjT83\n/V2b/g08Hk/j9zweT+N39nevU089Vaeeeqq6dOmi5557TlOmTNHJJ5+8z1TZqqoq/fCHP9TSpUvV\nq1cv3XTTTXv879aS32Hv7PEwlZQRwyTg8aQpPb2rKqvYmRQAACAWJk2apOXLl+uPf/xj44jRuHHj\n9MYbb6ikpEShUEgLFizQxIkT97iuS5cu2rZtm0pLS1VdXa3Fixc3nuvcubN27dq1z7Nact+97dix\nQz169JAkzZ8/v9nvXnzxxbr88ss1duxY5ebm7nN+wYIFeuSRR7RhwwZt2LBB69ev16uvvqpgMLjH\n98aPH69nnnlGkrRw4cLG48cff7wWLVqkUCik4uJivfnmmzrqqKOazXSgv0U0LF++vHH313A4rJUr\nV6pPnz4aP368/vWvf2nt2rWSIgXwZ5991lgEBgIB7d69W08//fQB733iiSfqoYcekhRZV7hz586Y\n/A7RQGGYJHy+3rSsAAAAOESVlZV7tKu45pprJEVGfaZOnaq//vWvjVM5u3Xrpttvv12TJ0/WiBEj\nNGrUKJ155pl73C81NVU33HCDxo0bp6lTp+qII45oPDd79mxdcskljZvPNGjJffd20003afr06Zow\nYYICgUCz3x09erQyMzN10UUX7XMuGAzqlVde2WN00HEcHXfccXrxxRf3+O69996r3/3udzrqqKO0\nZcuWxmmUZ599toYPH64RI0bohBNO0J133qmuXbs2m2n48OFKSUnRiBEjGjefiZZt27bp9NNP19Ch\nQxufc9lllyk/P1/z5s3TzJkzNXz4cI0fP15r1qxRdna2fvCDH2jYsGE666yzNHbs2APe+7777tPr\nr7+uYcOGafTo0XtMOY03piVD3B3RmDFj7P6GvpPVqlU/U1nZ2zruuHfcjgIAANAmq1ev1uDBg92O\nkfCKioo0adIkrVmzpnGnzrYIBoPy+XwyxmjhwoVasGCBnn/++SgmRVP7++fDGLPMWjumJdezxjBJ\nZPh6qbpmq0Khanm96Qe/AAAAAEnnscce03XXXaff/e53h1QUStKyZct02WWXyVqr7OxszZ07N0op\nEQsUhknC5+slSaqq+kqO09/lNAAAAIhHs2bN0qxZs6JyrwkTJuijjz6Kyr0Qe6wxTBK0rAAAAABw\nIBSGScLv7ytJCgbXuxsEAAAAQNyhMEwSqal5Sk3NUUXFWrejAAAAAIgzFIZJwhgjv38AhSEAAACA\nfbD5TBJxnIHatu1vstbKGON2HAAAgA7H6/Vq2LBhstbK6/XqgQceUOfOnfXd735XkrRx40ZlZWUp\nKytLgUBAjzzyiAYPHqzDDz9c1lo5jqNHH31Uhx9+uMu/CbAnCsMk4jgDVVe3XbW1pUpLa76xKQAA\nAPbl8/m0YsUKSdIrr7yia6+9Vm+88UbjsdmzZ2vq1KmaNm2aJGnDhg0aMGBA4/nf//73+vWvf635\n8+e78wsAB8BU0iTi+AdKkioq1rmcBAAAoOPbuXOncnJyYn4N0B4YMUwijtNQGK5VTs44l9MAAAC0\n3c0vfqJVRTujes8ju2fqxtOHNPudyspKFRYWqqqqSlu2bNFrr7120PuuW7dOhYWF2rVrl4LBoP79\n739HKzIQNYwYJpH09K7yejupIsgGNAAAAG3RMJV0zZo1+tvf/qZZs2bJWtvsNQ1TSdetW6d7771X\nc+bMaae0QMsxYphEjDFyHHYmBQAAHd/BRvbaw9FHH62SkhIVFxeroKCgRdecccYZuuiii2KcDGg9\nRgyTjEPLCgAAgKhYs2aNQqGQ8vLyWnzN22+/rQEDBsQwFdA2jBgmGccZqC1f/59qa3cqNTXT7TgA\nAAAdSsMaQ0my1mr+/Pnyer3NXtOwxtBaq7S0ND3yyCPtERVoFQrDJOOv34AmGFyrrKxRLqcBAADo\nWEKhULPn582bt8fnvn37qrKyMoaJgOhgKmmSoWUFAAAAgL1RGCYZn6+nPJ50VVR87nYUAAAAAHGC\nwjDJGOOV399fFUFGDAEAQMdzsNYQQDKKxj8XFIZJyHEGsjMpAADocDIyMlRaWkpxCDRhrVVpaaky\nMjIO6T5sPpOEHP8Abd36okKhoLxev9txAAAAWqRnz57avHmziouL3Y4CxJWMjAz17NnzkO5BYZiE\nHGeQJKki+IUyOw91OQ0AAEDLpKamql+/fm7HABISU0mTkN+JNFVlOikAAAAAicIwKfl9fWRMioIU\nhgAAAABEYZiUPJ40+Xx9GDEEAAAAIInCMGk5zkBaVgAAAACQRGGYtBxnoCorv1Q4XO12FAAAAAAu\nozBMUo5/oKwNKRjc4HYUAAAAAC6jMExSjjNQkphOCgAAAIDCMFn5/f0lGTagAQAAAEBhmKy83gz5\nMnpRGAIAAACgMExmfmcAvQwBAAAAUBgmM8cZqGDleoXDdW5HAQAAAOAiCsMk5jgDFQ7XqKpqk9tR\nAAAAALiIwjCJOf76nUmZTgoAAAAkNQrDJOY4AyRJFRW0rAAAAACSGYVhEktJ6az09K6qCH7udhQA\nAAAALqIwTHKOfyAjhgAAAECSozBMcn5ngILBdbI27HYUAAAAAC6hMExyjjNQoVBQ1dVfux0FAAAA\ngEsoDJOc4wySJFVUsM4QAAAASFYUhknO8TfsTErLCgAAACBZURgmubS0XKWm5lIYAgAAAEmMwhBy\nnIGqCFIYAgAAAMmKwhCRwrBinay1bkcBAAAA4AIKQ8jxD1Bd3Q7V1JS4HQUAAACACygM8c3OpEwn\nBQAAAJIShSHkOAMlsTMpAAAAkKwoDKG0tAJ5vZ0oDAEAAIAkRWEIGWPkOIMUpDAEAAAAkhKFISRJ\njjOANYYAAABAkqIwhKTIOsOamhLV1m53OwoAAACAdkZhCEmS42cDGgAAACBZURhCUpOdSYPrXE4C\nAAAAoL1RGEKSlJHRQx5PBiOGAAAAQBKiMIQkyRiPHP8AVVR87nYUAAAAAO2MwhCNHGegghVMJQUA\nAACSTbsUhsYYrzHmQ2PM4vrPbxljVtS/iowxz9Ufn2SM2dHk3A1N7nGKMeZTY8xaY8w17ZE72fid\nAaqqLlJdXYXbUQAAAAC0o5R2es4VklZLypQka+2EhhPGmGckPd/ku29Za6c2vdgY45X0oKSTJW2W\n9IEx5gVr7apYB08mDRvQBIPrlJk53OU0AAAAANpLzEcMjTE9JZ0m6ZH9nOss6QRJzx3kNkdJWmut\n/cJaWyNpoaQzo5012dGyAgAAAEhO7TGV9F5JP5MU3s+5syX901q7s8mxo40xHxlj/mqMGVJ/rIek\nTU2+s7n+GKLI5+stY1JpWQEAAAAkmZgWhsaYqZK2WWuXHeArMyUtaPJ5uaQ+1toRkv5H34wkmv1c\na/fzvDnGmKXGmKXFxcWHkDw5eTyp8vv7MmIIAAAAJJlYjxgeK+kMY8wGRaZ/nmCMeUKSjDF5ikwR\nfanhy9bandba3fU/vywp1RgTUGSEsFeT+/aUVLT3w6y1f7DWjrHWjsnPz4/Rr5TYHP9AWlYAAAAA\nSSamhaG19lprbU9rbV9J50t6zVr7nfrT0yUtttZWNXzfGNPVGGPqfz6qPl+ppA8kDTLG9DPGpNXf\n64VYZk9WjjNQlZWbFApVux0FAAAAQDtpr11J9+d8SXfsdWyapEuNMXWSKiWdb621kuqMMZdJekWS\nV9Jca+0n7Zo2SfidAZLCClauV+dOR7gdBwAAAEA7aLfC0Fq7RNKSJp8n7ec7D0h64ADXvyzp5dik\nQwPHGSRJClaspTAEAAAAkkS7NLhHx+H39ZPkYQMaAAAAIIlQGGIPXm+6fL5etKwAAAAAkgiFIfbh\nOIPYmRQAAABIIhSG2IfjH6BgcIPC4Tq3owAAAABoBxSG2IfjDJS1taqs3Oh2FAAAAADtgMIQ+3Cc\ngZKkiiDTSQEAAIBkQGGIffj9/SVJwQo2oAEAAACSAYUh9pGS0knp6d1oWQEAAAAkCQpD7JfjDFRF\nkMIQAAAASAYUhtgvxxmoiop1sjbsdhQAAAAAMUZhiP1y/AMVDlepquort6MAAAAAiDEKQ+xX486k\nrDMEAAAAEh6FIfbrm5YVFIYAAABAoqMwxH6lpmYrLS2gClpWAAAAAAmPwhAH5PcPYCopAAAAkAQo\nDHFAjjNIweBaWWvdjgIAAAAghigMcUCOM0B1dbtUU7PN7SgAAAAAYojCEAfk+NmZFAAAAEgGFIY4\nIMcZJInCEAAAAEh0FIY4oLS0gFJSMmlZAQAAACQ4CkMckDFGjjOQlhUAAABAgqMwRLMc/0BVVHzu\ndgwAAAAAMURhiGY5zkDV1pappqbM7SgAAAAAYoTCEM3yOwMkSRVBppMCAAAAiYrCEM1y/A07kzKd\nFAAAAEhUFIZoVkZGN3m9fgXZgAYAAABIWBSGaJYxHvn9/ellCAAAACQwCkMclOMMpJchAAAAkMAo\nDHFQjn+gqqu/Vl3dLrejAAAAAIgBCkMclOMMlCRVBL9wOQkAAACAWKAwxEE1FobsTAoAAAAkJApD\nHFRGRi8Zk8YGNAAAAECCSnE7AOKfx5Mix99PO3eu1M6d/3E7TqsZ45XjHCaPh/+7AwAAAPvDvymj\nRTp1Gqyvtz6nD5ae5XaUNhnQ/yr17Xup2zEAAACAuERhiBYZNOg6FXT5ttsx2uTLLx/WV0UL1KfP\nHBnjdTsOAAAAEHcoDNEiaWm5yg+c6HaMNgmHq/Xxxz9WadlbCuRNcjsOAAAAEHfYfAYJLz9wklJT\n81T01UK3owAAAABxicIQCc/jSVP3btNUUvqaqqu3uh0HAAAAiDsUhkgK3bvPkLUhFRX9xe0oAAAA\nQNyhMERS8Pv7KDfnWBUVLZK1IbfjAAAAAHGFwhBJo3uPmaqqLlJp2VtuRwEAAADiCoUhkkZ+4ESl\npubpq68WuB0FAAAAiCsUhkgaHk+aunefrtLS11VV/bXbcQAAAIC4QWGIpNK923myNqQtbEIDAAAA\nNKIwRFL5ZhOaP7MJDQAAAFCPwhBJp3ETmtI33Y4CAAAAxAUKQySdxk1oiha6HQUAAACICxSGSDps\nQgMAAADsicIQSYlNaAAAAIBvUBgiKUU2oTlOXxUtYhMaAAAAJD0KQySt7j3OV3X1FjahAQAAQNKj\nMETSyg+cpLS0AJvQAAAAIOlRGCJpeTyp6tZtmkpKXmMTGgAAACQ1CsP2FCyT1rwkVZS4nQT1enSf\nISmsIjahAQAAQBKjMGxPpWulhRdIRSvcToJ6Pl9v5eYcpyI2oQEAAEASozBsT/68yHuQEcN40qPH\nTDahAQAAQFKjMGxPTiDyXlHsbg7sIRA4kU1oAAAAkNQoDNtTeqbkSWWNYZyJbEIzPbIJTdUWt+MA\nAAAA7Y7CsD0ZExk1ZCpp3OnR/TxJYRVtedrtKAAAAEC7ozBsb05Aqih1OwX24vP1Vm7uBDahAQAA\nQFKiMGxvfkYM41WP7uezCQ0AAACSEoVhe3MCrDGMU99sQrPA7SgAAABAu6IwbG9+CsN49c0mNK+z\nCQ0AAACSCoVhe3PypJpdUl2120mwHz26z1BkE5q/uB0FAAAAaDcUhu3NyY+8M2oYl3y+XmxCAwAA\ngKRDYdje/PVN7tmAJm716D5T1dVfq7T0DbejAAAAAO2CwrC9OfWFISOGcSsQOKF+E5qFbkcBAAAA\n2gWFYXtrHDGkl2G82nMTmiK34wAAAAAxR2HY3py8yHtFsbs50KxvNqF52u0oAAAAQMxRGLa3jGzJ\nk8JU0jjXdBOacLjO7TgAAABATFEYtjdjItNJ2Xwm7jVsQlNW9qbbUQAAAICYSnE7QFJyAlIFawzj\nXWQTmnxt+PIh1daWy3jS5PWky+NJb/zZeNLk8aTLY9Lk8da/e9Ll8aTJmBQZY9z+NQAAAICDojB0\ngz+PEcMOwONJVY8eF2r9+nu1Y8fyttxBHk+6Onceovz8k5QfOEl+f7+o5wQAAAAOFYWhG5yAVPSh\n2ynQAv36XqYe3WcoHK5u8qpp/t3WKByKvIfqKlS+/d9au/YOrV17hxxnkAKBE5UfOEmZmSNkDLO5\nAQAA4D4KQzf4mUraURhjlJ5ecMj3qazcrJKSf6i45B/auPGP+vLLh5WWlq9A4ATlB05WTs4x8nrT\no5AYAAAAaD0KQzc4Aal6h1RXI6WkuZ0G7cDn66levWarV6/Zqq3dodLSJSou+Ye2bl2soqJF8nr9\nys2doPzASQoEJis1NcftyAAAAEgiFIZucJo0uc/s5m4WtLvU1Cx17XqmunY9U+FwtcrL31NxyT9U\nUvxPFRe/ImO8ysoao/zAScrJGS+Px53/eJCSkqX09HxXng0AAID2RWHoBn9DYVhCYZjkPJ505eVN\nVF7eRNnDbtauXR+ruPjvKi75hz5fe5ur2YxJ07HHvBGVqbQAAACIbxSGbmgYMaTJPZowxqPMzOHK\nzByuAQN+qsrKjdq58z+SbLtnqakp1Wef36LS0jfUvfv0dn8+AAAA2heFoRv8FIY4OJ+vt3y+3q48\n21qrLzf+gcIQAAAgSbBXvhucJlNJgThkjFFe7vEqLXtL4XCt23EAAAAQYxSGbsjIloyXEUPEtby8\nSQqFdmvHDnpuAgAAJDoKQzd4PJI/jxFDxLXc3GNkTIpKS5e4HQUAAAAxRmHoFifAiCHiWkpKZ2Vl\njVZp2RtuRwEAAECMURi6xZ8X6WMIxLFA3iTt3r1GVVVb3I4CAACAGKIwdIsTkCqK3U4BNCsvb6Ik\nqbTsTZeTAAAAIJYoDN3iZyop4p/jHKb09G4qLWU6KQAAQCKjMHSLE5CqtkshWgEgfhljlJc3UWVl\n/1I4XON2HAAAAMQIhaFbGnsZlrmbAziIQN7E+rYVy92OAgAAgBihMHSLnyb36Bhyco6RMakqoW0F\nAABAwqIwdEvDiCHrDBHnUlI6KTt7DOsMAQAAEhiFoVsaRgzZmRQdQF7eJFVUfKaqqiK3owAAACAG\nKAzd0rjGkF6GiH+NbSsYNQQAAEhIFIZu8eVIMkwlRYfg+AcqI6MH6wwBAAASFIWhWzxeyZ/H5jPo\nEBraVpSXv0vbasovKwAAIABJREFUCgAAgAREYegmhyb36Djy8iYpFKrQ9u1L3Y4CAACAKKMwdJOf\nwhAdR27O0TImTaVMJwUAAEg47VIYGmO8xpgPjTGL6z/PM8asN8asqH8V1h83xpj7jTFrjTErjTGj\nmtzje8aYz+tf32uP3DHnMJUUHYfX61dO9liVlr3pdhQAAABEWXuNGF4hafVex6621hbWv1bUHztV\n0qD61xxJD0mSMSZX0o2Sxkk6StKNxpicdkkeS4wYooOJtK34XJWVX7kdBQAAAFEU88LQGNNT0mmS\nHmnB18+U9JiNeE9StjGmm6RvSfq7tbbMWlsu6e+STolZ6Pbi5EuV5VI45HYSoEUa21aU0bYCAAAg\nkbTHiOG9kn4mKbzX8dvqp4veY4xJrz/WQ9KmJt/ZXH/sQMf3YIyZY4xZaoxZWlzcARrHOwFJVgqW\nuZ0EaBG/v78yMnqxzhAAACDBxLQwNMZMlbTNWrtsr1PXSjpC0lhJuZJ+3nDJfm5jmzm+5wFr/2Ct\nHWOtHZOfn9/24O3Fnxd5Z50hOoiGthVlZe8oHK52Ow4AAACiJNYjhsdKOsMYs0HSQkknGGOesNZu\nqZ8uWi3pUUXWDUqRkcBeTa7vKamomeMdmxOIvFd0gNFNoF4gb5LC4UqVb//A7SgAAACIkpgWhtba\na621Pa21fSWdL+k1a+136tcNyhhjJJ0l6eP6S16QNKt+d9LxknZYa7dIekXSFGNMTv2mM1Pqj3Vs\n/obCkBFDdBw5OePl8aSptJR1hgAAAIkixaXnPmmMyVdkiugKSZfUH39Z0rclrZUUlHSRJFlry4wx\nt0pqGKK4xVrb8RfmNYwYBkvdzQG0gtfrU3b2uEhhOOg6t+MAAAAgCtqtMLTWLpG0pP7nEw7wHSvp\nRwc4N1fS3BjFc4cvV5JhxBAdTl7eRH3++a9UWblJPl+vg18AAACAuNZefQyxP94UyZfD5jPocAJ5\nkySJ6aQAAAAJgsLQbQ5N7tHx+Hx95fP1VgltKwAAABIChaHb/BSG6Hga2laUl7+rUIi2FQAAAB0d\nhaHbnDymkqJDysubpHC4Stu3/9vtKAAAADhEFIZuY8QQHVRO9nh5POmsMwQAAEgAbrWrSEq7tn2l\nd1/4vUYVjFKqNzVycHWFtCYoLV4sGXPQe/hGFCqtZ48YJwUOzuvNUE7OeJWULtFhut7tOAAAADgE\nFIbt6NOVb6jX3X9Rsf6y15ls6Z2rW3QPb06OBvz1ZXmzs6MfEGilvNyJKi29RcHgl/L7+7gdBwAA\nAG1EYdiORh57tn541VOysrp/8v0yxkifvSK9+kvpgj9Luf2avb62aIs2zZmj4vvvV9cbbmin1MCB\n5eVNlD6XSsvekN8/y+04AAAAaCPWGLYjr8+nb038L72bulEr/aVK799f6YcNVnpmndID6ZHPzbw6\nHXesci64QOULF6lq1Sq3fx1Afn9f+Xx9VUrbCgAAgA6NwrCdfbvft5Wdnq0nVj8ROeAPRN5buAFN\n/uU/ljc7W1/fcqtsOByjlEDLBfImqbz8PYVCVW5HAQAAQBtRGLazjJQMTT9supZsWqJNuzZFGtxL\nLW5Z4c3MVMFPf6rKFSu047nnY5gUaJm8vIkKh6tVvv09t6MAAACgjSgMXTDj8BnyGq8WrFkg+fMi\nBytKW3x91tlnyTdihLbdfbdCO3fGKCXQMtnZ4+TxZNC2AgAAoAOjMHRBF6eLTu5zsp79/FlVhGuk\njOxWNbk3Ho+63HC9QuXlKr7/f2KYFDg4rzddOTlHs84QAACgA6MwdMmFR16o3bW79dza5yLTSSuK\nW3W9b8gQZZ8/Q+VPPaWqNWtilBJomby8iaqs3KhgcL3bUQAAANAGFIYuGZE/QsMCw7RgzQKF/Xkt\n3nymqYIrrpA3M1Nf3/orWWtjkBJomUDeRElSCaOGAAAAHRKFoYsuHHyhvtz5pd7OSJeCLV9j2MCb\nna38n16pymXLtPOFF2KQEGgZn6+3/P7+rDMEAADooCgMXTSlzxQV+Ar0hHa0acRQkrLPPVcZw4dr\n6113K7RrV5QTAi2XlzdJ27f/W6FQpdtRAAAA0EoUhi5K9aZqxhEz9G5dudbV7pDa0JfQeDzqev31\nCpWWquSBB2KQEmiZSNuKGpWX07YCAACgo6EwdNm0w6YpzXj1ZGe/VLW9TffwDRuq7OnTVfbEk6r6\n9LMoJwRaJid7rDweH9NJAQAAOiAKQ5flZuTqtJxherGTox3lbd/RMf8n/y1vp07aeuutbEQDV3g8\n6crNPUYlpUv4/yAAAEAHQ2EYBy7sM0VVHo+e+aLtG8ik5OQo/yc/UXDpUu1c/FIU0wEtl5c7UVVV\nm2hbAQAA0MFQGMaBw/NHaGxllRZs/qfqwnVtvk/29GnKGDJE2+68U6Hdu6OYEGiZvPq2FTS7BwAA\n6FgoDOOBE9CFO3fp65odem3ja22+jfF61fWG61VXXKySB/83igGBlvH5esrvH8g6QwAAgA6GwjAe\n+AOaFKxUj5ROenL1k4d0K9+IEcqadq7KHn9c1WvXRikg0HKBvIkq3/6+6uoq3I4CAACAFkpxOwAk\npaTJm56lmRk9dfe25VpVukpH5h3Z5tsVXHmldr36d339q9vU+9G5MsZEMSzQvLy8idq46U8qK39b\ngbxJbscBAABoEY8n3e0IrqIwjBdOns4O+/Rgik9Prn5Stx13W5tvlZKbq/z/vkJbb7lVu/72N2We\nemoUgwLNy84eI6/X0X/+80O3owAAALRYfv4pGjrkXnk8qW5HcYVJ1G3lx4wZY5cuXep2jJZ75GQp\n1afbDh+nZz5/Rq9Oe1UBX6DNt7OhkNZPn65QaZkGvPySPI4TxbBA80pL39SuXZ+4HQMAAKBFqmu2\nafPmx9S1y5k68si7ZUxirLgzxiyz1o5pyXcZMYwXTkDavlEXDL5ACz9dqL98+hddWnhpm29nvF51\nvf56fTnzApU8/LAKfvrTKIYFmpeXd7zy8o53OwYAAECLpafla90Xv1VKapYOG3RD0i3HanEpbCK+\nY4y5of5zb2PMUbGLlmScgFRRon5Z/XRcj+O06NNFqgnVHNIt/SNHKuvss1U6b76qv6CvHAAAAHAg\nffpcqt69vq/Nmx/T+g0PuB2n3bVmjPR/JR0taWb9512SHox6omTlD0jBUslafXfwd1VaVapXNrxy\nyLctuOqn8mRkaOuvfqVEnTYMAAAAHCpjjAYOvFbdup6r9evv1abNj7kdqV21pjAcZ639kaQqSbLW\nlktKi0mqZOQEpHCtVLVDR3c/Wv2z+uvxVY8fcjGXkpen/MsvV8U772jXq3+PUlgAAAAg8RhjdMQR\nv1YgcJI+++xmff31C25HajetWWNYa4zxSrKSZIzJlxSOSapk5K/faKaiRMaXrQsHX6hb37tVH277\nUKO6jDqkW+fMPF/bn35aW++4Q7amWlL7z5c2qanqNGmiPBkZ7f5sAAAAoKU8nhQNHXK/Vnx0kVat\nvlopKZ0VCEx2O1bMtaYwvF/Ss5IKjDG3SZom6ZcxSZWMnLzIe7BE0kBN7T9V9y6/V0+sfuKQC0OT\nkqKuN1yvjbMvUtHVPzv0rG3U7bbblH3uOa49HwAAAGgJrzddI4b/Xss/vFD/+fgyjSycr+zsFm3u\n2WG1uDC01j5pjFkm6URFhpzOstaujlmyZNNkxFCS/Kl+TRs0TY+tekxbdm9Rt07dDu32o0dr4BtL\nFNqx41CTtl5dnb44/QzVFW9r/2cDAAAAbZCS0lmFI+Zq2fLz9dHKizVq5AJ17jzY7Vgx06LC0EQa\neay01g6VtCa2kZKUkx95D5Y0Hjr/iPM1f9V8Lfh0ga4cfeUhPyIlN1cpubmHfJ+28DiO6srKXHk2\nAAAA0BZpaQGNLHxMS5dN14qPZmv0qEXy+/u6HSsmWrT5jLU2LOkjY0zvGOdJXs6eI4aS1L1Td53Y\n+0Q989kzCtYGXQoWHd6cHIXKt7sdAwAAAGiVjIzuGlk4X9aG9OGK76m6eqvbkWKiNbuSdpP0iTHm\nn8aYFxpesQqWdFLSpbTOexSGknTh4Au1s2anFn+x2KVg0eHNzVWIEUMAAAB0QI4zUIUj5qq2tlwf\nrpit2trEG/BoTWF4s6Spkm6R9NsmL0SLk7fHVFJJGlUwSoNzB+up1U916D6E3pxshcrL3Y4BAAAA\ntElm5nANH/aQgsEN+uijixUKdewZfXtrcWForX1DkfWFnetfq+uPIVr8gX1GDI0xunDwhVq3Y53e\n3fKuS8EOXUp2juq2UxgCAACg48rNPVZDh9yrHTs/0sr//FDhcI3bkaKmxYWhMeY8Se9Lmi7pPEn/\nNsZMi1WwpOQE9hkxlKRT+52q3IxcPbn6SRdCRUdkKimFIQAAADq2goJvafARt6ms7C19suoqWRty\nO1JUtGYq6XWSxlprv2etnSXpKEnXxyZWknICUkXpPofTvGk67/Dz9ObmN/Xlzi9dCHbovDk5slVV\nCldWuh0FAAAAOCTdu5+ngQN+rm3bXtKnn93UoZd8NWhNg3uPtbZpI7pSta6wxMH460cMrZWM2ePU\njMNn6JH/PKIb/nWDhgSGtOn2aZ40TTtsmnp27hmNtK2SkpsjSQqVlcnTo0e7Px8AAACIpj595qi2\ntlxfbvyDUlNzNKD/obeXc1NrCsO/GWNekbSg/vMMSX+NfqQk5gSkUI1UvVPKyNrjVMAX0AVHXKBn\nPn9Gn5Z/2qbbV9dVa9Gni/TL8b/Uaf1Pi0biFvPmRArDuvLtSqUwBAAAQAIYMOBnqq3drg0bHlRu\nzrHKyRnndqQ2a3FhaK292hhzjqTjJBlJf7DWPhuzZMnI36SX4V6FoSRdPfZqXT326jbfvmh3ka55\n6xpd89Y1evurt3XduOvUKa1Tm+/XGg2FITuTAgAAIFEYY3TEEb9Sbt7xys4+yu04h6Q1m8/0k/Sy\ntfZKa+1PFBlB7BurYEmpocl9cN91htHQvVN3zf3WXP2w8Id6ef3LmvbiNH1U/FFMnrW3bwpDehkC\nAAAgcRjjVZeCU2X2WgrW0bRmjeBfJIWbfA7VH0O0+PMi7xX77kwaLSmeFF064lLNO2WerLX63l+/\np99/9HuFwrHdTSmFEUMAAAAgbrWmMEyx1jY26qj/OS36kZKYkx9530/LimgbWTBST5/xtKb0naIH\nVjyg77/6fW3ZvSVmz/NkZkper+ooDAEAAIC405rCsNgYc0bDB2PMmZJiX8EkE6fJGsN20Dmts34z\n4Tf69XG/1urS1Tr3xXP1yoZXYvIs4/HIm51NL0MAAAAgDrWmMLxE0i+MMRuNMZsk/VzS/4tNrCSV\n6pNSnXYrDKXIgtnTB5yup09/Wn0z++qqN67SDf+6QcHaYNSf5c3JZiopAAAAEIdaXBhaa9dZa8dL\nOlLSkdbaY6y1a2MXLUk5ee0ylXRvvTJ7af6p8/WDYT/Qc2uf03mLz9MnpZ9E9RkpObmqY/MZAAAA\nIO60ZlfSK4wxmZIqJN1jjFlujJkSu2hJyh9o1xHDplI9qbp81OX607f+pKq6Kn3n5e9o7sdzFbbh\ng1/cAt6cHIXKt0flXgAAAACipzVTSf/LWrtT0hRJBZIuknRHTFIlMyfgyohhU2O7jtUzZzyjyb0m\n655l92jO3+doa8XWQ76vNzeHqaQAAABAHGpxg3tFmtpL0rclPWqt/ch09GYd8cjJl7aucjuFstKz\n9NuJv9Wza5/VHe/foXNfPFffH/p9+VP8bbpfqjdV4zI7KbR9u2w4LONpzX+TAAAAABBLrSkMlxlj\nXpXUT9K1xpjO2rOvIaLBX7/G0FrJ5brbGKNzBp2jkQUjdc1b1+h3y353SPe7L3yyuoXDCu3Y0djX\nEAAAAID7WlMYfl9SoaQvrLVBY0yeItNJJUnGmCHW2ujuVpKMnIBUVyXV7JbSO7udRpLUL6ufFpy2\nQGVVbds4xlqrk58+WSXpNeqmSJN7CkMAAAAgfrS4MLTWhiUtb/K5VFJpk688LmlU9KIlKX+TXoZx\nUhhKksd4FPAF2nx9ni9PxZXVksQ6QwAAACDORHOhF+sNo6GhyX2wtPnvdTAFvgJtSY30RqQwBAAA\nAOJLNAtDG8V7Ja+mI4YJpMBfoM3eHZKkujJ6GQIAAADxhK0h403jiGFiFYb5/nxtMJGCkF6GAAAA\nQHyJZmFYE8V7Ja+GwrCi2N0cUdbF30WldpeMz6cQI4YAAABAXGlxYWgivmOMuaH+c29jzFEN5621\n42MRMOmkOVKKLyGnkkqSsjMV2s4aQwAAACCetGbE8H8lHS1pZv3nXZIejHoiREYNE2zzmXx/viSp\nrrNfdWw+AwAAAMSV1vQxHGetHWWM+VCSrLXlxpi0GOVKbv68hBsx7OLvIkmqzkxXqIzCEAAAAIgn\nrRkxrDXGeFW/+6gxJl9SOCapkp2Tn5Cbz0hS0O+lXQUAAAAQZ1pTGN4v6VlJBcaY2yS9LenXMUmV\n7JyAVJFYU0k7p3aWL8WnHX4xlRQAAACIMy2eSmqtfdIYs0zSiYo0sz/LWrs6ZsmSmT8v4XYlNcao\nwF+g8vQ62WBQ4aoqeTIy3I4FAAAAQK0oDI0x90laZK1lw5lYcwJSXaVUUxHZpTRB5PvyVZz2tSQp\ntH27PF27upwIAAAAgNS6qaTLJf3SGLPWGHOXMWZMrEIlPX9DL8PEWmdY4C/Q16kVkkQvQwAAACCO\ntLgwtNbOt9Z+W9JRkj6T9BtjzOcxS5bMGprcJ9gGNAX+Am327pTEOkMAAAAgnrRmxLDBQElHSOor\naU1U0yDCiezgmWgb0BT4C1Tqq5MkWlYAAAAAcaTFhaExpmGE8BZJn0gaba09PWbJkpk/L/KegCOG\nu3yRn2lZAQAAAMSP1jS4Xy/paGttYlUr8ahhKmmC7Uxa4C/Q7gzJGqPQdgpDAAAAIF4ctDA0xhxh\nrV0j6X1JvY0xvZuet9Yuj1W4pJXWSfKmJ+TmM9ZjFOrsUx2bzwAAAABxoyUjhldKmiPpt/s5ZyWd\nENVEkIyJjBoGE2uNYb4vsnayulO6QuXbXU4DAAAAoMFBC0Nr7Zz6H0+11lY1PWeMoUN5rPjzEm7E\nMM2bppz0HAU7scYQAAAAiCet2ZX0nRYeQzQ4+Qm3+Ywk5fvztcsnhcqZSgoAAADEi5asMewqqYck\nnzFmpCRTfypTkj+G2ZKbE5BK17qdIuoK/AUqy9iiuq+YSgoAAADEi5asMfyWpNmSekr6XZPjuyT9\nIgaZIEn+QMJNJZWkLv4uKkmvUai8SjYclvG0pZUmAAAAgGhqyRrD+ZLmG2POtdY+0w6ZIElOnlRb\nIdVWSqk+t9NETb4/X5tSK6VQWOFdu+TNynI7EgAAAJD0WtzH0Fr7jDHmNElDJGU0OX5LLIIlPX9D\nL8MSKbuXu1miqMBfoE/qJyCHysspDAEAAIA40OJ5fMaYhyXNkPRjRdYZTpfUJ0a50NDkPsE2oCnw\nFWhn/QBoXRk7kwIAAADxoDULvI6x1s6SVG6tvVnS0ZISZygr3jiRnn+qSKxehgX+Au3yR/YvCm2n\nMAQAAADiQWsKw8r696AxprukWkn9oh8JkiJ9DCWpotjdHFFW4C/QzoappGW0rAAAAADiQYvXGEpa\nbIzJlnSXpOWSrKRHYpIKCTuVNCcjR5VOiqSQ6mhyDwAAAMSF1mw+c2v9j88YYxZLyrDW7ohNLCg9\nU/KkJlzLCo/xKDOrQHVpRQqV08sQAAAAiActaXB/TjPnZK39v+hGgiTJmMioYYKNGEqRlhVBZytT\nSQEAAIA40ZIRw9ObOWclURjGij+QcJvPSJEm97t8nyjEVFIAAAAgLrSkwf1F7REE+5GgI4YF/gKV\nZ7DGEAAAAIgXLV5jaIy5YX/HaXAfQ05AKl/vdoqoy/flRwrDssQbDQUAAAA6ota0q6ho8gpJOlVS\n3xhkQoMEnUra0LKCEUMAAAAgPrRmV9LfNv1sjLlb0gtRT4RvOHlSzS6prlpKSXc7TdQU+Au01G+k\niqDCNTXypKW5HQkAAABIaq0ZMdybX1L/aAXBfvjrexkmWMuKAn+BdvkiP9OyAgAAAHBfa9YY/keR\nXUglySspXxLrC2PJyY+8B0ukrB7uZomihqmkkhQqL1NqlwJ3AwEAAABJrsWFoaSpTX6uk7TVWlsX\n5TxoyknMEUMn1VFtZ5+kClpWAAAAAHGgNWsMvzTG5EjqVX9dl/oG98tjli7ZJehUUklKy8sThSEA\nAAAQH1ozlfRWSbMlrdM3U0qtpBOiHwuSIpvPSAnZyzAjr4ukjaorozAEAAAA3NaaqaTnSRpgra1p\n7UOMMV5JSyV9Za2daox5UtIYSbWS3pf0/6y1tcaYSZKel9TQvO//GvokGmNOkXSfIusbH7HW3tHa\nHB1ORrbkSUnIEcPMQHdJYsQQAAAAiAOt2ZX0Y0nZbXzOFZJWN/n8pKQjJA2T5JN0cZNzb1lrC+tf\nDUWhV9KDivROPFLSTGPMkW3M0nEYI/nzEnLEMNC5i3b5RJN7AAAAIA60ZsTwdkkfGmM+llTdcNBa\ne0ZzFxljeko6TdJtkq6sv+blJuffl9TzIM8+StJaa+0X9dcslHSmpFWtyN8xOfkJ2+R+l0+qLN3m\ndhQAAAAg6bWmMJwv6TeS/iMp3Irr7pX0M0md9z5hjEmV9F1FRhQbHG2M+UhSkaSrrLWfSOohaVOT\n72yWNK4VGTquBB0x7OLvop0+qbq02O0oAAAAQNJrTWFYYq29vzU3N8ZMlbTNWrusfv3g3v5X0pvW\n2rfqPy+X1Mdau9sY821Jz0kaJMns51q79wFjzBxJcySpd+/erYkav5yAVPSh2ymiLt+fryK/UV1Z\nmdtRAAAAgKTXmsJwmTHmdkkvaM+ppM21qzhW0hn1RV6GpExjzBPW2u8YY26UlC/p/zW5184mP79s\njPlfY0xAkRHCXk3u21OREcU9WGv/IOkPkjRmzJh9Cke37Syp1MrXNrfuog3HScX50p8/lyT1PCJH\nfYcHYpCufXXxd9FOv2Q37Tz4lwEAAADEVGsKw5H17+ObHGu2XYW19lpJ10pS/YjhVfVF4cWSviXp\nRGtt47RUY0xXSVuttdYYc5Qim+OUStouaZAxpp+krySdL+mCVmSPC5W7arX6nX3q2eaFekp1+dI7\nRaqrCWvTmrKEKAzzfHna5Tfy7qiQtVbG7G9QGAAAAEB7aE2D+8lRfO7Dkr6U9G59QdDQlmKapEuN\nMXWSKiWdb621kuqMMZdJekWRdhVz69cedihd+mXqB/dObN1FH/xJeulK6co1+uez5dq8JjHaO6R6\nUlXX2S9PaLfCu3fL23mfJagAAAAA2klrGtzfsL/jDS0lDsZau0TSkvqf9/tca+0Dkh44wLmXJb28\nv3MJzcmPvAdLlOZLV3Vlnbt5osiTky1pt0Ll5RSGAAAAgIta08ewoskrpEhPwb4xyISmnPppoxXF\nSvelqLYqpHA47pZPtklabp4kKcQGNAAAAICrWjOV9LdNPxtj7lZkIxrEkr+hMCxVmm+gJKmmsk4Z\nTqqLoaIj4/+zd+dhcp3lnfd/T9WpU3tVr2r1InW3bGuzrLaxsAFDAhgy4I0kYJklCRlmQmaGNyFD\nSAjDkEzCNrwJIQkQyEJYkryxRUjwjmPWgM2mGMsylhdhSZbUWlrd6r2Wrqrz/nGqW63NUktddeqc\n+n6ui6vUVdXVt61A9NP9PPfd0SVJKh0PxvFYAAAAwK+W0jE8VULSmuUqBGcx3zGcPaZows3xxYAc\nJ02t6JYkFUaDt6cRAAAA8JOl3DHcqRO7A8NyV02c1/1CXIRYi2TC0swx2W3ub1dQ7hm2ruiXJE0e\n3S//z1kFAAAA/Gsp6ypuWvTrkty1EsFIKI0sFJISbW7HsLfaMZwNxr/29rZezYWl0shhr0sBAAAA\nmtpSjpJ2SxpzHGef4zgHJcWMMdfWqC4slux0O4bxYHUMVyTdJff50SNelwIAAAA0taUEw09Lml70\n9Wz1OdRaol2aCd4dw65El6biUmmM4TMAAACAl5YSDE112bwkyXGcipZ2FBUXKtnhHiWNu5NIg9Ix\nzEazmkqG5ExMeF0KAAAA0NSWEgyfNcb8pjEmUv3POyU9W6vCsEiiQ5o5pkg8LCk4HUNjjObSMYUn\nZrwuBQAAAGhqSwmG/03SSyQdlHRA0rWS3l6LonCKZIeUH1dYZVnRcGA6hpJUyaRkT+W9LgMAAABo\naktZcH9U0hvP9rox5r2O43xkWarCyRLt7uPsmKKxcGCmkkqSaW1RLHdUztycTCTidTkAAABAU7qY\nBfenunUZPwuLJTvdx9ljshORwBwllaRIW5skqXScATQAAACAV5YzGJpl/Cwslqyuf58ZUTQerKOk\n8fYuSdLUyLDHlQAAAADNazmDoXPut+CCJOaD4THZ8WB1DFOdPZKkscN7PK4EAAAAaF50DP1gvmM4\nO+p2DAN0xzDb1SdJGj+y3+NKAAAAgOZ13sHQGHPdOZ770rJUhNPFWyUZt2OYiKiYD04wbF+5RpI0\nzVFSAAAAwDNL6Rh+4vmecxznwxdfDs4oFJYSbdUl927H0HGCcXJ3RbcbDAujIx5XAgAAADSvc66r\nMMa8WO7+wk5jzLsWvZSRFK5VYThFslOaGZGdtVQpOyrPVWTZ/v/Xn4hnNBMzKo6Nel0KAAAA0LTO\np2NoS0rJDZHpRf+ZlPSG2pWGkyQ6pJlRReNulg/SZNJc0pLGJ7wuAwAAAGha5+wYOo7zbUnfNsZ8\n3nGcfZJkjAlJSjmOM1nrAlGVbJeO7pKdcH/LirmSktmox0Utj2I6ptDEjNdlAAAAAE1rKXcMP2KM\nyRhjkpKekPSUMeZ3alQXTpXocIfPxKodwwBNJq1kU7Kncl6XAQAAADStpQTDjdUO4c9Luk/Sakm/\nXJOqcLpkh5Q7rmjM/S0L0i5D05JVfKakcqXsdSkAAABAU1pKMIwYYyJyg+GdjuPMiaX29ZPslOTI\nNu6RyyDyWsJsAAAgAElEQVTdMYy0tik9K43mGEADAAAAeGEpwfCvJO2VlJT078aYfrkDaFAPiXZJ\nUtQZlxSsjmGsY4XssjQy+pzXpQAAAABN6byDoeM4f+E4Tq/jODc4rn2SXlHD2rBYskOSZFfGJAXr\njmGqs0eSNHpoj8eVAAAAAM3pvIOhMabLGPNZY8z91a83SnprzSrDyRJuMIwUR2VCJlAdw2zXKknS\nxNH9HlcCAAAANKelHCX9vKQHJPVUv35a0m8td0E4i2rH0ORGZcfDgbpjOB8Mp0aGPa4EAAAAaE5L\nCYYdjuNsk1SRJMdxSpIYI1kv8Tb3ceaYonErUB3DaJsbevOjRz2uBAAAAGhOSwmGM8aYdlUnkRpj\nXiRpoiZV4XRhyw2Hs8dkx61AdQzDbW7onRtlKikAAADgBWsJ732XpLskrTHGPCSpU9IbalIVzizZ\nIc2MKJoIVscwlEqpHDaqjI97XQoAAADQlJYSDJ+Q9K+SZiVNSfqK3HuGqJdEhzQzKjtmaWIk53U1\ny8YYo2I6pvDEjNelAAAAAE1pKUdJvyhpvaQPS/qEpMsk/X0tisJZJNqk3PHAdQwlqZJJKjZdVL6U\n97oUAAAAoOkspWO4znGcoUVff9MYs2O5C8LzsFNScUp2R7DuGEqSWjJKjx3TyOyIVmVWeV0NAAAA\n0FSW0jH8cXXgjCTJGHOtpIeWvyScVTQlFaYVjVuay5dVqTheV7RsIm3tysxKR3NMJgUAAADq7Zwd\nQ2PMTrmTSCOSfsUY81z163659w5RL3ZKKk7Ljru/bcVcSbFkxOOilkesrVPpWenoLMEQAAAAqLfz\nOUp6U82rwPmxU1K5qGjUSApWMEyu6FEpL+2aOux1KQAAAEDTOWcwdBxnXz0KwXmIpiRJdmROkgJ1\nzzDR0aUpSeNH93tdCgAAANB0lnLHEF6z3WAYtYqSpOJscIJhuLVVkjQ9MuxxJQAAAEDzIRj6yXzH\nMFyQFKyOodXWJknKHTvicSUAAABA8yEY+omdliRFw+5y+yDtMpzvGM6NjXpcCQAAANB8CIZ+Yifd\nBzMrKVgdw3Cr2zGsjE/IcYKzhgMAAADwA4Khn8wfJdW0pKB1DFskSYmZkiaLkx5XAwAAADQXgqGf\nVIfPhMvTsuxQoDqGIdtWJRFVetZhlyEAAABQZwRDP4m6dwxVmFY0bgVqKqkkqSWrDEvuAQAAgLoj\nGPpJtWOo4pTsuBWoo6SSZLW2KZ0jGAIAAAD1RjD0EysqmbDbMUxYgTpKKkmxjk5lchwlBQAAAOqN\nYOgnxrgDaIozgewYRlrb1TIbIhgCAAAAdUYw9Bs7LRXdO4aFgN0xDLe2KpVzdDRHMAQAAADqiWDo\nN9GUVKjeMcwHLBi2tcqec3T8+GGvSwEAAACaCsHQb+yU2zFMuB3DIC2Dt1pbJUm50SMeVwIAAAA0\nF4Kh30RTUmFadtxSpeyoPFfxuqJlE25rkySVxo6rVAlWNxQAAABoZARDv7Hd4TPRuCVJgZpMGm5x\nO4bp2YqO5Y55XA0AAADQPAiGfmOnFvYYSgrUZNJwa4skKZOTRmZHPK4GAAAAaB4EQ79ZdJRUUqAm\nk1rVo6SZWZbcAwAAAPVEMPSb+eEzAewYhtJpKRxWOufoyCwDaAAAAIB6IRj6TTQllYuyo+400iDd\nMTShkMItLcrOhjSS4ygpAAAAUC8EQ7+xU5KkaLggKVgdQ0my2lrVUYxwlBQAAACoI4Kh31SDoR3O\nSwrWHUPJnUzamrcIhgAAAEAdEQz9JuoGw4gzIxMygesYhtvalJ51CIYAAABAHREM/cZOS5LM3Izs\neDhQdwwld2VFYqbEugoAAACgjgiGflPtGKowpWjcCl7HsLVV9nRR04VJzc7Nel0OAAAA0BQIhn5j\nJ93HorvLMGgdQ6u1TcZxlMqzyxAAAACoF4Kh31SHz6g4o2gimB1DSUrnxMoKAAAAoE4Ihn4Tde8Y\nqjAtO2YFbyppmxsMM7NiyT0AAABQJwRDv1noGE4FsmNozXcMZx0G0AAAAAB1QjD0GysqhSy3YxjA\nO4bzR0k7CjZ3DAEAAIA6IRj6jTFu17A4rWjc0ly+rErF8bqqZTMfDFfOJThKCgAAANQJwdCP7JRU\nnJEdtyQpUMdJQ7GYTCKhzmKMo6QAAABAnRAM/SiacvcYJoIXDCX3nmFrPsxRUgAAAKBOCIZ+VD1K\nOt8xDOI9w8ysdDR3VI4TnGOyAAAAQKMiGPpRNCUV3DuGUvA6huHWViVmSypVSjpeOO51OQAAAEDg\nEQz96NSOYcB2GVptrYpOFSSJ46QAAABAHRAM/Wh+Kun8HcN8sIJhuKVV4ckZSQRDAAAAoB4Ihn5U\nPUoa1I5huK1NJldQZM4hGAIAAAB1QDD0o1OOkgbvjmGLJCmTEysrAAAAgDogGPpRNCWViwo7JVl2\nKJBTSSWpr5xhyT0AAABQBwRDP7LT7mPRnUwatI6h1dYmSVpVynKUFAAAAKgDgqEfRVPuY2FKdtxS\nMWh3DKsdw5WlhEZyHCUFAAAAao1g6Ed20n0sziiasAJ7lLSzGKNjCAAAANQBwdCPFh0ltQN4lDSc\nyUihkFrzYY3lxzRXnvO6JAAAACDQCIZ+tOgoaTQevI6hCYcVzmaVmTWSxHFSAAAAoMYIhn5kV4Nh\nQDuGkrvLMDnj/nNxnBQAAACoLYKhHy10DKcX7hg6juNtTcss3Nqi6HRBEsEQAAAAqDWCoR8tdAxn\nZMctVUqOynMVb2taZlZrq6zJWUkEQwAAAKDWCIZ+tBAM3TuGkgJ3zzDc2iZnfFKRUERHcwRDAAAA\noJYIhn5kRaWQJRXcO4aSAnfPMNzaqvL4uLpinXQMAQAAgBojGPqRMW7XsHgiGAatY2i1tUrlslaZ\ndo3MMpUUAAAAqCWCoV9F0+7wmfmO4WywguH8kvvecpqOIQAAAFBjltcF4ALZSbdjmAhmx3A+GHaX\nUjpSOiLHcWSM8bgqAAAAIJjoGPpV9ShpNLB3DNskSV2FmHKlnGbmZjyuCAAAAAgugqFfRVMnDZ8J\nWsfQam2RJLUWwpJYWQEAAADUEsHQr6odw0g0LBMywbtj2OZ2DDPuKkNWVgAAAAA1RDD0q+rwGWOM\n7Hg4cEdJQ/G4TCym5GxFEh1DAAAAoJYIhn5lp6TilCQpGrcCd5RUcgfQRKcKkgiGAAAAQC0RDOuo\nUnH03WeOqViqXPyH2Ump6A5kseNW4DqGkmS1tkoTk0pHWFkBAAAA1BLBsI6+s/uYfumzP9A3nlyG\nkBNNSeWiVCoGumNYPj6uFYkVBEMAAACghgiGdXTdJe3qykS1bfv+i/8wO+0+FqcD2zEMt7WpfPy4\nViRWaGR2xOtyAAAAgMCqy4J7Y0xY0nZJBx3HuckYMyjpdkltkh6R9MuO4xSNMVFJX5R0taRRSbc5\njrO3+hnvlfRfJJUl/abjOA/Uo/blZIVDesPVffr0t36qwxN5rczGLvzDoin3sTDldgwDNpVUksKt\nLSqPjakz8UL98Nkf6uf++ee8LqnuelO9+tuf+1uFQ2GvSwEAAECA1SUYSnqnpF2SMtWvPyrp447j\n3G6M+YzcwPfp6uNxx3EuNca8sfq+24wxGyW9UdLlknokfc0Ys9ZxnHKd6l82t169Sp/65k/15UcO\n6B2vuPTCP8iuBsPitOxEJJAdQ6u1VZWZGb1x8PUKmZAcx/G6pLraP7Vf249s1+HZw+pN9XpdDgAA\nAAKs5sHQGNMn6UZJH5L0LmOMkfRKSW+uvuULkv6P3GD4uuqvJemfJX2y+v7XSbrdcZyCpD3GmN2S\nrpH0vVrXv9wGOpK6drBNX9q+X//j5ZfI/ce7AAvBcEZ2vEPFfFmViqNQ6AI/rwGFW91dhuutXn3g\nug94XE39fW/4e3r7g2/X8PQwwRAAAAA1VY87hn8m6XclzY/ibJc07jjOfIvrgKT5P/X2StovSdXX\nJ6rvX3j+DN/jO1u3rNLe0Vn9cM/YhX/IKUdJJQWuaxhubZUklY8f97gSb/Sl+iRJB6YOeFwJAAAA\ngq6mwdAYc5Oko47j/Mfip8/wVuccrz3f9yz+eW83xmw3xmwfGWncYSU3XNGtVNTSHRczhGbxUdKA\nBkOrrbmD4crkShkZHZw+6HUpAAAACLhadwyvk3SLMWav3GEzr5TbQWwxxswfY+2TNFz99QFJqySp\n+npW0tji58/wPQscx/lrx3G2OI6zpbOzc/n/aZZJ3A7r5qEe3bfzkKbycxf2IQsdw2lFE+6/yqCt\nrJjvGJbGLqKz6mORcERdyS6CIQAAAGqupsHQcZz3Oo7T5zjOgNzhMd9wHOctkr4p6Q3Vt71V0p3V\nX99V/VrV17/huBNH7pL0RmNMtDrR9DJJP6xl7bV22wtXKT9X0d07Dl3YB5yyrkIKXsfwxFHScY8r\n8U5vqlfD06f9HQgAAACwrLzaY/geuYNodsu9Q/jZ6vOfldReff5dkn5PkhzH+YmkbZKekPRVSe/w\n40TSxYb6slrblbrwnYZ20n0sTi/cMQzayopwNisZo3KTdgwlNxgemOaOIQAAAGqrXusq5DjOtyR9\nq/rrZ+VOFT31PXlJt57l+z8kd7JpIBhjtHXLKn3w3l16+siU1nall/YBVlQKWVJhUccwH6xgaCxL\n4UxG5fHmvGMoucFwZHZExXJRdtj2uhwAAAAElFcdQ0j6hat6FQkbbfvRBXQNjXEH0BQX3TEMWMdQ\nksJtbSo16fAZyQ2GjhyOkwIAAKCmCIYeak9F9aoNXfqXHx9UsVQ59zecKpo+uWMYsDuGknvPsDzW\n3MFQEsEQAAAANUUw9NjWLas0NlPUN548svRvtlNScUrhcEiWHQrcVFKpGgybuGPYl67uMuSeIQAA\nAGqIYOixn1nbqZWZmO64kOOk0ZRUmHZ/GbcC2TG02lpVOt68w2c6452yQhYrKwAAAFBTBEOPhUNG\nr7+6V99+ekSHJ/JL+2Y7KRVn3F/GLRWDeMewpVXl4+Nyt5Y0n3AorO5kN8EQAAAANUUwbAC3Xr1K\nFUf68iNLPC5YHT4jSdGEFcyjpG1tUqmkyvS016V4hl2GAAAAqDWCYQMY6Ejq2sE2bdu+f2mdserw\nGanaMQxiMGxtkaSm32VIxxAAAAC1RDBsELe9cJX2jc7qB3uWEICqw2ck945hEDuGVmurJDX1AJre\nVK/G8mOanZv1uhQAAAAEFMGwQbx2U7fSUUvbti9hCM2i4TOB7Ri2tUmSSqysoGsIAACAmiEYNoi4\nHdbNV/bovp2HNJmfO79vspNSZU4qFRfuGAZtSEuYjqF60+wyBAAAQG0RDBvI1i2rlJ+r6J4dh87v\nG+y0+1h0l9xXSo7Kc5XaFeiBcEs1GI43cTCsdgzZZQgAAIBaIRg2kKG+rNZ1pXXH+R4njabcx8KU\nonHL/WXAjpOGkgkZ21apiYfPtMfaFQvHOEoKAACAmiEYNhBjjG7d0qcd+8f11OGpc3+DXQ2G1Y6h\npMDdMzTGKNzq7jJsVsYY9aR6dHCKYAgAAIDaIBg2mF+4qleRsDm/ITQLHcMTwTBoHUPJHUDTzOsq\npOouwxnuGAIAAKA2CIYNpj0V1as2dOlff3xQxdI57gsu6hjOHyUtzgYvGFqtLU09fEaq7jKkYwgA\nAIAasbwuAKfb+sJVuv/xw/r6riN67RXdZ3/j4qOkLQHuGLa0Kv/U0xr74he9LsUzLzh0SBP7J3Qw\n/9eKWzGvy8HzSFxzjWLr13tdBgAAwJIQDBvQz1zWqZWZmLZt3//8wXDRUdJoQO8YSlJ03TpN3nef\njnz4I16X4pkBSf9Z0uTXPq5Jj2vB84tdcYUGv7TN6zIAAACWhGDYgMIhozdc3ae//NZuHZ7Ia2X2\nLB2iU9ZVSMHsGHb8+tvV+qY3SgHb0bgUT409pbc98DZ96KUf1stX/azX5eAsjn36Mxr7h39QJZ9X\nKEZnFwAA+AfBsEHduqVPn/zmbn35kQN6xysuPfObFq2riETDMiETyDuGkhTOZLwuwVO9sXWaiRsd\nMMcVzma9LgdnkXjhFo19/vPKP7FLiRdc5XU5AAAA543hMw2qvz2pF61p07bt+1WpnKVTZkWlUEQq\nTssYIzseDuRRUkgZO6NUJKUDUyy5b2TxzZslSbkdOzyuBAAAYGkIhg3stheu0r7RWf1w7/OsarCT\nUnFGkhSNW4E8Sgp3l2Fvqpcl9w3O6uxUpKdHuccIhgAAwF8Ihg3sNZd3Kx21tO1Hz7PTMJqWCtOS\nJDtu0TEMsN5Ur4an2WXY6OJXDtExBAAAvkMwbGBxO6xbruzRfY8f0mR+7sxvslNScUoSHcOg6027\nS+6dJh7C4wexzZtVGj6kuaNHvS4FAADgvBEMG9zWLauUn6vo7h1n6RRFU3QMm0Rvqle5Uk6j+VGv\nS8HziA8NSZLyjz3mcSUAAADnj2DY4Db3ZbV+ZVrbtp9l6IidkopuMIzGLRUCOpUUbjCUxD3DBhfb\nuFGKRDhOCgAAfIVg2OCMMbp1yyrt2D+upw5Pnf6GRcNn7AQdwyCbD4bcM2xsoWhUsfXrldtBxxAA\nAPgHwdAHfuGqXkXCRtu2n2EIzanDZ/Lls6+3gK/RMfSP+NCQco8/Lqdc9roUAACA80Iw9IG2pK1X\nb+zSv/74oIqlyskvnjJ8RpLm8nQNgygRSag12souQx+ID22WMzurwu7dXpcCAABwXgiGPrF1yyqN\nzRT19V1HTn7hlOEzkrhnGGDsMvSH+QE0uUe5ZwgAAPyBYOgTL7usU93ZmG4/daehnZIqc1KpoGjC\nDYZFOoaB1Ztml6EfRFatUri1lQE0AADANwiGPhEOGd32wlX69tMjenZk+sQLdsp9LEzTMWwCvSl3\nl2G5wt21RmaMUXzzZuUeIxgCAAB/IBj6yFuu7ZcdDukLD+898WS0GgyL0wt3DJlMGly9qV6VKiWN\n5Ea8LgXnEL9ySMXdP1V5ctLrUgAAAM6JYOgjnemobh7q0Zf+44AmcnPuk/aJYLjQMSQYBtb8ZFIG\n0DS+2ObNkqTczp0eVwIAAHBuBEOf+c/XDWi2WNaX5ldXRE8cJV24Y0gwDKyFXYYz3DNsdPHNmyVj\nlH+MfYYAAKDxEQx9ZlNvVtcMtunzD+9VueJIdtp9oTjFHcMm0JPqkSQdnGIyaaMLp9OyL1nDZFIA\nAOALBEMfett1AzpwPKcHnzhyUscwHA7JskN0DAPMDttaEV+hA9McJfWD+OYh5R57TI7jeF0KAADA\n8yIY+tCrN65UX2tcf/fQHslOuk8WZyS5uwy5YxhsvWl2GfpFfGhI5ePHNbd//7nfDAAA4CGCoQ+F\nQ0ZvffGAfrhnTLvGqp2IorvCIhq36BgGXG+KXYZ+ER+qDqBhnyEAAGhwBEOf2vrCVUrYYX3uR8fc\nJwpTkqodQ+4YBlpvqldHZo9orjLndSk4h+ill8okEsrtYAANAABobARDn8rGI3rD1X36ys5jckKR\nEx3DBB3DoOtN9ariVHR4+rDXpeAcjGUpvmkTHUMAANDwCIY+9qsvGVCxXFE+lJAKbjDkjmHwLewy\nZACNL8SHNiv/5JOqFApelwIAAHBWBEMfW9OZ0ivWdWq8FFG5wB3DZtGbru4y5J6hL8SHhqS5OeWf\neMLrUgAAAM6KYOhzb3vpoCYrMR0+OiKJjmEz6Ep0KWzCTCb1idhmBtAAAIDGRzD0uZde2qFyJKkj\nx0blOI6iCUuVkqPSXNnr0lAjVsjSyuRKjpL6RGTFClk93co/xgAaAADQuAiGPmeMUWtLm1Sc0o/2\nHpcdsySJyaQB15til6GfxIeGlHuUjiEAAGhcBMMAWNHRrkyooM89tEfRhBsMuWcYbOwy9Jf45iHN\nDQ+rNDLidSkAAABnRDAMgHAsrU57Tg/85LAmy+4RUu4ZBltvqlfHcseUL+W9LgXnIT40JEnKcZwU\nAAA0KIJhENgppUMFGWP09d3uwns6hsHGZFJ/iW3cIFkWx0kBAEDDIhgGQTSlUHFar920Uvc96S49\n545hsLHL0F9CsZhi69fTMQQAAA2LYBgEdkqqzOltL+rR6JwbCOkYBtt8MKRj6B/xoSHld+6UU2Zi\nMAAAaDwEwyCIpiVJV3VZWtuXlSTl6RgGWke8Q3bIZjKpj8SHNqsyO6vC7p96XQoAAMBpCIZBYKck\nSaY4rV952YAqcrT74KTHRaGWQiaknlQPwdBHFgbQ7HjU40oAAABORzAMAjvpPhZndMMVPZoLSY/v\nHfe2JtRcb6pXB6a4Y+gXkdWrFW5pUW4HA2gAAEDjIRgGQdTtGKowLdsKyY5bGj2e0+6jU97WhZrq\nTfVqeIY7hn5hjFFsaLPyDKABAAANiGAYBLZ7x1BFNwi2tcSUkNHnHtrrXU2oud50ryYKE5ouTntd\nCs5TfGhIhd0/VXma3zMAANBYCIZBsKhjKEmJZETdyai+/MgBjc8WPSwMtTQ/mZR7hv4R3zwkOY7y\nO3d6XQoAAMBJCIZBUB0+o2rnyI5b6rAjys9VdPuP9ntYGGqJXYb+E998hSRxzxAAADQcgmEQLATD\nGUlSNG5JpYpeckm7vvjwXpXKFQ+LQ62wy9B/wpmM7DVrlHuUYAgAABoLwTAIFo6SuncM7YSl4mxJ\nb7tuUMMTeT3wkyMeFodaaYm2KGElOErqM/GhIeUee0yO43hdCgAAwAKCYRBYUSkUOekoabFQ1ivW\ndqq/PaG/e2iPxwWiFowx6k336uAUwdBP4kNDKo+Nae4AR4ABAEDjIBgGRTS1MHwmGrckRyoVy3rr\niwf0H/uOa8d+9hoGUW+ylzuGPhMf2ixJHCcFAAANhWAYFHb6pI6hJBVyJd26pU+pqKXP0TUMpN50\nr4anhzmW6CPRyy6TiceVY58hAABoIATDoIimFu4YRhNuMCzmSkrHIrp1S5/u3XlIRyfzXlaIGuhN\n9Wq2NKvxAh1hvzCWpfjllzOZFAAANBSCYVDYyYWppPMdw2KuJEn61ZcMqFRx9A/f3+dZeagNdhn6\nU/zKIRV27VKlyJ5RAADQGAiGQWGnFo6SRuePks66wbC/Panr13fpH3/wnPJzZc9KxPJjl6E/xYaG\n5MzNqfDEE16XAgAAIIlgGByLhs8svmM4720vHdDoTFG3//A5T8pDbbDL0J/im4cksegeAAA0DoJh\nUCwaPrP4juG8F69p13WXtuvPvv6Mxmc5vhYUKTulbDTLygqfiXStkNXdrdwOBtAAAIDGQDAMikXD\nZ+xTjpJK7s6799+0UZO5Of3Z157xpETURm+qlzuGPhTfvJmOIQAAaBgEw6BYNHwmHA7JskMndQwl\naf3KjN50zWr9/ff3affRKS+qRA0QDP0pPjSkuYMHVTp2zOtSAAAACIaBYaekypxUKrhfxq2T7hjO\ne9er1yphh/WBe3bVu0LUSG/K3WVYcSpel4IliF9ZvWfIPkMAANAACIZBEU27j4UTk0lP7RhKUnsq\nqndef5m+/fSIvvnU0XpWiBrpTfWqWCnqWI7Ok5/ENm6ULEu5RzlOCgAAvEcwDAo75T4WT9wzXHzH\ncLFfefGA1nQk9cF7ntBcmS6T37HL0J9CsZhi69bRMQQAAA2BYBgU0WowLJyYTHqmjqEk2VZI77tx\ng346MqO//x5L7/1uYZfhFLsM/SY+tFn5xx6TU2a/KAAA8BbBMCjspPtYHUBztjuG8165foVedlmH\n/uxrT+v4DOsr/Kwn1SOJXYZ+FB8aUmV2VoWf/tTrUgAAQJOzvC6gmYxMFfT1XUcu6jOGVrVoQ3fm\n9Bfs6h3D6lHSs90xnDe/vuK1f/4dffxrT+uPXrfpouqCd2JWTB3xDo6S+lB86MSi+9jatR5XAwAA\nmhnBsI6eG5vV7/3Lzov6jA3dGd3/zped/sIpR0nP1TGUpLVdab3l2tX6xx88p196Ub/WdqUvqjZ4\nh5UV/hTp71c4m1Vuxw613nqr1+UAAIAmRjCso029GX3vva+84O//+INP6/7HD5/5xYXhMyfuGFZK\njkpzZVmR8Fk/83++aq2+8uOD+sA9T+iLb7tGxpgLrg/e6Un16LERhpj4jTFGsaHNyu/g9w4AAHiL\nYFhHUSus7mz8gr9/TWdKU/mSpgslpaKn/Nadsq7CjrmvF2ZLsrJnD4atSVu/9aq1+qN7ntA3njyq\n6zd0XXB98E5fqk//tvffVKqUZIX4r7WfxDcP6dh3vqvy9LTCqZTX5QAAgCbF8Bkf6c7GJEmHxnOn\nv3jKuopowg0Hz3fPcN4vv7hfl3Qm9cF7d6lYYn2FH/WmelV2yjoye3F3WFF/8aEhyXGUf/xxr0sB\nAABNjGDoIz0tbrdxeCJ/+ouWLYUiJ00llXTOe4aSFAmH9L9v2qg9x2b0xe/tXa5yUUe96eouwynu\nGfpNfPMVksSiewAA4CmCoY88b8dQcgfQzO8xjJ9/x1CSXrFuhX52baf+/OvPaHS6cPHFoq56kyy5\n96twNit7cFC5HQRDAADgHYKhj3RlYjLmLB1DyV1ZUTwxlVRy7xier/fftEGzxbL+9MGnL7pW1NfK\n1EqFTIhg6FPxoSHlHntMjuN4XQoAAGhSBEMfiYRDWpGOnqNjuPQ7hvMuXZHWL7+oX//0w+e069Dk\nRdeL+omEIupKdBEMfSo+tFnl0VHNHeT3DwAAeINg6DPd2bgOnbVjmDq9Y7iEYChJv/Wqy5SJR/TB\ne5+ge+Ez7DL0r8WL7gEAALxAMPSZnpaYhifO0jG0kwvDZyLRsIxZWsdQkloStv7nq9bqod2jevAJ\nJlz6SU+qh+EzPhVdu1YmFiMYAgAAzxAMfaY7G9eh8fyZu3mLhs8YY2THLRWXcMdw3puvXa1LV6T0\noft2qVAqX2zJqJO+VJ+O5o6qWC56XQqWyFiWYpsuJxgCAADPEAx9pjsbU26urInc3OkvLho+I7n3\nDAv5pQfDSDik99+0UftGZ/WFh/deRLWop/mVFcPTwx5XggsRHxpS4YldqhQJ9gAAoP4Ihj7TnXV3\nGWq/ZxgAACAASURBVJ7xnuGi4TOSLrhjKEk/u7ZTr1y/Qp/4+m4dY32FL/SmWFnhZ/HNQ3Lm5pTf\nudPrUgAAQBMiGPpMd0t1l+GZ7hnOD5+pHjONxq0lD59Z7H03blBurqyP/dtTF/wZqB+Cob8lX/Ji\nmVhME1+50+tSAABAEyIY+kxPtWM4PH6GjqGdlColqXrHzI5bSx4+s9glnSn9yosHdPuP9usnwxMX\n/Dmoj854p6yQRTD0qXA6rcwNN2ji3ntVnp7xuhwAANBkCIY+05mOygqZM3cMo2n3sTqA5mI7hpL0\nzusvU0s8og/cw/qKRhcOhdWT7CEY+ljrbVvlzM5q8p57vC4FAAA0GYKhz4RDRl2ZmA6dsWOYch+L\n7j3Di7ljOC+biOhdr16r7z87pgd+cviiPgu115vqZWWFj8U2b1Z03TqNb9vmdSkAAKDJEAx9qDt7\nll2G0WowrHYM7YSlYqEsp3Jxnb43XbNa67rS+sA9uzRduLigidrqSdEx9DNjjFpu26r8E08ot/Nx\nr8sBAABNhGDoQ90t8TNPJV3oGJ44SipHKl7AyorFrHBIH/7FTTo0kdMH73nioj4LtdWX7tPxwnHN\nzs16XQouUPbmm2XicY1vu8PrUgAAQBMhGPpQTzamQxNnWHJ/yh1DO265X17kPUNJurq/Tb/2M2t0\n+4/26xtPHrnoz0NtMJnU/9whNK/VxL33qTw9fe5vAAAAWAYEQx/qzsZULFU0OnPKImw76T4u7hhK\nFzWZdLF3vXqt1nWl9Z4v79TxU382GgLBMBhab7uNITQAAKCuCIY+1N1SXXJ/6gCaU46S2onlDYZR\nK6yPbR3S8Zmi3n8n958aUU+qRxLB0O9iV1yh6Pr1On7HNqYBAwCAuqhpMDTGxIwxPzTG7DDG/MQY\n84fV579jjHm0+p9hY8xXqs+/3Bgzsei131/0Wa8xxjxljNltjPm9Wtbd6Lqz7pL70wbQnGFdhSQV\nLnIy6WKberN65/WX6Z7HDunuHcPL9rlYHu2xdsWtOMHQ54wxar1tqwq7din/OH8JAwAAaq/WHcOC\npFc6jjMk6UpJrzHGvMhxnJc5jnOl4zhXSvqepH9Z9D3fmX/NcZw/kiRjTFjSpyS9VtJGSW8yxmys\nce0Nq7u65P7wqQNozrCuQlq+juG8//7ySzS0qkXvv/NxHZ08wxAceMYY4+4yZGWF72WqQ2iO38EQ\nGgAAUHs1DYaOa356QqT6n4VzUcaYtKRXSvrKOT7qGkm7Hcd51nGcoqTbJb2uBiX7QnvSlh0Ond4x\ntGwpbJ/eMVzmYGiFQ/rYrUPKFct6z5cf46hbg+lN99IxDIBwKqXMjTdokiE0AACgDmp+x9AYEzbG\nPCrpqKQHHcf5waKXf0HS1x3HmVz03IurR0/vN8ZcXn2uV9L+Re85UH2uKYVCRiuzZ1tyn5SKM+4v\na9QxlKRLV6T0ntes1zefGtEdP9p/7m9A3fQk3V2GBHb/a73tNjm5nCbvvtvrUgAAQMDVPBg6jlOu\nHhntk3SNMWbTopffJOmfFn39iKT+6tHTT+hEJ9Gc6aNPfcIY83ZjzHZjzPaRkZHl+QdoUN3ZmA6d\nacm9nV4YPhO2QrIioWW9Y7jYr75kQC9e064P3POE9o+xN69R9KX7ND03rcni5LnfjIYW27RJ0Y0b\nGEIDAABqrm5TSR3HGZf0LUmvkSRjTLvcI6L3LnrP5PzRU8dx7pMUMcZ0yO0Qrlr0cX2STpt84jjO\nXzuOs8VxnC2dnZ21+kdpCD0tcQ2fqWMYTUmFqYUv7YRVk46h5HYu//jWzTLG6N1f2qFKhT+4NgJW\nVgSHMUatW7eq8OSTyu/c6XU5AAAgwGo9lbTTGNNS/XVc0qskPVl9+VZJ9ziOk1/0/pXGGFP99TXV\n+kYl/UjSZcaYQWOMLemNku6qZe2Nrjsb05HJvMqnhjE7tdAxlNx7hst9x3CxvtaEfv+mjfrBnjH9\n3UN7avZzcP4IhsGSuekmmUSCITQAAKCmat0x7Jb0TWPMY3LD3YOO48xvbH6jTj5GKklvkPS4MWaH\npL+Q9MbqAJuSpP9H0gOSdkna5jjOT2pce0PrbomrVHF0bLpw8gvR1MLwGcm9Z1irjuG8W7f06fr1\nK/T/PvCUdh+dOvc3oKYWdhkymTQQwqmUsjfeoMn77ld5iv9+AQCA2qj1VNLHHMe5ynGczY7jbJpf\nP1F97eWO43z1lPd/0nGcyx3HGXIc50WO4zy86LX7HMdZ6zjOJY7jfKiWdftBz/wuw/FT7hkuGj4j\nSdGEVbM7hvOMMfrI669Q0g7rXdt2aK5cqenPw/PLRrNKR9I6MH3A61KwTFq2ukNoJhhCAwAAaqRu\ndwyxvOZ3GR46bZdh+qSjpHbcUjFfrnk9K9IxffDnr9BjByb0l9/8ac1/Hp5fb7pXw9OnXcOFT8Wv\n2KTYxo0aZwgNAACoEYKhT/W0nKVjeMrwmWjcUmF2ri413bi5W7cM9egT33hGOw9M1OVn4sx6U+wy\nDJqWrVtVeOop5R97zOtSAABAABEMfSobjygWCZ2hY1gdPlPtKrh3DGvfMZz3R6+7XG1JW+/a9qjy\nc/X7uThZT6pHw9PDdJcC5MQQmm1elwIAAAKIYOhTxhj1ZOM6fGowjKakSkkquUNpoglL5VJFpTqF\ntJaErY++YbOeOTqtP33w6br8TJyuN9WrfDmv0fyo16VgmYRTSWVvvFGT992n8iQ7KgEAwPIiGPpY\nd0tMw6cuubfT7mP1nqEds9wv69g1fMW6FXrTNav1N995Vj/cM1a3n4sT+lJ9klhZETQtt90mJ59n\nCA0AAFh2BEMf687GdejUJfd20n2sBsNowg2G9bpnOO99N25QX2tc7/7SDs0UajsVFadb2GXIyopA\niW+6XLHLL2cIDQAAWHYEQx/rycZ0dCqv0uL1ENGU+1jdZWjH698xlKRU1NLHbr1S+4/P6kP37arr\nz8aiXYZ0DAOnZetWFZ5+WvkdO7wuBQAABIjldQHNpOw4yleWb8dfWyaqiiPtGZ9VT4u7vkJWSgrF\npPy0VC6rEg2pGJbGZwtKlesbDi9fndVbXzqgzz28T6/Y2KVXr1tR15/fzBKRhNpibdo/td/rUrDM\nMjfeqKMf/aiO37FN8Suv9LocAAAQECaox5G2bNnibN++3esyTrJ9YkY3PfLMsn1eaCQv+5FRFa7p\nkNMaXbbPrQnH0dvjaW2yGrzOZWaM9PJ1K9SZrv8/91vvf6sk6Quv/ULdfzZq69Dv/4Em7rpLl/37\ntxXOZLwuBwAANChjzH84jrPlfN5Lx7COemMRvf+SnmX7vGOtOX3ukVG9PpvRhkva3Senjkjf+6S0\n+TZp5SYVc3Paft8+XfKCTnUNZpftZy/F4Ymc/ubImD6765AiTzffNMWOVFSfevNVunZNe11/7kB2\nQN/e/+26/kzUR8ttWzW+bZsm7rpbbb/0Fq/LAQAAAUAwrKPuqK13rF6+45RTK+b0OT2uKyxbvz7/\nucdz0oHbpatfJq1+pYr5kv7mqaf0ksujumoZf/ZSfXc2p7ahlP7iF8/rLywC4+hkXr/9pR1689/+\nQO95zTr92svWyBhTl5/dn+nXaH5UU8Uppeen1SIQ4pdfrtimTRq/4w61vuXNdfu/KQAAEFwEQx9L\nxyJKR62Tl9xHqwGgOnwmEg3LGKmQq+9U0lNdno7r4fFp9c7fhWwSvS1x3fmO6/SeLz+mD9/3pB7Z\nN64/vnWz0rFIzX92f6ZfkrRvcp82dWyq+c9DfbVsvVWHf/8PlHv0USWuusrrcgAAgM8xldTnulti\nGh5ftMvQrk4lLU5JkowxsuNW3aeSnmp9MqbhwpzG55pvdUU6FtGn3vwC/e8bN+jBXUd0yycf0lOH\np2r+cwcyA5KkvZN7a/6zUH/ZG29UKJHQ+B3bvC4FAAAEAMHQ51Zm4yd3DC1bCtsLHUPJ3WXodcdw\nfcrtFD41kz/HO4PJGKP/+rI1+qdfe5GmCyX9/Kce0p2P1naVxKr0KhkZ7ZvcV9OfA2+Ekkllbr5Z\nk/ffr/LEhNflAAAAnyMY+lxPNnZyMJTcrmHxRDBshI7hhmRMkrSrSYPhvGsG23Tvb7xUV/Rm9c7b\nH9Uf3Pm4iqXlW2GymB221ZPq0b4JgmFQtd62VU6hoIm77va6FAAA4HMEQ5/rzsZ1bLqgQmlR8LNT\nUnFm4cto3FJh1tuOYU80oowV0pNNHgwlaUUmpn/8tWv1ay8b1Be+t0+3/fX3Tj4OvIwGMgMcJQ2w\n2MaNil1xhca33aGgrh4CAAD1QTD0ue4WtxN3ZKJw4sloSiqcuMPWCB1DY4zWJ+N6cro2AchvIuGQ\n3nfjRv3lW16gpw9P6aZPfFcP7T627D9nIDugfZP7CA0B1rL1VhWe2a3cjx/1uhQAAOBjBEOf68m6\nd/eGJ04ZQLPoKGk07v0dQ8kdQPPkTJ6QssgNV3Trrt94qdqTtn75sz/Qp765W5XK8v376c/0a7Y0\nq2O55Q+daAzZG25QKJnU+B13eF0KAADwMYKhz813DA8tDobR1EnDZxqhYyi5wXC8VNbhovchtZFc\n0pnSV95xnW7c3KM/fuApvf3vt2timYL8/MoKjpMGlzuE5iZNfvWrDKEBAAAXjD2GPrfQMRxfdHfP\nTkmTwye+TFgq5ktyKo5MyLtF2Buqk0l3TefVHbU9q6MRJaOW/uKNV+rq1S364L27dPMnvqtP/9IL\ndHlP9qI+d/HKiheufOEyVIpG1HrbbRq//Q6Nfu5zSl//Kq/LAWrKamtVpLfX6zIAIHAIhj4Xt8Nq\nSURO6RimT15XEbckRyoWyu6vPbK+Opn0yZm8Xtme8ayORmWM0a9eN6gr+rL6H//4iH7xLx/Wu169\nVj0t8Qv+zIpTkWUi+sbunyiWu24Zq0Vjyarv0g0a/cxfafQzf+V1MUBtGaNVn/m0Uj/7s15XAgCB\nQjAMgO5sXIdO6hgmT1tXIUmF2TlPg2FrxNJKO6JdMwygeT5X97fp3t98mX7j//uxPnL/kxf9eYnB\nNn3r2Sd0/7//eBmqQ6NqvfRWXdZxwOsymo4dDumTb75KYQ9PYzSbkT/7cw3/3ns1+JWvKNK1wuty\nACAwCIYB0JONaXjilKOkxWnJcSRjFsJgI9wz3JCK6alpVlacS0cqqn/8r9dq7+iMKhc5rOejj3xV\n+6ef1Se3/swyVQdAkh74yRH98QNPafLKF2l1e8LrcpqGvXq19rzhVg2/5z1a/dm/lQmHvS4JAAKB\nYBgA3S0x/cdzx088EU1JlZJUKkiRmOzEfDD0fujLumRMnx8/prLjKGz4G/bnEwoZrelMXfTnbFpx\nqbYf/a4GOuKyQvxXHlgux6v7YZ89Nk0wrKPoJZdo5fv+lw797/dr9G/+Vh3/7de9LgkAAoGppAHQ\nnY1rfHZOuWK1I2in3cfqcdL5jmGhETqGybjyFUd7coVzvxnLoj/Tr5JT0vD08LnfDOC8DXYkJUl7\njs14XEnzyb7+9crc8FqNfOITmn2EY/IAsBwIhgHQnT1lZUW02mWqLrmfv2NYnPW+Y7g+VR1Aw3HS\nulk8mRTA8mlP2krHLIKhB4wxWvmHf6hId7eG3/1ulScnvS4JAHyPYBgA3dWVFYfm7xna7t9iq+j+\nYaWROoZrEzEZiQE0dbSwy3Bir7eFAAFjjNGajiTB0CPhdFq9f/oxzR09qkPv/305F3kfGwCaHcEw\nAHqqS+6Hx6thy652DKtHSRc6hg1wxzAeDmkwHtWTM3QM66Ul2qKMndG+yX1elwIEzmBHUs+OEAy9\nEt+8WSt+652aeuABjW/7ktflAICvEQwDYOXCUdJq2IpW7xhWdxmGrZCsSEiF2ZIX5Z1mQyrGUdI6\nMsZoIDNAMARqYLAjpeGJnPJz3p/IaFZtb3ubktddpyMf/rDyTz/tdTkA4FsEwwCIWmF1pOwTdwwX\nOoZTC++xE5aKucYIhuuSMe3JFZQrV7wupWn0Z/q5YwjUwGBnUo4jPTc263UpTcuEQur5vx9RKJXS\n8G//tio5rioAwIUgGAZEdzau4fkl9wvDZ04suY/GLRUaJBhuSMZVkfTMLF3DehnIDujI7BHNzvGH\nV2A5ralOJuU4qbeszk71fPSjKjyzW0f+70e9LgcAfIlgGBDd2dgZOoYn/qBixxunY7ihOpl0F8dJ\n62Z+AM3+qf0eVwIEywArKxpG6qXXqe2/vE3jd9yhyQf+zetyAMB3CIYB0dMS16H5juEZjpJG41bD\n3DEciEUVDRk9yWTSumFlBVAbqailznRUe45Nn/vNqLkV73ynYps369D736+5gwe9LgcAfIVgGBDd\n2ZimCiVN5ecky5bC9klHSe2EpWK+MYYjWCGjtYkYk0nraFV6lSRWVgC1MMjKioZhbFu9H/sTqVLR\nwXf/jpxSY/yFKAD4AcEwILpbTt1lmFpYVyG5R0kLDbDgft66JMGwnhKRhLoSXUwmBWqAXYaNxV61\nSiv/8P8o9+Mfa+STn/S6HADwDYJhQHRnT9llGE2dNnym2AAL7udtSMV1qDCn8Tn+NrdeWFkB1MZg\nR1LHpouaaIBdsXBlb7xR2df/okb/6q818/3ve10OAPgCwTAg5oPh4YWOYfq0jmG5VFGpQXZtrU+6\n9dI1rJ/+TL/2TO6R4zhelwIEymB1AM1euoYNZeX73id7cFDDv/O7Ko2NeV0OADQ8gmFAdGViMkYa\nXgiGyZOCYTRuSVLDdA03VIPhLoJh3fRn+jVVnNJ4YdzrUoBAWdPJZNJGFEok1PunH1N5YkKH3vu/\n+EsxADgHgmFARMIhrUhHdegsR0ntajBslHuG3dGIslZYu6aZTFovA9kBSeI4KbDMVrUlFDLSswTD\nhhNbv14rfvd3Nf3tb+v4F7/odTkA0NAIhgHSnY2fdfhMNNFYHUNjjNYnY3qKjmHdsLICqI2oFVZf\na4KOYYNqfcublbr+eh35k48p9/hPvC4HABoWwTBAelpiGp5fch9NN3THUHLvGe6ayXG8p056Uj2y\njEXHEKiBwY4kdwwblDFG3R/8gKz2dh387XepPM3vEwCcCcEwQLqz7pJ7x3GqHcMTC+4TaVuSdP9n\nduruTzyqR7/2nEYPTnsaytan4posVXSo0DhhNciskKW+dB+7DIEamN9lyF90NSartVW9f/LHmtt/\nQCMf/7jX5QBAQ7K8LgDLpzsbU26urIncnFrspFSckRxHMkbZFXHd8ptXau/OY9q/a0wP/fNuSVIi\na2v1hjb1bWjTqg1tSmTsutW7eABNT6x+P7eZDWQGOEoK1MBgR1LThZJGpgtakY55XQ7OILFli7I3\n36yJO+/Uit95t0Ixfp8AYDGCYYD0VJfcD4/n1RJNSZWSVCpIkZiMMVq1sU2rNrZJkqbG8tq/a0z7\nd41p785RPfn9w5KkjlUprVrvvq/70qysSLhm9S5eWXF9e6ZmPwcn9Gf69fDww6o4FYUMBwaA5TK/\nsmLPyAzBsIFlX3eLJu68U9Pf+pYyr3mN1+UAQEMhGAbI/C7DQxM5bbTT7pPFaSly+h9S0m0xbbyu\nRxuv65FTcTSyf8oNik+Macc39uvHDz6ncCSknstatGpDm1ZvbFNbT1LGmGWrtyViqTsaYTJpHfVn\n+1WsFHV45rB6Uj1elwMExkIwPDaja9e0e1wNziZx7bWyVqzQxJ13EQwB4BQEwwBZ6BhO5KVYyn2y\nMCUlO573+0zIaEV/Riv6M7r6NQMq5ksafmZ8ISg+/OXdevjL7vsuNBaGwkY3/PfNCx3LeeuTMZbc\n19HiyaQEQ2D59LTEZVshJpM2OBMOK3PTTRr74hdVOn5cVmur1yUBQMMgGAZIRyoqK2TcXYarq8Fw\n0cqK82XHLA1c0aGBK9xAOX3cPXY6cfTCO3s7vr5fe3ceO2MwfHj8mEoVR1Zo+bqROLP5YLhvcp9e\n0vMSb4sBAiQcMhpoT7DL0Aeyr7tFY3/3d5q87z61veUtXpcDAA2DYBgg4ZBRVyamwxN5d8G95A6g\nuUip1pg2vOTiukuHfjqhI3snT3t+QyquQsXRnlxBlyW5l1NrHfEOJawEKyuAGhjsSOqnIwTDRhdb\nt07Rdes0edfdBEMAWITpEwHTna3uMrTnj5IuvWNYC10DGY3sn1J5rnLS84sH0KD2jDHqz/SzsgKo\ngcGOlPaNzqhcYWVFo8vecrNyO3aouHev16UAQMMgGAZMd0tchybyJ4Lhol2GXupak1Gl5A65Weyy\nREwhSbtmGEBTL6ysAGpjTUdSc2VHB4/zv2eNLnPTTZIxmrj7Hq9LAYCGQTAMmJ5sTIcm8nJsd0Je\n43QMs5KkI3tOPk4aD4c0GI/qyWk6hvXSn+3X8PSwiuWi16UAgTLY6f7v7rPHGuN/d3F2ka4uJV50\nrSbuvluOQ4cXACSCYeB0Z2MqlioaLVXv613A8JlaSLVGlWqN6sieidNeW59iMmk99Wf65cjR/qn9\nXpcCBMrilRVofNlbXqe5555T7sePel0KADQEgmHAdFdXVhyarS6mb5COoeTeMzzjAJpkXHtyBc2W\nK2f4Liy3wcygJHGcFFhm7Ulb6ZilvQRDX0i/+tUysZgm7r7L61IAoCEQDAOmJ1vdZThdksJ2w3QM\nJalrMKvJY3nNTp58hHF9MiZH0jOzdA3rYXVmtSQxmRRYZsYYDXYkWVnhE+FUUunrr9fUfffLKXK0\nHgAIhgHT3eIeIT00Xp1M2lDBMCNJp3UNN6TcmndNM7ChHtJ2Wu2xdoIhUAODHUmOkvpI9pabVZ6Y\n0PR3vuN1KQDgOYJhwLQnbdlWyJ1MGk011FHSzv60TMjoyLMn3zMciEcVCxnuGdYRKyuA2hjsSOrg\neE75ubLXpeA8JK+7TuG2Nk3cyXFSACAYBowxprrLMC/Z6YbqGEbssDr6Uqd1DMPGaG0ixmTSOhrI\nsrICqIXBjqQcR3pubNbrUnAejGUpc+ONmv7mN1WePP0OPAA0E4JhAK3MxNyjpNGUVGiMPYbz5gfQ\nVE5ZAL0uFWOXYR31Z/o1lh/TZJE/CAHLaU2Hu0P22RGOk/pF9pZb5MzNafKrX/W6FADwFMEwgHoW\nltwnpWJj/eGka01Gc/myjh8+ua4NybiOFEsamyt5VFlz6c/0S5Kem3zO40qAYBnoSEhiZYWfxDZd\nLnvNGk3edbfXpQCApwiGAdSdjenIZF7lSGMdJZXcjqF0+qL7DUl3AA3HSeuDlRVAbaRjEXWmo9rD\nknvfMMYoe8vNmt2+XcUDB70uBwA8QzAMoO6WuEoVR8dC7Q01fEaSWlYkFE1YpwXD9dXJpE9ynLQu\n+tJ9CpkQk0mBGmAyqf9kbrpZkjR5zz0eVwIA3iEYBlBP1g1Zw5U2qdhYdwxNyLj3DPecPJl0pR1R\nixVmMmmd2GFbPcke7ZsgGALLbQ3B0Hfsvl7Ft1ytibvukuM45/4GAAgggmEAdVeX3B+qZN2OYYP9\nP7muwYzGhmdUzJ+4T2iM0fpkjGBYR/3Zfo6SAjUw2JHUsemiJnJzXpeCJcjecouKzz6r/OM/8boU\nAPAEwTCAeqpL7ofn0pJTlkoFjys6WddgVo4jHd13cjdzfSquJ2dy/G1tnQxkBrRvch//voFlNtCR\nlCTtpWvoK5n/9J9kIhFN3M1OQwDNiWAYQNl4RPFIWIeK7nS8xh1Ac/Jx0vXJmCZLFR0s8Lfs9dCf\n6ddsaVYjuRGvSwECZc18MBwlGPpJOJtV6hWv0OS998kpMSEbQPMhGAaQMUbdLTEdKkbdJxpsl2Es\nFVF2Rfzsk0k5TloX8ysrGEADLK/V7QkZwy5DP8recrPKo6Oaefhhr0sBgLojGAZUTzau4ZzlftFg\nHUNJWjmY1ZE9kycdY1xXDYa7pplMWg+srABqI2qF1dcaZwCND6V+5mcUzmY1cSfHSQE0H4JhQHVn\nYzo0a9wvGmxlheQOoJmdLGpq7ER3sCViqSca0VN0DOuiK9mlaDjKZFKgBgY7UgRDHzK2rfQNr9XU\n17+u8jS/fwCaC8EwoLqzMR2dleaccEN2DLsGz7zofn0ypl3sMqyLkAlpdWY1R0mBGphfWcFwJ//J\n3nyLnHxeUw8+6HUpAFBXBMOA6m6Jy5F0VC0NGQzb+1IKR0JnCIZxPTNTUKnCH6bqYSAzwFFSoAYG\nO5KaLpQ0Mt1YU6FxbvGrrlRk1SpNMp0UQJMhGAZUd3XJ/SGnvSGPkobDIa1YnT59AE0qpqLj6Nkc\nf5iqh/5Mvw5MHVCpwgQ+YDkNVieT7mEAje8YY5S9+WbNfO/7mjtyxOtyAKBuCIYB1dPiLrkfdtob\nsmMoSf9/e3ceH3dV73/89Zl9MpOtTZomXZKUtrRAoUhZRJBFrYpS1CuiiKAPF/CqV+91w4sXEXH7\neRVc4SqguKKgCAgqiGzK2ipCoS1LN9qkTdMmadZJZub8/phvSiht6ZLMd5b3E9KZOfOd+X6Snmbm\nM+ecz5nSWsWW9b1k0tkdbfNGC9BoOmleNFc1k3ZpNvZt9DsUkZKyIzHUOsOiVL3kdHCO7X+4ze9Q\nRETyRolhiSr0EUPIVSbNpLN0bnghvjkVMQLAyj4VoMmHlqoWQFtWiIy3ppo4kVBAiWGRirS0EDvi\ncHpu0XRSESkfSgxLVGUsTGU0RDv1MFxY+xiO2lUBmlgwwKyKqPYyzJPRxHBtz1pf4xApNcGA0TK5\ngtVKDItW9ZIlpFatYmjVKr9DERHJCyWGJayxJkabTYHhwnxjkqyNUlEdYfOanhe1z0vEWKmppHlR\nE6uhOlqtEUORCdAyOaERwyJWddppEApp1FBEyoYSwxLWWB0v6KmkZrZjo/ux5ifirB0cpj+T8Smy\n8tJc1azEUGQCtNYnWL91gIyqLBelUG0tyRNPZPutf8Dp9UhEyoASwxLWVBOjPVuY21WMamitomfL\nIIN9wzva5iVjOODpflUmzQdtWSEyMWbVJRjOZGnr1gyIYlV9xhLSHR0MPPKI36GIiEw4JYYlKstA\nswAAIABJREFUrLE6Tmc2SWqwcKcy7Wqd4fxErqKqppPmR3NVM5sHNjMwMuB3KCIlpbUuCaB1hkUs\nefLJBJJJem7WdFIRKX1KDEvYaGXSTYPmcyS7Vz+zErMXJ4bN8QjxgKkyaZ40VzUDsL53vc+RiJSW\nF/YyLNxZG7JngViMyje8nt477iA7qA8rRaS0KTEsYY3V3l6Gg2GfI9m9SCzEpGlJNq99ITEMmjEn\nEVNl0jzZUZlU00lFxlVdMkJlNKQCNEWu+vQlZAcG6L3rr36HIiIyoZQYlrDGGm/EMBXxOZI9a2it\nYvOa7bgxBRrmJWLa5D5PZlbNBGBdjwrQiIwnM6O1PqGppEWu4uhFhBob6blV00lFpLQpMSxhTaMj\nhsNxnyPZs6mtVQwPpunueGGN2/xEnI7hNFuH0z5GVh7ioThTE1NVmVRkArTWacuKYmeBANVvfjP9\nf/s76c5Ov8MREZkwSgxLWDwSpCacpn0kCa5wy6U3tFQDsGn1mAI0ydxopwrQ5Ie2rBCZGK11CTZ2\nDzI0ou0Oiln1GUsgk2H77X/0OxQRkQkT8jsAmViN8TTtfZMgPQThwhw5rJ1aQSQWZPPa7cw/vhGA\neV5l0hX9Q7yqttLP8MpCS1ULt6+5HeccZoVbrEik2LTWJXAO1m8bYG6DfpcVq+js2UQPmU/PLbdQ\n+55z/A5HRApYMb+PUmJY4poqoK13Um6T+wJNDC1gTGmpYvOanh1tDZEQtaEgq1SAJi+aq5rpHe6l\nO9VNbazW73BESsas0S0rtvQrMSxy1UuW0PG1r7Ny/iF+hyIiBar1pt8Rmz/f7zD2mxLDEteYNJZt\nmuxtcl/vdzi7NXVWNcv+tI6RVIZwNIiZcXAixoo+TSXNh9EtK9ZtX6fEUGQctdRVAGidYQmoPfNM\n3MgILjXsdygiUqBCdXV+h3BAlBiWuMbKMN1EGezfTnyS39HsXkNLFS7r2LJ+O01zconJ/GScGzZt\n0/TGPBjdsmJNzxoWTlnobzAiJaQyFqYuGWVNp/YyLHaBRIK6D37Q7zBERCaMis+UuKbqKABtW3t9\njmTPGlqrANg0ZqP7eYkYfZksG1IjfoVVNpqSTYQCIRWgEZkAs1SZVEREioASwxLXWJMAoL27sN+U\nxCsjVNXH2TwmMZyf8CqTajrphAsFQsyonKHEUGQC5LasGHj5A0VERHykxLDENU3KFTto6yn85Kqh\npepFieG8ZK5YzkoVoMmL5qpm1m5f63cYIiWntT5BZ1+K7UOa/SAiIoVLiWGJa5iUm6LZvr3w35BM\nnVVFf3eKvq5cIlgVCjItGmaFEsO8aKlqYf329WRd1u9QREpKa11u5sZaTScVEZECpsSwxEUrqqij\nh019hf9mf3Sj+xeNGibimkqaJ81VzQxnh9nUv8nvUERKyiwvMdQ6QxERKWRKDEtdtJJG20pbEbwf\nqZuRJBgKvLgATTLGMwMpRrLOx8jKw+iWFZpOKjK+Zk6uwCy3l6GIiEihUmJY6oJhGgNdtA8W/l91\nMBSgbkbyRRvdz0/EGHGO1YMpHyMrD6NbVqztWetrHCKlJhoKMr02rhFDEREpaIWfLcgBawr10j4U\n8TuMvTK1tZot63rJZHJTX+d5lUm10f3Eq4vXkQgnVJlUZAK01iWVGIqISEFTYlgGGiMD9GZC9BZB\nRbyG1irSI1m2bcy9gZpdESNosEoFaCacmdFc1azEUGQCjO5l6JymxYuISGFSYlgGGiO5aZjtPYWf\nXI1udD86nTQWDDArHmVFv0YM80FbVohMjJbJFfSl0mzp07R4EREpTKGJfHIziwH3AVHvXDc6575g\nZj8BTgJGF5O91zn3mJkZ8G3gNGDAa/+H91znAZ/3jr/MOXfdRMY+ETY8+QwP3XZP3s+7pmc+AL/5\n0U3MixT6mxJHvGqIf9y5gpUP56a/Jg86iL/U1LDgjw/5HNv+icSiROJRv8PYKz3urfRUnspxDz6F\nmd/RSD4ZRm04SEMkzJRomIZI6EXXp0TC1EVCBNUx9ktrfRKANVv6mVIZ8zkaERGRl5rQxBBIAac6\n5/rMLAz8zcz+6N33aefcjTsd/0Zgjvd1LHAlcKyZTQK+ACwCHLDMzG5xznVNcPzjqmPNBpYPbMz7\neftCEcjAU0PbSac7837+fVbhXQ7kLmauG6RvpJVinYBlPVAVjDN9bivB8ET/kzswG3u7eax3NXPi\n06mMVPodjuRRxjm2Dqd5ZmCIB7r76E5nXnJMAKgbTRgjYRqiuYRxSiTE8bVJ5iXi+Q+8SIzdsuLY\nWZN9jkZEROSlJvRdqsstpujzboa9rz29vz8D+Kn3uIfMrMbMGoGTgTudc9sAzOxO4A3AryYq9olw\nxOtP5NBTj8v7edM3XcDvnljAwleewsdPmZX38++rf/7leZbetob3XPZKYomw3+EckK6NHdz2i5t4\nnm6qnljKSUcfy1Gnn+J3WLv1ZGcf71x5Je89/GBeM/Mwv8MRHw1lsnQMj9AxnKZjeITNw2k6UiMv\nur68b4Atw2myQEUwwF8WHcysiuIYHc+3ppo4kWBABWhERKRgTfjwhZkFgWXAbOD7zrmHzezDwJfN\n7GLgLuBC51wKmAY8P+bhG7y23bXvfK4PAR8CmDlz5gR8NwcmGA75MmIUTSSZEthOx0CaaEXhf6I/\nfW4dy27fQE/HCNWHVvkdzgGZOqeZ91/yCf72yz/wwMrHuXXpvTz12JMsOf9dVE8pvFGD0b0MVYBG\nYsEAM+NRZr7MNOiMc6wZTHH6smf48FNrufUVc4gEtHx9Z8GA0Ty5QomhiIgUrAl/9XbOZZxzC4Hp\nwDFmdhjwOWAecDQwCfisd/iuFq+4PbTvfK4fOucWOecW1dfXj0v8JSGSoNG20d5THAVcpjRXgfGi\nje6L3Qlnv5nzP3o+B4XqeC7dyf997/+4/xe3+h3WSyQjSeriddrLUPZa0IzZFTG+OW8G/+od5P+t\n2eR3SAWr1atMKiIiUojy9rGuc64buAd4g3Ou3eWkgB8Dx3iHbQBmjHnYdKBtD+2yN6JJGl1nUVQl\nBYjEQ0xqTLC5hBJDgOopk3nP/3yUJUefRIgAdz2zjGsuuYKO1Rv8Du1FtGWF7I/T6mt4T9Nkvr++\ng7919fodTkFqrU+wbusAmWyxrpgWEZFSNqGJoZnVm1mNdz0OvBZY6a0bxKtC+hZgufeQW4BzLec4\noMc51w78GVhsZrVmVgss9tpkb0SSNFon7d2DRbOH1tTWKjav7SmaePfFK958Ch/+9Mc4JNbIRtfD\nNdf9hDuuup5M5qXFPvzQUtWiLStkv1wyu4mDKqJ89Kn1bBtJ+x1OwZlVl2A4k6Wtuzhmb4iISHmZ\n6BHDRuBuM3sceJRcAZk/AL8wsyeAJ4A64DLv+NuB1cCzwI+Afwfwis58yXuOR4FLRwvRyF6IVtJo\nWxkcydIzWPib3AM0tFaT6k/T01Gab6DilQneceH5vOM1p5F0ER7YtJIfffEK1v9rpd+h0VzVzLah\nbWwfLq0RW5l4iWCQKw9pZutImk+tfL4kP9g5EK11uS0rVms6qYiIFKAJTQydc4875450zh3unDvM\nOXep136qc26B13aOc67Pa3fOuY845w7y7l865rmudc7N9r5+PJFxl5xIkibbCkBbd3FMJ915o/tS\nNe/VR3PB5z/BkdUtdFo/P/3db7j58p8wMjzsW0yjBWjWb1/vWwxSvBZUVvDfsxq5vbOHn7dv9Tuc\ngtI6umXFlr6XOVJERCT/CntTNRkfkQSNXmJ4zjUPEw0VR8XAvqoU19z2ONG7n/I7lDyYQTo4laGB\nIX652XHRxbcTi0UJRyN5jySdTdM3eCHnXLmWeGhz3s8/HhYf0sD/vPkQQsHi6Oul5vwZ9dyzrZeL\nn9nIcdVJ5iS0oTtAXTJCMhpSARoRESlISgzLQTTJYbaWDx0Roztc53c0e23d8m1kM1la5xRPzAfK\nOUfbqrV0DmwnO5ylciRG8ACSm1AkQiAQ3LcYzFFrKSpcHwkDgoYFDAKjl7DrQsEvVl1dRUVFxX7F\nfSB6Bke47sF1bOlLccVZRxIpkg9CSknAjO/Mn8kpj67kw0+t47aj5hDVFhaYGa11CU0lFRGRgqTE\nsBxEKglbhv9elIU5R/gdzV57MPQcj92xng8uOYxQZN+Sm+K2kI7VG7j1pzfyvOvemxxs9/az/sfc\nIJAFDmDmcaArwBvf+EYWLVpErs5U/lx9/2ouu20Fg8NLufKco4iFy6n/FIaGaJgr5s3k3CfW8NXV\n7Vwy+yVbz5al1roE/1jf5XcYIiIiL6HEsBxEcwUPSBVXCfmprVVks44t63tpnF3jdzh5NWXWdN5/\nySfIHEBlx86N6/n1JZ+luqGRsy7+KpFYfK8f+5G7PkL3QBc/O+U6sgMjZPpHyPaPkB0YIdufJts/\nQmZgtC294z43kgUgRZp7wk9y2223sfq+p1h81MkkZk8i3JjEghOfJH7gxFlUREJc9PsneO+PH+Hq\n844mGdWvu3xbXFfNe6fVcdXzWzh5UiUnT6ryOyTftdYluPXxNoZGMvrAQkRECoreKZWDiJcYDhdX\nwYOG1moANq/dXnaJ4ahgeP//iTa0zOL0T1zITV/7In/8/jc541MX7fW00paaFn67ZRmP9C/LNVR4\nX3sUwEaMwBAEBoMs2ryQqqdW81TPGjr/upXX/GkBFeEYqamQajJSTcbwVHDhiUkUW2bAvy9OcOUd\n2zjjB3/hs2ckScY0nTHfXl8Bd0ViXLD8OS5vGaS6zF91srGtBCqe49anY0yr3fsPa0REpPAdUX8E\niXDC7zD2W5m/RJeJ0RHD4eJa11JRFaFycoxNq7Vtwv5qXXgUp77vfO669kru+/m1nHzuB/fqcXNr\n5zKYHuT8O88/sAAmQVO0iaO3HM0v4/cxKRzmFR1zaHm+iQABRkjzbHw9y+PP8WTFszxZ8Rx9wYED\nO+dOItMO4bmNZ3PBdRuIz7yGQKi4PiApBenwDLqnXsL5y1dRteVbBzQ7uhRUzIRLl778cSIiUlxu\nOP0G5k2a53cY+02JYTkYHTFMFd8b4obWKjatLu0tKybawte/iW3tG1h2283UNk7jiNed9rKPWXLQ\nEmbXzCbtxmeT8t5tvTzyp0fo6emn48QwlXOSRNqzhDdmmL1xNvM2zeLMba8DID05QHpqADdes+wm\nwbLwCJesDVG77mK+PquSKRO4ZjVTHWB4dohMrUYnx7p5K1y16UjeccxPOX2y39H4pz+V5rxrH+Gc\n45p5y5FadykiUkpmVs70O4QDosSwHATDEIzCcHGtMQSY2lrNs0s76O9JkaiO+h1O0Tr53A/Qs3kT\nd117FdVTptJyxCv2eHwwEGRB/YLxC2AKHNNyDDfddBPL/7acwPYAp59+OuHjwgC4kQzDz/eRWttD\nau12Rtb3wzhujv5qIlweq+JTg718clUv34lXMX0fq7XuFQfZ/mG4f5hQQwXxw+qIH1ZHeGpF3gvw\nFJqF9Y6nh1dzbUcfZ86Yy/xk+U6jrA32MNQ7hSOnHO53KCIiIjsoMSwX0WTRjhgCbF6znVkL632O\npngFAkHe9B+f5vqLP8Otl3+Nd33pG9TNaM5rDLFYjLPOOov777+fu+++m46ODs466yxqa2uxcJDo\nrGqis6on7PxNwPQNPZx77cN8NDjILz5wLHMaKsf9POnuIQaf3Mrg8q30/nU9vXetJzg5RvzQOuKH\nTSYyvTK37UeZMTO+PX8mpzyyig8/tY4/HTWXWJnuMzmrLqG9DEVEpOCU56tyOYoki674DEDdjCSB\noLF5jaaTHqhIvIK3fPYLhKNRbvr6pQz0dOc9hkAgwEknncTZZ59NV1cXP/zhD1m9enXezr9gejW/\nPv+VALzj/x5k+cbx71ehmhiVr5rGlPMPp/GiY6l522xCk+P0/X0jW37wL9q/9ghdNz/L0LPduMz4\njYoWg/pImG/Pn8nK/iEuW93mdzi+0V6GIiJSiMyN43StQrJo0SK3dKlW9+9w5augphne9Uu/I9ln\nN3z1UTLpLIefOsPvUIpOzZQKGlqrCI7Z5H3Ts0/z6y9+jvrmFs68+CuEI/5M0d26dSvXX389nZ2d\nvPa1r+X444/P23TLtZ39vPvqh9k+OMKP33c0i1omTfg5s4NphlZuY3B5J0NPd+FGsgQqQsTmTyZ+\n2GRis2uxcHl8Vvc/z2zgRxs6+fnhs3jt5PLbwuKqe5/ja39cyeOXLKYqFvY7HBERKWFmtsw5t2iv\njlViWCauWQyhGJx3i9+R7LMHf/8c//jTOr/DKFqhSIDGg6qZdnAt0w6uZcrMSp5b+hC3fOsrHHz8\nq3nTf3zat/VvqVSKm2++maeeeopDDz2UM844g0gkkpdzt3UPcs7VD9PeM8SPzl3ECXPq8nJegOxw\nhtTTXbkppyu24oYyWDRIbHYNFi/9Gf4pHO+sHqIz4LipO06dK6+ptRu6Bvn7c5287pAGJlXkp7+X\nEgsFCDdUEG5KEm5MEJjAYlIiIsVOiSFKDF/iZ2+DoW744F/9jmSfuayjvyc1nrVIyoLLOjo39LFx\nVRcbVnWxrS03dS0cC9I0p4b04KM89+jvOfZt7+SEs87xL07n+Pvf/85dd91FfX0973znO5k0aeJH\n8AC29KZ4zzUPs3pLP987+0gWHzo1L+cdy6WzpFb35EYSn+2GdDbvMfjhubjx7sPDHNXj+O7KkbJa\n1zCSdXT2paiJh4lrk/t9lh3O4IYyuRsGobo44aYkkabEjmQxmFTCLSICSgwBJYYv8ZtzoWMlfPQR\nvyMRnwxsH2bj011sfLqbjau66NrUT3rgDjLDT9I070wOPflUps2tZVJTwpcRxGeffZYbb7wRgCVL\nltDQ0JCX8/YMpvnYb1ewclM/l75pNm+Yn7+Rw/EWDAaJRqNEo1ECgcJPtX68sZPPPb2BL82exgdn\nlE9xqaGRDPMv/hP/ceoc/vN1c/0Op+g458j0pBhp62ekrY9h7zLTndpxTLAqkksSmxJEmpKEm5IE\na6NlXx1YRMqPEkOUGL7E7z8Cq++G/3rK70ikQPR1pXh+xRbu+/k36Nu2lkjy7QRC04hXhpk2t/Yl\naxPzEtPgdh5a/hd6+rfl9bwjLsBdI3PYlK3k2NB6pgX8KXZkOJI2zHi8dw0Fw4RDEcLBCKHQC9fD\noQjhUJjQjuu5r1AwnPc3zQ74ZkWQx0PG4WlXVhvfb+weJBoKUJfUNjzjJuuwrIO0wzJZLJOFzAv9\nypnhggY+VgU278/cf7lruf9faGOi/iWMPq3Zi647G73PazdwY67vaBcpNjv1211mPLaLAw/AVxfM\nZN6U8a94fiD2JTEs/cUsklOk21XIxEnWRpl//HRaDr+MX33+Uwxsv51jl3yWrs1hNq7q5tllHb7E\nFWY+VdFtOMvvlMq3AreH0zxMfrfx2FmFyzIjm2ZmJsOMbJrErl/KdslZFmcZXCCdu7Q0Q4EMzoZx\ngQGcZchaGhfIQJ5/vruzIByh8+BXsC4S8zuU/IrBCNA3lHrZQ2U/BL2vImS7+HO88zJz3rPncWwg\ngHlfgdyly6XCo20ipaBn3XYosMRwXygxLBej21U4x7gMR0jJiCcreeuFX+CXF32Sx++8irO/9L9E\nE4eQ6k9TqjMKdueCTJZ7n+lkKJ3x5fz9qTSPru/igTXbWDU4AsC8KUmOnzWZV82azFEzaoiGxufd\nbiaTIZUaIpVKkRoeZng45dvf9/t8Oau/rn9kPQ+u3sYVZx2h6Y1lJJvNkslkSGfSZDIZMukMmWyG\nTCZNJp0hnfGuZzIvPS6THtdY3OgfzkHWu3S5qbpj21zWO/AAfj2MZNIMpAboTw0wODK0y2MqInEq\nohUkohUkIvHcZbSCimgFwSKYGi8FxuvbO/r52PYdl+5F18fjJXBeS/LAn8RHSgzLRSQBLgPpIQjH\n/Y5GCkzt1CbO+ORF3HDZ57n18q/wts9dSixZfmX048CSo6f7GsP7gGzW8WTbdu57Zgv3P7OFnz26\nnmsfWkc0FODYWZN59Zw6TpxTz9yG5AElFUn0u8AvLd1hfrIqxeTmZqZUltloqZS1dDpNf38/vb29\n9PX17bgce/353nb62vvK7sNJKX7TT5xNJdV+h7HflBiWi6g3rJ3qU2IouzT9kMNYfP7H+NMPLucv\nV/+Axed/TCMZPgkEjAXTq1kwvZqPnDKb/lSah9ds5b6nO7n/mS1cdtsKYAVTKqOcOKeeV8+t44TZ\ndUzWerWi0Vqf+1R5beeAEkMpK6FQiOrqaqqr9/zmOZvNMjAwQH9/P9lsYUx9F3k5kydP9juEA6LE\nsFxEvKHt4V6gfKr/yb459KTX0NXexsM3/ZrkpEm0HHGU3yGJ52CDgw8O8MGDG9jUl+bRtgEe2TjI\nnU+28dt/bABgcrxIF1WVoaxzBFyGc3/0AEEfi6FIkQkEtBxEpIBdfe7RvPKg4k0OlRiWi6iXGKoA\njbyMV73j3XRtauOh317PQ7+93u9wZA8OBeZjbInUsT4+g95Q8S54L0dNfgcgRSljAYYDUVKBCMOB\nCCnvazgQxZnW4on4KeVTjYLxosSwXOwYMez3Nw4peBYI8KaPfYqFi08jMzLidzgiJSvrHOms1lDJ\n3smm0/R0bKJnUxvd7W10b2qjd+sWxlbMSNROomZqE9VTp1HT2ETN1NxX1ZQGgqHyWzcukm+RYHF/\nOKPEsFyMJoZr7oMhf/ZoOyBVjdB4hN9RlI1AMMiMQxb4HYaIiOzByHCKnk3tdLW3sa19I13tG+lq\nb2PNsocY3P7Ca70FAsQSSU1DlaIyts6BmYGN2brFuw1j9gPdcbx//fxtF36BydNn+nb+A6XEsFxU\nTs1d3vMVf+M4EM0nwIn/BQedqhc3EREpe+FIlLqZLdTNbHnJfUN9fXRtyiWKXW0bGOztzX+AIvvN\nvVCV1oHD7Rgdd2O2mnDOvWjrCb8r2YajxV1MzPz+AU6URYsWuaVLl/odRmHZthoGu/2OYv+sfxAe\n+B70tkHjwlyCOO/03EJ8ERERERF5CTNb5pxbtDfHasSwnEya5XcE+2/aK+DoD8C/roe/XwG/ORfq\n5sIJ/wkLzoSg1k6IiIiIiOwvDbdI8QhF4ajz4KNL4e3XQjACv/8wfOdIePiHMDLod4QiIiIiIkVJ\niaEUn0AQDvs3uOBvcPYNUDUN/vhpuGIB3P/N4iyuIyIiIiLiIyWGUrzMYO5ieP+f4X1/zFUtvetS\nuPyw3GXfFr8jFBEREREpCkoMpTQ0Hw/n/BY+dG+uaun938qNIN7+Geh+3u/oREREREQKmorPSGlp\nWgjvuA46n8kVqVl6DTx6NcRr/I5MRERERErZebdCw6F+R7HflBhKaaqbA2d8H07+HCy7Dga3+R2R\niIiIiJSyWHEPRCgxlNJWPR1OvcjvKERERERECprWGIqIiIiIiJQ5JYYiIiIiIiJlTomhiIiIiIhI\nmVNiKCIiIiIiUuaUGIqIiIiIiJQ5JYYiIiIiIiJlTomhiIiIiIhImVNiKCIiIiIiUuaUGIqIiIiI\niJQ5JYYiIiIiIiJlTomhiIiIiIhImVNiKCIiIiIiUuaUGIqIiIiIiJQ5JYYiIiIiIiJlTomhiIiI\niIhImVNiKCIiIiIiUuaUGIqIiIiIiJQ5JYYiIiIiIiJlTomhiIiIiIhImVNiKCIiIiIiUuaUGIqI\niIiIiJQ5JYYiIiIiIiJlTomhiIiIiIhImVNiKCIiIiIiUuaUGIqIiIiIiJQ5JYYiIiIiIiJlTomh\niIiIiIhImVNiKCIiIiIiUuaUGIqIiIiIiJQ5JYYiIiIiIiJlTomhiIiIiIhImVNiKCIiIiIiUuaU\nGIqIiIiIiJQ5JYYiIiIiIiJlTomhiIiIiIhImTPnnN8xTAgz2wKs8zuO3agDOv0OQsqC+prki/qa\n5Iv6muST+pvky0T1tWbnXP3eHFiyiWEhM7OlzrlFfschpU99TfJFfU3yRX1N8kn9TfKlEPqappKK\niIiIiIiUOSWGIiIiIiIiZU6JoT9+6HcAUjbU1yRf1NckX9TXJJ/U3yRffO9rWmMoIiIiIiJS5jRi\nKCIiIiIiUuaUGOaRmb3BzFaZ2bNmdqHf8UhpMbNrzazDzJaPaZtkZnea2TPeZa2fMUppMLMZZna3\nma0wsyfN7ONeu/qbjCszi5nZI2b2L6+vfdFrbzWzh72+9mszi/gdq5QGMwua2T/N7A/ebfU1GXdm\nttbMnjCzx8xsqdfm+2uoEsM8MbMg8H3gjcAhwLvM7BB/o5IS8xPgDTu1XQjc5ZybA9zl3RY5UGng\nk865+cBxwEe832fqbzLeUsCpzrkjgIXAG8zsOODrwOVeX+sC3u9jjFJaPg6sGHNbfU0myinOuYVj\ntqjw/TVUiWH+HAM865xb7ZwbBq4HzvA5Jikhzrn7gG07NZ8BXOddvw54S16DkpLknGt3zv3Du95L\n7k3UNNTfZJy5nD7vZtj7csCpwI1eu/qajAszmw68Cbjau22or0n++P4aqsQwf6YBz4+5vcFrE5lI\nDc65dsi9mQem+ByPlBgzawGOBB5G/U0mgDe17zGgA7gTeA7ods6lvUP0eirj5QrgM0DWuz0Z9TWZ\nGA64w8yWmdmHvDbfX0ND+T5hGbNdtKkkrIgULTNLAr8FPuGc2577cF1kfDnnMsBCM6sBbgLm7+qw\n/EYlpcbM3gx0OOeWmdnJo827OFR9TcbDq5xzbWY2BbjTzFb6HRBoxDCfNgAzxtyeDrT5FIuUj81m\n1gjgXXb4HI+UCDMLk0sKf+Gc+53XrP4mE8Y51w3cQ25da42ZjX64rddTGQ+vApaY2Vpyy31OJTeC\nqL4m48451+ZddpD7wOsYCuA1VIlh/jwKzPGqW0WAdwK3+ByTlL5bgPO86+cBN/sYi5QIb93NNcAK\n59y3xtyl/ibjyszqvZFCzCwOvJbcmta7gbd7h6mvyQFzzn3OOTfdOddC7j3aX51z70YldA8tAAAF\nPElEQVR9TcaZmSXMrHL0OrAYWE4BvIZqg/s8MrPTyH36FASudc592eeQpISY2a+Ak4E6YDPwBeD3\nwG+AmcB64Ezn3M4FakT2iZmdANwPPMELa3H+m9w6Q/U3GTdmdji5IgxBch9m/8Y5d6mZzSI3qjMJ\n+CdwjnMu5V+kUkq8qaSfcs69WX1NxpvXp27yboaAXzrnvmxmk/H5NVSJoYiIiIiISJnTVFIRERER\nEZEyp8RQRERERESkzCkxFBERERERKXNKDEVERERERMqcEkMREREREZEyp8RQRERERESkzCkxFBGR\nkmdm95jZojye7xtm9qSZfWM3919gZud6199rZk3jeO6Tzez4XZ1LRERkd0J+ByAiIlLIzCzknEvv\n48POB+p3txG2c+6qMTffCywH2sYpppOBPuCBXZxLRERklzRiKCIiBcPMWsxshZn9yBtxu8PM4mNH\n/MyszszWetffa2a/N7NbzWyNmX3UzP7LzP5pZg+Z2aQxT3+OmT1gZsvN7Bjv8Qkzu9bMHvUec8aY\n573BzG4F7thNrOaNDC43syfM7Cyv/RYgATw82raLx15iZp8ys7cDi4BfmNlj3vd6lJnda2bLzOzP\nZtboPeYeM/uKmd0LfNzMTjezh724/2JmDWbWAlwA/Kf3fCeOnst7joXez+VxM7vJzGrHPPfXzewR\nM3vazE702g/12h7zHjNnf/9uRUSksCkxFBGRQjMH+L5z7lCgG/i3lzn+MOBs4Bjgy8CAc+5I4EFg\n7BTKhHPueODfgWu9touAvzrnjgZOAb5hZgnvvlcC5znnTt3Ned8GLASOAF7rPbbRObcEGHTOLXTO\n/XpPgTvnbgSWAu92zi0E0sB3gbc7547y4vzymIfUOOdOcs59E/gbcJz3vV4PfMY5txa4CrjcO//9\nO53yp8BnnXOHA08AXxhzX8g5dwzwiTHtFwDf9mJbBGzY0/cjIiLFS1NJRUSk0Kxxzj3mXV8GtLzM\n8Xc753qBXjPrAW712p8ADh9z3K8AnHP3mVmVmdUAi4EloyNqQAyY6V2/0zm3bQ/nPQH4lXMuA2z2\nRvKOBm552e9w9w4ml+jeaWYAQaB9zP1jE83pwK+9EcUIsGZPT2xm1eQSy3u9puuAG8Yc8jvvcuzP\n/EHgIjObDvzOOffMvn5DIiJSHDRiKCIihWbsurwMuQ8x07zwmhXbw/HZMbezvPgDULfT4xxgwL95\no2sLnXMznXMrvPv7XyZOe5n794cBT46JZ4FzbvGY+8fG9F3ge865BeTWNO78c9lXoz+30Z85zrlf\nAkuAQeDPZra70VMRESlySgxFRKQYrAWO8q6/fT+fY3QN4AlAj3OuB/gz8DHzhufM7Mh9eL77gLPM\nLGhm9cCrgUf2I65eoNK7vgqoN7NXevGEzezQ3TyuGtjoXT9vN8+3g/f9do2uHwTeA9y783Fjmdks\nYLVz7jvkRkIP39PxIiJSvJQYiohIMfhf4MNm9gBQt5/P0eU9/irg/V7bl4Aw8LiZLfdu762bgMeB\nfwF/JbfGb9N+xPUT4Coze4zc1NG3A183s38BjwHH7+ZxlwA3mNn9QOeY9luBt44Wn9npMeeRWwv5\nOLn1kZe+TGxnAcu92OaRW6MoIiIlyJzbeWaNiIiIiIiIlBONGIqIiIiIiJQ5VSUVERHZAzNbAPxs\np+aUc+7YvXjsRcCZOzXf4Jz78q6OFxER8YumkoqIiIiIiJQ5TSUVEREREREpc0oMRUREREREypwS\nQxERERERkTKnxFBERERERKTMKTEUEREREREpc/8fgk8TAdpy9VYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_df=pd.DataFrame(index=range(n_iter))\n",
    "for elm in eval_array:\n",
    "    scores_df[elm.name] = elm.plot_data['score'].cummin()\n",
    "\n",
    "ax = scores_df.plot(figsize=(15, 15))\n",
    "\n",
    "ax.set_xlabel(\"number_of_iterations\")\n",
    "ax.set_ylabel(\"best_cumulative_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE scored:\n",
      "GridSearch - 2523.141\n",
      "RandomSearch - 2750.581\n",
      "Hyperopt TPE - 2777.769\n",
      "Hyperopt Anneal - 2694.643\n",
      "Scikit-Optimize API Bayes - 2706.230\n",
      "Scikit-Optimize dummy minimize - 2636.697\n",
      "Scikit-Optimize forest minimize - 2714.055\n",
      "Scikit-Optimize gbrt minimize - 2679.641\n",
      "GPyOpt - 3506.660\n",
      "Evolutionary Algorithm Search - 2708.234\n",
      "BTB - 2674.263\n"
     ]
    }
   ],
   "source": [
    "print('Test MSE scored:')\n",
    "for elm in eval_array:\n",
    "    print(\"{} - {:.3f}\".format(elm.name, elm.test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>module</th>\n",
       "      <th>time</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>best_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearch</td>\n",
       "      <td>6.817726</td>\n",
       "      <td>4029.866516</td>\n",
       "      <td>4596.657380</td>\n",
       "      <td>3438.887311</td>\n",
       "      <td>356.777234</td>\n",
       "      <td>2523.140865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scikit-Optimize dummy minimize</td>\n",
       "      <td>7.574192</td>\n",
       "      <td>4149.902876</td>\n",
       "      <td>5567.267032</td>\n",
       "      <td>3432.740060</td>\n",
       "      <td>591.714643</td>\n",
       "      <td>2636.696703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BTB</td>\n",
       "      <td>4.317228</td>\n",
       "      <td>4267.949820</td>\n",
       "      <td>5483.298115</td>\n",
       "      <td>3439.895488</td>\n",
       "      <td>610.822699</td>\n",
       "      <td>2674.262659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scikit-Optimize gbrt minimize</td>\n",
       "      <td>10.398283</td>\n",
       "      <td>3835.557352</td>\n",
       "      <td>5536.792532</td>\n",
       "      <td>3445.595057</td>\n",
       "      <td>598.237049</td>\n",
       "      <td>2679.640941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyperopt Anneal</td>\n",
       "      <td>4.138011</td>\n",
       "      <td>4044.759981</td>\n",
       "      <td>4620.078719</td>\n",
       "      <td>3537.089592</td>\n",
       "      <td>272.548183</td>\n",
       "      <td>2694.643487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scikit-Optimize API Bayes</td>\n",
       "      <td>29.149408</td>\n",
       "      <td>3609.819929</td>\n",
       "      <td>5341.096304</td>\n",
       "      <td>3450.590099</td>\n",
       "      <td>408.356173</td>\n",
       "      <td>2706.229847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Evolutionary Algorithm Search</td>\n",
       "      <td>25.028434</td>\n",
       "      <td>3501.268253</td>\n",
       "      <td>3935.414664</td>\n",
       "      <td>3451.234900</td>\n",
       "      <td>94.062858</td>\n",
       "      <td>2708.234064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Scikit-Optimize forest minimize</td>\n",
       "      <td>14.882848</td>\n",
       "      <td>3761.765738</td>\n",
       "      <td>5536.792532</td>\n",
       "      <td>3449.772499</td>\n",
       "      <td>539.017159</td>\n",
       "      <td>2714.055111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomSearch</td>\n",
       "      <td>4.686191</td>\n",
       "      <td>4259.892297</td>\n",
       "      <td>5701.840470</td>\n",
       "      <td>3413.942217</td>\n",
       "      <td>607.425657</td>\n",
       "      <td>2750.581122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyperopt TPE</td>\n",
       "      <td>6.407045</td>\n",
       "      <td>4184.970193</td>\n",
       "      <td>4631.380250</td>\n",
       "      <td>3473.879946</td>\n",
       "      <td>360.459850</td>\n",
       "      <td>2777.768522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GPyOpt</td>\n",
       "      <td>38.214963</td>\n",
       "      <td>4784.159838</td>\n",
       "      <td>5785.903613</td>\n",
       "      <td>4386.428347</td>\n",
       "      <td>344.723024</td>\n",
       "      <td>3506.659816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             module       time   mean_score    max_score  \\\n",
       "0                        GridSearch   6.817726  4029.866516  4596.657380   \n",
       "5    Scikit-Optimize dummy minimize   7.574192  4149.902876  5567.267032   \n",
       "10                              BTB   4.317228  4267.949820  5483.298115   \n",
       "7     Scikit-Optimize gbrt minimize  10.398283  3835.557352  5536.792532   \n",
       "3                   Hyperopt Anneal   4.138011  4044.759981  4620.078719   \n",
       "4         Scikit-Optimize API Bayes  29.149408  3609.819929  5341.096304   \n",
       "9     Evolutionary Algorithm Search  25.028434  3501.268253  3935.414664   \n",
       "6   Scikit-Optimize forest minimize  14.882848  3761.765738  5536.792532   \n",
       "1                      RandomSearch   4.686191  4259.892297  5701.840470   \n",
       "2                      Hyperopt TPE   6.407045  4184.970193  4631.380250   \n",
       "8                            GPyOpt  38.214963  4784.159838  5785.903613   \n",
       "\n",
       "      min_score   std_score  best_test_score  \n",
       "0   3438.887311  356.777234      2523.140865  \n",
       "5   3432.740060  591.714643      2636.696703  \n",
       "10  3439.895488  610.822699      2674.262659  \n",
       "7   3445.595057  598.237049      2679.640941  \n",
       "3   3537.089592  272.548183      2694.643487  \n",
       "4   3450.590099  408.356173      2706.229847  \n",
       "9   3451.234900   94.062858      2708.234064  \n",
       "6   3449.772499  539.017159      2714.055111  \n",
       "1   3413.942217  607.425657      2750.581122  \n",
       "2   3473.879946  360.459850      2777.768522  \n",
       "8   4386.428347  344.723024      3506.659816  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_frame = pd.DataFrame(columns=['module', 'time', 'mean_score', 'max_score', 'min_score', 'std_score', 'best_test_score'])\n",
    "stat_frame = stat_frame.append(\n",
    "    pd.DataFrame(\n",
    "        [[elm.name, \n",
    "          elm.time, \n",
    "          elm.plot_data['score'].mean(), \n",
    "          elm.plot_data['score'].max(), \n",
    "          elm.plot_data['score'].min(), \n",
    "          elm.plot_data['score'].std(),\n",
    "          elm.test_score] for elm in eval_array], \n",
    "        columns=['module', 'time', 'mean_score', 'max_score', 'min_score', 'std_score', 'best_test_score']\n",
    "    )\n",
    ")\n",
    "stat_frame.sort_values('best_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# estim = HyperoptEstimator(regressor=xgboost_regression('my_gb'), max_evals=n_iter, trial_timeout=60, seed=random_state)\n",
    "\n",
    "# estim.fit(train_data, train_targets)\n",
    "\n",
    "# print(mean_squared_error(test_targets, estim.predict(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_config = {\n",
    "    'lightgbm.sklearn.LGBMRegressor': {\n",
    "        'learning_rate': np.logspace(-4, -1, 80),\n",
    "        'max_depth':  np.linspace(2,20,18,dtype = int),\n",
    "        'n_estimators': np.linspace(100,2000,1900, dtype = int),\n",
    "        'random_state': [random_state]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -17.47902699438331\n",
      "Generation 2 - Current best internal CV score: -17.47902699438331\n",
      "Generation 3 - Current best internal CV score: -17.47902699438331\n",
      "Generation 4 - Current best internal CV score: -17.47902699438331\n",
      "Generation 5 - Current best internal CV score: -17.47902699438331\n",
      "Generation 6 - Current best internal CV score: -17.47902699438331\n",
      "Generation 7 - Current best internal CV score: -17.47902699438331\n",
      "Generation 8 - Current best internal CV score: -17.47902699438331\n",
      "Generation 9 - Current best internal CV score: -17.47902699438331\n",
      "Generation 10 - Current best internal CV score: -17.47902699438331\n",
      "\n",
      "Best pipeline: LGBMRegressor(input_matrix, learning_rate=0.014606863203649888, max_depth=13, n_estimators=469, random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict={'lightgbm.sklearn.LGBMRegressor': {'learning_rate': array([0.0001 , 0.00011, ..., 0.09163, 0.1    ]), 'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       20]), 'n_estimators': array([ 100,  101, ..., 1998, 2000]), 'random_state': [42]}},\n",
       "       crossover_rate=0.1,\n",
       "       cv=KFold(n_splits=2, random_state=42, shuffle=False),\n",
       "       disable_update_check=False, early_stop=None, generations=10,\n",
       "       max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "       mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
       "       periodic_checkpoint_folder=None, population_size=50,\n",
       "       random_state=42, scoring='neg_mean_squared_error', subsample=1.0,\n",
       "       use_dask=False, verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot = TPOTRegressor(\n",
    "    generations=10, \n",
    "    population_size=50, \n",
    "    verbosity=2,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=kf,\n",
    "    n_jobs=-1,\n",
    "    random_state=random_state,\n",
    "    #periodic_checkpoint_folder='tpot_results',\n",
    "    config_dict=tpot_config\n",
    ")\n",
    "tpot.fit(train_data, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.36163314071664"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-tpot.score(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.36163314071664"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_targets, tpot.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lgbmregressor',\n",
       "  LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "         learning_rate=0.014606863203649888, max_depth=13,\n",
       "         min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "         n_estimators=469, n_jobs=-1, num_leaves=31, objective=None,\n",
       "         random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "         subsample=1.0, subsample_for_bin=200000, subsample_freq=1))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.fitted_pipeline_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tpot.export('tpot_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### auto_ml##########\n",
    "# from auto_ml.utils import get_boston_dataset\n",
    "\n",
    "# df_train, df_test = get_boston_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(random_state)\n",
    "# Load data\n",
    "df_train = pd.DataFrame(train_data)\n",
    "df_train.columns = diabetes.feature_names\n",
    "df_train['targets'] = train_targets\n",
    "df_test = pd.DataFrame(test_data)\n",
    "df_test.columns = diabetes.feature_names\n",
    "df_test['targets'] = test_targets\n",
    "\n",
    "df_train, fl_data = train_test_split(df_train, test_size=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to auto_ml! We're about to go through and make sense of your data using machine learning, and give you a production-ready pipeline to get predictions with.\n",
      "\n",
      "If you have any issues, or new feature ideas, let us know at http://auto.ml\n",
      "You are running on version 2.9.10\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{'epochs': 1000, 'batch_size': 50, 'verbose': 2}\n",
      "Running basic data cleaning\n",
      "Performing feature scaling\n",
      "Fitting DataFrameVectorizer\n",
      "\n",
      "\n",
      "********************************************************************************************\n",
      "About to fit the pipeline for the model DeepLearningRegressor to predict MEDV\n",
      "Started at:\n",
      "2019-02-10 23:14:42\n",
      "\n",
      "We will stop training early if we have not seen an improvement in validation accuracy in 25 epochs\n",
      "To measure validation accuracy, we will split off a random 10 percent of your training data set\n",
      "Train on 154 samples, validate on 28 samples\n",
      "Epoch 1/1000\n",
      " - 1s - loss: 646.4211 - mean_absolute_error: 23.5612 - mean_absolute_percentage_error: 99.9912 - val_loss: 433.8459 - val_mean_absolute_error: 19.8675 - val_mean_absolute_percentage_error: 99.9548\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 646.0476 - mean_absolute_error: 23.5532 - mean_absolute_percentage_error: 99.9510 - val_loss: 433.4662 - val_mean_absolute_error: 19.8579 - val_mean_absolute_percentage_error: 99.8973\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 645.5453 - mean_absolute_error: 23.5426 - mean_absolute_percentage_error: 99.8990 - val_loss: 432.8853 - val_mean_absolute_error: 19.8433 - val_mean_absolute_percentage_error: 99.8093\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 644.7374 - mean_absolute_error: 23.5255 - mean_absolute_percentage_error: 99.8128 - val_loss: 431.8360 - val_mean_absolute_error: 19.8169 - val_mean_absolute_percentage_error: 99.6503\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 643.2497 - mean_absolute_error: 23.4936 - mean_absolute_percentage_error: 99.6519 - val_loss: 429.7778 - val_mean_absolute_error: 19.7649 - val_mean_absolute_percentage_error: 99.3382\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 640.2596 - mean_absolute_error: 23.4302 - mean_absolute_percentage_error: 99.3337 - val_loss: 425.6613 - val_mean_absolute_error: 19.6608 - val_mean_absolute_percentage_error: 98.7142\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 634.2444 - mean_absolute_error: 23.3017 - mean_absolute_percentage_error: 98.6911 - val_loss: 417.3421 - val_mean_absolute_error: 19.4493 - val_mean_absolute_percentage_error: 97.4568\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 621.1710 - mean_absolute_error: 23.0300 - mean_absolute_percentage_error: 97.3832 - val_loss: 400.0321 - val_mean_absolute_error: 19.0050 - val_mean_absolute_percentage_error: 94.8525\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 592.3736 - mean_absolute_error: 22.4215 - mean_absolute_percentage_error: 94.5101 - val_loss: 361.2691 - val_mean_absolute_error: 17.9787 - val_mean_absolute_percentage_error: 89.1140\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 516.5278 - mean_absolute_error: 20.7984 - mean_absolute_percentage_error: 87.3712 - val_loss: 286.5443 - val_mean_absolute_error: 15.5514 - val_mean_absolute_percentage_error: 76.1600\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 376.8803 - mean_absolute_error: 16.8750 - mean_absolute_percentage_error: 71.1245 - val_loss: 209.8948 - val_mean_absolute_error: 12.7004 - val_mean_absolute_percentage_error: 59.6687\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 265.9415 - mean_absolute_error: 13.4009 - mean_absolute_percentage_error: 54.6646 - val_loss: 152.8491 - val_mean_absolute_error: 10.7205 - val_mean_absolute_percentage_error: 51.5685\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 204.6504 - mean_absolute_error: 11.1746 - mean_absolute_percentage_error: 44.4955 - val_loss: 98.1718 - val_mean_absolute_error: 8.1214 - val_mean_absolute_percentage_error: 45.5060\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 133.7607 - mean_absolute_error: 8.1931 - mean_absolute_percentage_error: 33.1858 - val_loss: 64.5568 - val_mean_absolute_error: 6.4924 - val_mean_absolute_percentage_error: 45.0663\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 97.8563 - mean_absolute_error: 7.1369 - mean_absolute_percentage_error: 33.1866 - val_loss: 69.3841 - val_mean_absolute_error: 6.8276 - val_mean_absolute_percentage_error: 55.0954\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 90.5591 - mean_absolute_error: 6.9643 - mean_absolute_percentage_error: 35.4361 - val_loss: 48.2164 - val_mean_absolute_error: 5.7433 - val_mean_absolute_percentage_error: 40.7009\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 107.6506 - mean_absolute_error: 7.5069 - mean_absolute_percentage_error: 33.6457 - val_loss: 61.7065 - val_mean_absolute_error: 6.3045 - val_mean_absolute_percentage_error: 52.6968\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 85.8911 - mean_absolute_error: 6.8421 - mean_absolute_percentage_error: 36.0878 - val_loss: 65.9186 - val_mean_absolute_error: 6.7235 - val_mean_absolute_percentage_error: 52.3290\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 80.4965 - mean_absolute_error: 6.4297 - mean_absolute_percentage_error: 31.9519 - val_loss: 66.9587 - val_mean_absolute_error: 6.7594 - val_mean_absolute_percentage_error: 51.8059\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 80.5114 - mean_absolute_error: 6.5611 - mean_absolute_percentage_error: 33.6835 - val_loss: 43.1053 - val_mean_absolute_error: 5.1798 - val_mean_absolute_percentage_error: 42.7560\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 85.8757 - mean_absolute_error: 6.6821 - mean_absolute_percentage_error: 33.6520 - val_loss: 38.3255 - val_mean_absolute_error: 4.8072 - val_mean_absolute_percentage_error: 35.4232\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 83.6040 - mean_absolute_error: 6.3769 - mean_absolute_percentage_error: 28.4466 - val_loss: 43.4558 - val_mean_absolute_error: 5.3859 - val_mean_absolute_percentage_error: 39.2810\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 73.4288 - mean_absolute_error: 5.9347 - mean_absolute_percentage_error: 27.3150 - val_loss: 69.3318 - val_mean_absolute_error: 6.9642 - val_mean_absolute_percentage_error: 54.2039\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 72.9410 - mean_absolute_error: 6.6390 - mean_absolute_percentage_error: 33.4965 - val_loss: 31.5479 - val_mean_absolute_error: 4.2438 - val_mean_absolute_percentage_error: 31.6669\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 69.4130 - mean_absolute_error: 5.5947 - mean_absolute_percentage_error: 24.1904 - val_loss: 71.0308 - val_mean_absolute_error: 6.6005 - val_mean_absolute_percentage_error: 46.2991\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 66.1866 - mean_absolute_error: 5.8337 - mean_absolute_percentage_error: 26.8870 - val_loss: 30.8575 - val_mean_absolute_error: 4.3042 - val_mean_absolute_percentage_error: 33.2646\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 68.4106 - mean_absolute_error: 6.0385 - mean_absolute_percentage_error: 28.3498 - val_loss: 67.6954 - val_mean_absolute_error: 7.0154 - val_mean_absolute_percentage_error: 52.9008\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 63.2793 - mean_absolute_error: 6.1050 - mean_absolute_percentage_error: 29.8213 - val_loss: 36.5614 - val_mean_absolute_error: 4.7593 - val_mean_absolute_percentage_error: 34.4011\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 55.5829 - mean_absolute_error: 5.3737 - mean_absolute_percentage_error: 25.2480 - val_loss: 28.8273 - val_mean_absolute_error: 4.0226 - val_mean_absolute_percentage_error: 29.1398\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 55.4462 - mean_absolute_error: 5.4281 - mean_absolute_percentage_error: 24.2864 - val_loss: 28.1700 - val_mean_absolute_error: 4.1088 - val_mean_absolute_percentage_error: 31.6298\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 58.3873 - mean_absolute_error: 5.7265 - mean_absolute_percentage_error: 26.4964 - val_loss: 28.8874 - val_mean_absolute_error: 4.1093 - val_mean_absolute_percentage_error: 30.3108\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 51.1712 - mean_absolute_error: 5.3054 - mean_absolute_percentage_error: 23.8272 - val_loss: 70.3651 - val_mean_absolute_error: 6.3008 - val_mean_absolute_percentage_error: 39.9856\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 55.7908 - mean_absolute_error: 5.4366 - mean_absolute_percentage_error: 24.1289 - val_loss: 41.4265 - val_mean_absolute_error: 5.1124 - val_mean_absolute_percentage_error: 35.3478\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 45.8951 - mean_absolute_error: 4.8240 - mean_absolute_percentage_error: 21.3899 - val_loss: 25.9737 - val_mean_absolute_error: 3.9535 - val_mean_absolute_percentage_error: 29.4762\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 46.2880 - mean_absolute_error: 4.9818 - mean_absolute_percentage_error: 22.3307 - val_loss: 39.6729 - val_mean_absolute_error: 5.2481 - val_mean_absolute_percentage_error: 35.1384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000\n",
      " - 0s - loss: 46.5460 - mean_absolute_error: 4.9829 - mean_absolute_percentage_error: 21.7383 - val_loss: 21.0951 - val_mean_absolute_error: 3.1907 - val_mean_absolute_percentage_error: 17.0290\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 55.4806 - mean_absolute_error: 5.3400 - mean_absolute_percentage_error: 22.4045 - val_loss: 29.8819 - val_mean_absolute_error: 4.1483 - val_mean_absolute_percentage_error: 27.9002\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 50.2483 - mean_absolute_error: 5.6504 - mean_absolute_percentage_error: 27.1670 - val_loss: 26.9150 - val_mean_absolute_error: 4.1264 - val_mean_absolute_percentage_error: 27.4680\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 38.9047 - mean_absolute_error: 4.6646 - mean_absolute_percentage_error: 20.9697 - val_loss: 18.9116 - val_mean_absolute_error: 3.0994 - val_mean_absolute_percentage_error: 20.0490\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 46.6716 - mean_absolute_error: 4.6483 - mean_absolute_percentage_error: 19.5229 - val_loss: 15.6119 - val_mean_absolute_error: 2.7520 - val_mean_absolute_percentage_error: 18.1489\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 51.1576 - mean_absolute_error: 4.9321 - mean_absolute_percentage_error: 19.8579 - val_loss: 40.6932 - val_mean_absolute_error: 4.8133 - val_mean_absolute_percentage_error: 31.6666\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 45.1369 - mean_absolute_error: 5.0401 - mean_absolute_percentage_error: 22.6499 - val_loss: 47.1230 - val_mean_absolute_error: 5.5549 - val_mean_absolute_percentage_error: 37.7196\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 42.7124 - mean_absolute_error: 5.1072 - mean_absolute_percentage_error: 23.7093 - val_loss: 27.8384 - val_mean_absolute_error: 3.7034 - val_mean_absolute_percentage_error: 21.3862\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 41.1617 - mean_absolute_error: 4.6119 - mean_absolute_percentage_error: 20.7014 - val_loss: 31.2319 - val_mean_absolute_error: 4.1994 - val_mean_absolute_percentage_error: 22.4961\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 39.5783 - mean_absolute_error: 4.6369 - mean_absolute_percentage_error: 20.1475 - val_loss: 19.9590 - val_mean_absolute_error: 3.3964 - val_mean_absolute_percentage_error: 25.1651\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 40.7731 - mean_absolute_error: 4.6652 - mean_absolute_percentage_error: 20.3494 - val_loss: 26.4146 - val_mean_absolute_error: 3.7825 - val_mean_absolute_percentage_error: 21.2904\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 36.5748 - mean_absolute_error: 4.4185 - mean_absolute_percentage_error: 20.3083 - val_loss: 18.7072 - val_mean_absolute_error: 3.2762 - val_mean_absolute_percentage_error: 23.8657\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 39.0148 - mean_absolute_error: 4.5462 - mean_absolute_percentage_error: 20.4062 - val_loss: 74.1976 - val_mean_absolute_error: 7.6628 - val_mean_absolute_percentage_error: 49.3445\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 46.5283 - mean_absolute_error: 5.4166 - mean_absolute_percentage_error: 26.3322 - val_loss: 25.5158 - val_mean_absolute_error: 3.6784 - val_mean_absolute_percentage_error: 22.2962\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 39.0791 - mean_absolute_error: 4.6420 - mean_absolute_percentage_error: 20.5805 - val_loss: 18.8361 - val_mean_absolute_error: 3.3007 - val_mean_absolute_percentage_error: 23.8122\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 40.5173 - mean_absolute_error: 4.7441 - mean_absolute_percentage_error: 21.0268 - val_loss: 15.7133 - val_mean_absolute_error: 2.8152 - val_mean_absolute_percentage_error: 17.2284\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 51.5326 - mean_absolute_error: 5.2177 - mean_absolute_percentage_error: 22.8567 - val_loss: 23.7778 - val_mean_absolute_error: 3.8771 - val_mean_absolute_percentage_error: 20.9375\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 37.9074 - mean_absolute_error: 4.3805 - mean_absolute_percentage_error: 19.4947 - val_loss: 24.4726 - val_mean_absolute_error: 3.9459 - val_mean_absolute_percentage_error: 28.2620\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 33.4926 - mean_absolute_error: 4.3110 - mean_absolute_percentage_error: 19.6946 - val_loss: 21.0707 - val_mean_absolute_error: 3.6015 - val_mean_absolute_percentage_error: 26.1405\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 42.5134 - mean_absolute_error: 4.8045 - mean_absolute_percentage_error: 20.7994 - val_loss: 32.7809 - val_mean_absolute_error: 4.2556 - val_mean_absolute_percentage_error: 25.8316\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 53.9446 - mean_absolute_error: 5.2978 - mean_absolute_percentage_error: 22.9819 - val_loss: 25.3191 - val_mean_absolute_error: 3.8436 - val_mean_absolute_percentage_error: 22.6275\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 36.1949 - mean_absolute_error: 4.4645 - mean_absolute_percentage_error: 20.7172 - val_loss: 32.5773 - val_mean_absolute_error: 4.2755 - val_mean_absolute_percentage_error: 26.9466\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 35.3293 - mean_absolute_error: 4.3123 - mean_absolute_percentage_error: 19.6193 - val_loss: 42.3422 - val_mean_absolute_error: 5.5512 - val_mean_absolute_percentage_error: 40.1758\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 45.1268 - mean_absolute_error: 5.1851 - mean_absolute_percentage_error: 24.5244 - val_loss: 41.6218 - val_mean_absolute_error: 5.5977 - val_mean_absolute_percentage_error: 36.5832\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 40.5604 - mean_absolute_error: 4.9418 - mean_absolute_percentage_error: 23.3816 - val_loss: 22.1572 - val_mean_absolute_error: 3.6603 - val_mean_absolute_percentage_error: 24.2817\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 38.4910 - mean_absolute_error: 4.6230 - mean_absolute_percentage_error: 20.5683 - val_loss: 28.5145 - val_mean_absolute_error: 4.1513 - val_mean_absolute_percentage_error: 27.7234\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 36.4202 - mean_absolute_error: 4.5189 - mean_absolute_percentage_error: 20.1309 - val_loss: 15.6299 - val_mean_absolute_error: 2.9894 - val_mean_absolute_percentage_error: 20.4803\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 36.7614 - mean_absolute_error: 4.2746 - mean_absolute_percentage_error: 19.0393 - val_loss: 18.8216 - val_mean_absolute_error: 3.3724 - val_mean_absolute_percentage_error: 24.1686\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 35.3648 - mean_absolute_error: 4.4800 - mean_absolute_percentage_error: 20.3683 - val_loss: 14.1275 - val_mean_absolute_error: 2.6752 - val_mean_absolute_percentage_error: 18.3385\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 36.7630 - mean_absolute_error: 4.2695 - mean_absolute_percentage_error: 19.0714 - val_loss: 14.9745 - val_mean_absolute_error: 2.7784 - val_mean_absolute_percentage_error: 20.2663\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 35.9370 - mean_absolute_error: 4.2591 - mean_absolute_percentage_error: 18.4908 - val_loss: 40.2864 - val_mean_absolute_error: 4.5717 - val_mean_absolute_percentage_error: 27.7578\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 44.9313 - mean_absolute_error: 4.7493 - mean_absolute_percentage_error: 20.1401 - val_loss: 17.7665 - val_mean_absolute_error: 3.3563 - val_mean_absolute_percentage_error: 20.7793\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 33.5229 - mean_absolute_error: 4.0211 - mean_absolute_percentage_error: 18.1358 - val_loss: 75.0496 - val_mean_absolute_error: 6.5454 - val_mean_absolute_percentage_error: 41.7424\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 44.5843 - mean_absolute_error: 5.0594 - mean_absolute_percentage_error: 23.4101 - val_loss: 16.4822 - val_mean_absolute_error: 3.1024 - val_mean_absolute_percentage_error: 21.5484\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 38.9132 - mean_absolute_error: 4.6019 - mean_absolute_percentage_error: 21.1876 - val_loss: 14.0270 - val_mean_absolute_error: 2.6604 - val_mean_absolute_percentage_error: 18.0832\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 29.6660 - mean_absolute_error: 3.8240 - mean_absolute_percentage_error: 17.0649 - val_loss: 16.3912 - val_mean_absolute_error: 3.0770 - val_mean_absolute_percentage_error: 21.6470\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 31.1191 - mean_absolute_error: 4.0623 - mean_absolute_percentage_error: 18.4195 - val_loss: 14.6387 - val_mean_absolute_error: 2.8243 - val_mean_absolute_percentage_error: 18.3105\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 38.0563 - mean_absolute_error: 4.4394 - mean_absolute_percentage_error: 19.6855 - val_loss: 50.9002 - val_mean_absolute_error: 6.1131 - val_mean_absolute_percentage_error: 41.4366\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 35.1486 - mean_absolute_error: 4.7704 - mean_absolute_percentage_error: 23.0137 - val_loss: 31.5483 - val_mean_absolute_error: 4.2249 - val_mean_absolute_percentage_error: 25.5155\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 34.7149 - mean_absolute_error: 4.3845 - mean_absolute_percentage_error: 20.2604 - val_loss: 20.9997 - val_mean_absolute_error: 3.6013 - val_mean_absolute_percentage_error: 25.8242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      " - 0s - loss: 35.1820 - mean_absolute_error: 4.4453 - mean_absolute_percentage_error: 20.1671 - val_loss: 60.5255 - val_mean_absolute_error: 5.3423 - val_mean_absolute_percentage_error: 30.1489\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 40.9572 - mean_absolute_error: 4.5569 - mean_absolute_percentage_error: 20.2227 - val_loss: 15.5770 - val_mean_absolute_error: 2.9430 - val_mean_absolute_percentage_error: 20.4769\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 32.7447 - mean_absolute_error: 4.1088 - mean_absolute_percentage_error: 18.4575 - val_loss: 15.8169 - val_mean_absolute_error: 3.0716 - val_mean_absolute_percentage_error: 19.4494\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 31.3672 - mean_absolute_error: 4.0178 - mean_absolute_percentage_error: 17.9192 - val_loss: 38.0438 - val_mean_absolute_error: 4.6126 - val_mean_absolute_percentage_error: 27.7178\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 40.5548 - mean_absolute_error: 4.6322 - mean_absolute_percentage_error: 21.2296 - val_loss: 36.7243 - val_mean_absolute_error: 4.6239 - val_mean_absolute_percentage_error: 28.7770\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 37.6769 - mean_absolute_error: 4.6744 - mean_absolute_percentage_error: 21.5830 - val_loss: 35.9866 - val_mean_absolute_error: 4.6909 - val_mean_absolute_percentage_error: 29.9575\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 36.8287 - mean_absolute_error: 4.4105 - mean_absolute_percentage_error: 19.4809 - val_loss: 51.3598 - val_mean_absolute_error: 5.4747 - val_mean_absolute_percentage_error: 34.3560\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 34.8033 - mean_absolute_error: 4.3539 - mean_absolute_percentage_error: 20.3039 - val_loss: 18.2317 - val_mean_absolute_error: 3.2809 - val_mean_absolute_percentage_error: 23.6576\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 34.3089 - mean_absolute_error: 4.3302 - mean_absolute_percentage_error: 19.2605 - val_loss: 16.6990 - val_mean_absolute_error: 3.0821 - val_mean_absolute_percentage_error: 22.3187\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 31.6792 - mean_absolute_error: 4.0976 - mean_absolute_percentage_error: 18.6250 - val_loss: 23.7227 - val_mean_absolute_error: 3.8325 - val_mean_absolute_percentage_error: 22.1518\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 34.4278 - mean_absolute_error: 4.1582 - mean_absolute_percentage_error: 18.5450 - val_loss: 22.2933 - val_mean_absolute_error: 3.7402 - val_mean_absolute_percentage_error: 24.7760\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 37.0622 - mean_absolute_error: 4.6495 - mean_absolute_percentage_error: 21.5340 - val_loss: 18.6614 - val_mean_absolute_error: 3.4247 - val_mean_absolute_percentage_error: 22.8219\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 33.9375 - mean_absolute_error: 4.2653 - mean_absolute_percentage_error: 19.5950 - val_loss: 14.7443 - val_mean_absolute_error: 2.7806 - val_mean_absolute_percentage_error: 19.8396\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 37.5913 - mean_absolute_error: 4.3934 - mean_absolute_percentage_error: 18.9977 - val_loss: 17.1108 - val_mean_absolute_error: 3.1295 - val_mean_absolute_percentage_error: 22.8817\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 32.5041 - mean_absolute_error: 4.1735 - mean_absolute_percentage_error: 18.9556 - val_loss: 15.1243 - val_mean_absolute_error: 3.0063 - val_mean_absolute_percentage_error: 20.2639\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 31.1661 - mean_absolute_error: 3.9284 - mean_absolute_percentage_error: 17.6056 - val_loss: 21.8832 - val_mean_absolute_error: 3.7839 - val_mean_absolute_percentage_error: 23.9994\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 33.5656 - mean_absolute_error: 4.2283 - mean_absolute_percentage_error: 18.6504 - val_loss: 20.3637 - val_mean_absolute_error: 3.6155 - val_mean_absolute_percentage_error: 23.8895\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 38.5400 - mean_absolute_error: 4.4661 - mean_absolute_percentage_error: 20.1280 - val_loss: 21.7749 - val_mean_absolute_error: 3.6640 - val_mean_absolute_percentage_error: 25.9677\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 28.5176 - mean_absolute_error: 3.9061 - mean_absolute_percentage_error: 17.7037 - val_loss: 17.7141 - val_mean_absolute_error: 3.3379 - val_mean_absolute_percentage_error: 20.0170\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 36.4305 - mean_absolute_error: 4.3758 - mean_absolute_percentage_error: 19.1017 - val_loss: 16.1428 - val_mean_absolute_error: 2.9718 - val_mean_absolute_percentage_error: 21.1801\n",
      "Epoch 00095: early stopping\n",
      "Finished training the pipeline!\n",
      "Total training time:\n",
      "0:00:16\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{'n_estimators': 2000, 'learning_rate': 0.15, 'num_leaves': 8, 'lambda_l2': 0.001, 'histogram_pool_size': 16384}\n",
      "\n",
      "\n",
      "********************************************************************************************\n",
      "About to fit the pipeline for the model LGBMRegressor to predict MEDV\n",
      "Started at:\n",
      "2019-02-10 23:14:59\n",
      "[1]\trandom_holdout_set_from_training_data's rmse: 7.81836\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\trandom_holdout_set_from_training_data's rmse: 7.02353\n",
      "[3]\trandom_holdout_set_from_training_data's rmse: 6.33738\n",
      "[4]\trandom_holdout_set_from_training_data's rmse: 5.89178\n",
      "[5]\trandom_holdout_set_from_training_data's rmse: 5.44069\n",
      "[6]\trandom_holdout_set_from_training_data's rmse: 5.09284\n",
      "[7]\trandom_holdout_set_from_training_data's rmse: 4.81442\n",
      "[8]\trandom_holdout_set_from_training_data's rmse: 4.60566\n",
      "[9]\trandom_holdout_set_from_training_data's rmse: 4.4407\n",
      "[10]\trandom_holdout_set_from_training_data's rmse: 4.3054\n",
      "[11]\trandom_holdout_set_from_training_data's rmse: 4.15802\n",
      "[12]\trandom_holdout_set_from_training_data's rmse: 4.09971\n",
      "[13]\trandom_holdout_set_from_training_data's rmse: 4.01898\n",
      "[14]\trandom_holdout_set_from_training_data's rmse: 3.93457\n",
      "[15]\trandom_holdout_set_from_training_data's rmse: 3.89352\n",
      "[16]\trandom_holdout_set_from_training_data's rmse: 3.86117\n",
      "[17]\trandom_holdout_set_from_training_data's rmse: 3.79059\n",
      "[18]\trandom_holdout_set_from_training_data's rmse: 3.78519\n",
      "[19]\trandom_holdout_set_from_training_data's rmse: 3.7424\n",
      "[20]\trandom_holdout_set_from_training_data's rmse: 3.70879\n",
      "[21]\trandom_holdout_set_from_training_data's rmse: 3.66042\n",
      "[22]\trandom_holdout_set_from_training_data's rmse: 3.64359\n",
      "[23]\trandom_holdout_set_from_training_data's rmse: 3.6616\n",
      "[24]\trandom_holdout_set_from_training_data's rmse: 3.65957\n",
      "[25]\trandom_holdout_set_from_training_data's rmse: 3.63168\n",
      "[26]\trandom_holdout_set_from_training_data's rmse: 3.62641\n",
      "[27]\trandom_holdout_set_from_training_data's rmse: 3.59232\n",
      "[28]\trandom_holdout_set_from_training_data's rmse: 3.60798\n",
      "[29]\trandom_holdout_set_from_training_data's rmse: 3.60524\n",
      "[30]\trandom_holdout_set_from_training_data's rmse: 3.54757\n",
      "[31]\trandom_holdout_set_from_training_data's rmse: 3.57301\n",
      "[32]\trandom_holdout_set_from_training_data's rmse: 3.52692\n",
      "[33]\trandom_holdout_set_from_training_data's rmse: 3.50541\n",
      "[34]\trandom_holdout_set_from_training_data's rmse: 3.49115\n",
      "[35]\trandom_holdout_set_from_training_data's rmse: 3.48922\n",
      "[36]\trandom_holdout_set_from_training_data's rmse: 3.50121\n",
      "[37]\trandom_holdout_set_from_training_data's rmse: 3.4959\n",
      "[38]\trandom_holdout_set_from_training_data's rmse: 3.474\n",
      "[39]\trandom_holdout_set_from_training_data's rmse: 3.43564\n",
      "[40]\trandom_holdout_set_from_training_data's rmse: 3.42919\n",
      "[41]\trandom_holdout_set_from_training_data's rmse: 3.42952\n",
      "[42]\trandom_holdout_set_from_training_data's rmse: 3.4156\n",
      "[43]\trandom_holdout_set_from_training_data's rmse: 3.42692\n",
      "[44]\trandom_holdout_set_from_training_data's rmse: 3.44753\n",
      "[45]\trandom_holdout_set_from_training_data's rmse: 3.44707\n",
      "[46]\trandom_holdout_set_from_training_data's rmse: 3.43627\n",
      "[47]\trandom_holdout_set_from_training_data's rmse: 3.45172\n",
      "[48]\trandom_holdout_set_from_training_data's rmse: 3.45409\n",
      "[49]\trandom_holdout_set_from_training_data's rmse: 3.45101\n",
      "[50]\trandom_holdout_set_from_training_data's rmse: 3.47392\n",
      "[51]\trandom_holdout_set_from_training_data's rmse: 3.49736\n",
      "[52]\trandom_holdout_set_from_training_data's rmse: 3.47912\n",
      "[53]\trandom_holdout_set_from_training_data's rmse: 3.49135\n",
      "[54]\trandom_holdout_set_from_training_data's rmse: 3.51304\n",
      "[55]\trandom_holdout_set_from_training_data's rmse: 3.49322\n",
      "[56]\trandom_holdout_set_from_training_data's rmse: 3.48587\n",
      "[57]\trandom_holdout_set_from_training_data's rmse: 3.48449\n",
      "[58]\trandom_holdout_set_from_training_data's rmse: 3.47085\n",
      "[59]\trandom_holdout_set_from_training_data's rmse: 3.48118\n",
      "[60]\trandom_holdout_set_from_training_data's rmse: 3.46743\n",
      "[61]\trandom_holdout_set_from_training_data's rmse: 3.47444\n",
      "[62]\trandom_holdout_set_from_training_data's rmse: 3.4761\n",
      "[63]\trandom_holdout_set_from_training_data's rmse: 3.46042\n",
      "[64]\trandom_holdout_set_from_training_data's rmse: 3.46895\n",
      "[65]\trandom_holdout_set_from_training_data's rmse: 3.47985\n",
      "[66]\trandom_holdout_set_from_training_data's rmse: 3.48235\n",
      "[67]\trandom_holdout_set_from_training_data's rmse: 3.46692\n",
      "[68]\trandom_holdout_set_from_training_data's rmse: 3.46449\n",
      "[69]\trandom_holdout_set_from_training_data's rmse: 3.4935\n",
      "[70]\trandom_holdout_set_from_training_data's rmse: 3.47535\n",
      "[71]\trandom_holdout_set_from_training_data's rmse: 3.46682\n",
      "[72]\trandom_holdout_set_from_training_data's rmse: 3.48848\n",
      "[73]\trandom_holdout_set_from_training_data's rmse: 3.46866\n",
      "[74]\trandom_holdout_set_from_training_data's rmse: 3.47528\n",
      "[75]\trandom_holdout_set_from_training_data's rmse: 3.45361\n",
      "[76]\trandom_holdout_set_from_training_data's rmse: 3.46413\n",
      "[77]\trandom_holdout_set_from_training_data's rmse: 3.45096\n",
      "[78]\trandom_holdout_set_from_training_data's rmse: 3.46075\n",
      "[79]\trandom_holdout_set_from_training_data's rmse: 3.47845\n",
      "[80]\trandom_holdout_set_from_training_data's rmse: 3.46623\n",
      "[81]\trandom_holdout_set_from_training_data's rmse: 3.47511\n",
      "[82]\trandom_holdout_set_from_training_data's rmse: 3.48807\n",
      "[83]\trandom_holdout_set_from_training_data's rmse: 3.46705\n",
      "[84]\trandom_holdout_set_from_training_data's rmse: 3.46682\n",
      "[85]\trandom_holdout_set_from_training_data's rmse: 3.46074\n",
      "[86]\trandom_holdout_set_from_training_data's rmse: 3.44476\n",
      "[87]\trandom_holdout_set_from_training_data's rmse: 3.45958\n",
      "[88]\trandom_holdout_set_from_training_data's rmse: 3.48004\n",
      "[89]\trandom_holdout_set_from_training_data's rmse: 3.48815\n",
      "[90]\trandom_holdout_set_from_training_data's rmse: 3.49792\n",
      "[91]\trandom_holdout_set_from_training_data's rmse: 3.49311\n",
      "[92]\trandom_holdout_set_from_training_data's rmse: 3.48297\n",
      "[93]\trandom_holdout_set_from_training_data's rmse: 3.49612\n",
      "[94]\trandom_holdout_set_from_training_data's rmse: 3.49192\n",
      "[95]\trandom_holdout_set_from_training_data's rmse: 3.47658\n",
      "[96]\trandom_holdout_set_from_training_data's rmse: 3.48145\n",
      "[97]\trandom_holdout_set_from_training_data's rmse: 3.48054\n",
      "[98]\trandom_holdout_set_from_training_data's rmse: 3.50068\n",
      "[99]\trandom_holdout_set_from_training_data's rmse: 3.49727\n",
      "[100]\trandom_holdout_set_from_training_data's rmse: 3.47498\n",
      "[101]\trandom_holdout_set_from_training_data's rmse: 3.4945\n",
      "[102]\trandom_holdout_set_from_training_data's rmse: 3.50981\n",
      "[103]\trandom_holdout_set_from_training_data's rmse: 3.51224\n",
      "[104]\trandom_holdout_set_from_training_data's rmse: 3.5105\n",
      "[105]\trandom_holdout_set_from_training_data's rmse: 3.50292\n",
      "[106]\trandom_holdout_set_from_training_data's rmse: 3.52044\n",
      "[107]\trandom_holdout_set_from_training_data's rmse: 3.51659\n",
      "[108]\trandom_holdout_set_from_training_data's rmse: 3.5042\n",
      "[109]\trandom_holdout_set_from_training_data's rmse: 3.49976\n",
      "[110]\trandom_holdout_set_from_training_data's rmse: 3.51528\n",
      "[111]\trandom_holdout_set_from_training_data's rmse: 3.53413\n",
      "[112]\trandom_holdout_set_from_training_data's rmse: 3.51226\n",
      "[113]\trandom_holdout_set_from_training_data's rmse: 3.52758\n",
      "[114]\trandom_holdout_set_from_training_data's rmse: 3.52293\n",
      "[115]\trandom_holdout_set_from_training_data's rmse: 3.53076\n",
      "[116]\trandom_holdout_set_from_training_data's rmse: 3.53473\n",
      "[117]\trandom_holdout_set_from_training_data's rmse: 3.51605\n",
      "[118]\trandom_holdout_set_from_training_data's rmse: 3.5247\n",
      "[119]\trandom_holdout_set_from_training_data's rmse: 3.51176\n",
      "[120]\trandom_holdout_set_from_training_data's rmse: 3.51346\n",
      "[121]\trandom_holdout_set_from_training_data's rmse: 3.51728\n",
      "[122]\trandom_holdout_set_from_training_data's rmse: 3.52425\n",
      "[123]\trandom_holdout_set_from_training_data's rmse: 3.53002\n",
      "[124]\trandom_holdout_set_from_training_data's rmse: 3.5144\n",
      "[125]\trandom_holdout_set_from_training_data's rmse: 3.52904\n",
      "[126]\trandom_holdout_set_from_training_data's rmse: 3.51477\n",
      "[127]\trandom_holdout_set_from_training_data's rmse: 3.52081\n",
      "[128]\trandom_holdout_set_from_training_data's rmse: 3.52261\n",
      "[129]\trandom_holdout_set_from_training_data's rmse: 3.52404\n",
      "[130]\trandom_holdout_set_from_training_data's rmse: 3.53591\n",
      "[131]\trandom_holdout_set_from_training_data's rmse: 3.53141\n",
      "[132]\trandom_holdout_set_from_training_data's rmse: 3.54353\n",
      "[133]\trandom_holdout_set_from_training_data's rmse: 3.54987\n",
      "[134]\trandom_holdout_set_from_training_data's rmse: 3.54089\n",
      "[135]\trandom_holdout_set_from_training_data's rmse: 3.54279\n",
      "[136]\trandom_holdout_set_from_training_data's rmse: 3.54691\n",
      "[137]\trandom_holdout_set_from_training_data's rmse: 3.54954\n",
      "[138]\trandom_holdout_set_from_training_data's rmse: 3.54592\n",
      "[139]\trandom_holdout_set_from_training_data's rmse: 3.54903\n",
      "[140]\trandom_holdout_set_from_training_data's rmse: 3.55256\n",
      "[141]\trandom_holdout_set_from_training_data's rmse: 3.53749\n",
      "[142]\trandom_holdout_set_from_training_data's rmse: 3.54058\n",
      "Early stopping, best iteration is:\n",
      "[42]\trandom_holdout_set_from_training_data's rmse: 3.4156\n",
      "Finished training the pipeline!\n",
      "Total training time:\n",
      "0:00:00\n",
      "\n",
      "\n",
      "Here are the results from our LGBMRegressor\n",
      "predicting MEDV\n",
      "Calculating feature responses, for advanced analytics.\n",
      "The printed list will only contain at most the top 100 features.\n",
      "+----+---------------------+--------------+----------+-------------------+-------------------+-----------+-----------+-----------+-----------+\n",
      "|    | Feature Name        |   Importance |    Delta |   FR_Decrementing |   FR_Incrementing |   FRD_abs |   FRI_abs |   FRD_MAD |   FRI_MAD |\n",
      "|----+---------------------+--------------+----------+-------------------+-------------------+-----------+-----------+-----------+-----------|\n",
      "| 16 | feature_learning_3  |            0 |   0.6463 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 13 | CHAS=1.0            |            0 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 21 | feature_learning_8  |            0 |   0.6059 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 20 | feature_learning_7  |            0 |   0.2559 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 12 | CHAS=0.0            |            0 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 19 | feature_learning_6  |            0 |   0.2597 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 22 | feature_learning_9  |            0 |   0.7728 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 15 | feature_learning_2  |            0 |   0.5739 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 17 | feature_learning_4  |            1 |   0.5906 |            0.0104 |           -0.0407 |    0.0104 |    0.0407 |    0.0000 |    0.0000 |\n",
      "| 23 | feature_learning_10 |            1 |   0.2592 |           -0.0071 |            0.0081 |    0.0071 |    0.0081 |    0.0000 |    0.0000 |\n",
      "|  1 | ZN                  |            1 |  11.8852 |           -0.0037 |            0.0015 |    0.0037 |    0.0015 |    0.0000 |    0.0000 |\n",
      "|  7 | RAD                 |            3 |   0.1920 |           -0.0878 |            0.2233 |    0.0878 |    0.2233 |    0.0000 |    0.0000 |\n",
      "|  8 | TAX                 |            9 |   0.1818 |            0.3340 |           -0.1726 |    0.3358 |    0.1742 |    0.0000 |    0.0000 |\n",
      "|  2 | INDUS               |           13 |   0.1853 |            0.2808 |           -0.1218 |    0.3336 |    0.2923 |    0.0000 |    0.0000 |\n",
      "|  5 | AGE                 |           14 |   0.1635 |           -0.1029 |            0.0494 |    0.2438 |    0.2508 |    0.0520 |    0.0598 |\n",
      "|  9 | PTRATIO             |           15 |   0.1654 |            0.1088 |           -0.0714 |    0.2244 |    0.1730 |    0.0913 |    0.0281 |\n",
      "| 10 | B                   |           16 |   0.1373 |           -0.4080 |           -0.1425 |    0.5413 |    0.2509 |    0.5383 |    0.1147 |\n",
      "|  0 | CRIM                |           19 |   0.1517 |           -0.0130 |           -0.1656 |    0.2353 |    0.4205 |    0.0876 |    0.3505 |\n",
      "| 18 | feature_learning_5  |           21 |   0.2294 |            1.2560 |           -1.0219 |    1.3423 |    1.0838 |    0.4608 |    0.3279 |\n",
      "| 14 | feature_learning_1  |           25 |   0.6385 |           -0.2992 |            0.1484 |    0.4534 |    0.5303 |    0.1399 |    0.2940 |\n",
      "|  3 | NOX                 |           26 |   0.1472 |            0.2519 |           -0.2977 |    0.5386 |    0.6162 |    0.2094 |    0.2825 |\n",
      "|  4 | RM                  |           28 |   0.1321 |           -0.3903 |            0.5763 |    0.5228 |    0.7296 |    0.2041 |    0.2544 |\n",
      "|  6 | DIS                 |           36 |   0.1523 |            0.1979 |            0.2414 |    0.6583 |    0.7253 |    0.5141 |    0.5598 |\n",
      "| 11 | LSTAT               |           46 |   0.1431 |            1.7306 |           -1.3591 |    1.7779 |    1.4335 |    0.9735 |    0.6950 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+--------------+----------+-------------------+-------------------+-----------+-----------+-----------+-----------+\n",
      "\n",
      "\n",
      "*******\n",
      "Legend:\n",
      "Importance = Feature Importance\n",
      "     Explanation: A weighted measure of how much of the variance the model is able to explain is due to this column\n",
      "FR_delta = Feature Response Delta Amount\n",
      "     Explanation: Amount this column was incremented or decremented by to calculate the feature reponses\n",
      "FR_Decrementing = Feature Response From Decrementing Values In This Column By One FR_delta\n",
      "     Explanation: Represents how much the predicted output values respond to subtracting one FR_delta amount from every value in this column\n",
      "FR_Incrementing = Feature Response From Incrementing Values In This Column By One FR_delta\n",
      "     Explanation: Represents how much the predicted output values respond to adding one FR_delta amount to every value in this column\n",
      "FRD_MAD = Feature Response From Decrementing- Median Absolute Delta\n",
      "     Explanation: Takes the absolute value of all changes in predictions, then takes the median of those. Useful for seeing if decrementing this feature provokes strong changes that are both positive and negative\n",
      "FRI_MAD = Feature Response From Incrementing- Median Absolute Delta\n",
      "     Explanation: Takes the absolute value of all changes in predictions, then takes the median of those. Useful for seeing if incrementing this feature provokes strong changes that are both positive and negative\n",
      "FRD_abs = Feature Response From Decrementing Avg Absolute Change\n",
      "     Explanation: What is the average absolute change in predicted output values to subtracting one FR_delta amount to every value in this column. Useful for seeing if output is sensitive to a feature, but not in a uniformly positive or negative way\n",
      "FRI_abs = Feature Response From Incrementing Avg Absolute Change\n",
      "     Explanation: What is the average absolute change in predicted output values to adding one FR_delta amount to every value in this column. Useful for seeing if output is sensitive to a feature, but not in a uniformly positive or negative way\n",
      "*******\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "***********************************************\n",
      "Advanced scoring metrics for the trained regression model on this particular dataset:\n",
      "\n",
      "Here is the overall RMSE for these predictions:\n",
      "4.1914474180200205\n",
      "\n",
      "Here is the average of the predictions:\n",
      "21.442622187899122\n",
      "\n",
      "Here is the average actual value on this validation set:\n",
      "21.488235294117654\n",
      "\n",
      "Here is the median prediction:\n",
      "21.034479644187087\n",
      "\n",
      "Here is the median actual value:\n",
      "20.15\n",
      "\n",
      "Here is the mean absolute error:\n",
      "2.500106761373544\n",
      "\n",
      "Here is the median absolute error (robust to outliers):\n",
      "1.7384825339524648\n",
      "\n",
      "Here is the explained variance:\n",
      "0.7604630479220672\n",
      "\n",
      "Here is the R-squared value:\n",
      "0.7604346768852921\n",
      "Count of positive differences (prediction > actual):\n",
      "55\n",
      "Count of negative differences:\n",
      "47\n",
      "Average positive difference:\n",
      "2.2759850256892036\n",
      "Average negative difference:\n",
      "-2.762376877599899\n",
      "\n",
      "\n",
      "***********************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed(random_state)\n",
    "\n",
    "# column_descriptions = {\n",
    "#     'targets': 'output'\n",
    "# }\n",
    "\n",
    "column_descriptions = {\n",
    "    'MEDV': 'output',\n",
    "    'CHAS': 'categorical'\n",
    "}\n",
    "\n",
    "ml_predictor = Predictor(\n",
    "    type_of_estimator='regressor', \n",
    "    column_descriptions=column_descriptions\n",
    ")\n",
    "\n",
    "ml_predictor.train(\n",
    "    df_train, \n",
    "    model_names = 'LGBMRegressor',\n",
    "    cv = kf,\n",
    "    feature_learning = True,\n",
    "#     fl_data = df_train.copy()\n",
    "    fl_data = fl_data\n",
    ")\n",
    "\n",
    "# Score the model on test data\n",
    "test_score = ml_predictor.score(df_test, df_test.MEDV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.5682314580267"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(df_test.MEDV, ml_predictor.predict(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-154-35585cb152cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m-\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_score' is not defined"
     ]
    }
   ],
   "source": [
    "-test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
